{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW6 Comprehensive Supervised Learning\n",
    "Contributors: Zongyu Wu, Tony Wilson, Chandler Smith\n",
    "\n",
    "Summary: The overall purpose of this assignment is to tie together a variety of supervised learning techniques in order to appropriately analyze several questions related to the Behavioral Risk Factor Surveillance System. More specifically, the goal is to use supervised ML to identify patterns of comorbidity among the survey respondents. This is a comparative exercise focusing on pre (2019) and post (2021) covid health. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notes from discussion:\n",
    "\n",
    "Approach: One approach for understanding behavioral factors behind comorbidity is to apply classification algorithms to the BRFSS data. Such algorithms can be trained to predict whether an individual has multiple chronic conditions based on their responses to the survey questions. By analyzing the features that are most important for predicting comorbidity, one can identify risk factors and inform the development of targeted prevention and intervention strategies.\n",
    "\n",
    "Response related:\n",
    "Depression = ADDEPEV3\n",
    " Ever told Asthma = _CASTHM1\n",
    " COPD = (CHCCOPD2 for 2019 and CHCCOPD3 for 2021)\n",
    " Cancer = (combine CHCSCNCR and CHCOCNCR)\n",
    " Ever told Heart Condition = combination of CVDCRHD4, CVDINFR4 and CVDSTRK3\n",
    " Diabetes = DIABETE4\n",
    " \n",
    "\n",
    "Key demographic features:\n",
    "Age: _AGE_G\n",
    " Marital: MARITAL\n",
    " Sex: _SEX\n",
    " Income: INCOME2\n",
    " Education: _EDUCAG\n",
    "\n",
    "- Do NOT refer to correlation\n",
    "- BRFSS data can be used to understand comorbidity, which refers to the presence of multiple chronic conditions in an individual. \n",
    "- RFSS uses a complex sampling and weighting scheme to measure prevalence of many health conditions, behavioral and lifestyle related risk factors and emerging health issues in states. \n",
    "- Do not use the weight variable as we are conducting estimations. \n",
    "\n",
    "\n",
    "- 2019 Codebook: https://www.cdc.gov/brfss/annual_data/2019/pdf/codebook19_llcp-v2-508.HTML\n",
    "- 2021 Codebook: https://www.cdc.gov/brfss/annual_data/2021/pdf/codebook21_llcp-v2-508.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clean, Standardize, and Merge data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn \n",
    "\n",
    "# Libraries related to outlier detection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color= darkgreen> Basic EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 1: Read the data and merge into Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE  \\\n0    1.00    1.00  b'01192021'  b'01'  b'19'  b'2021'   1100.00   \n1    1.00    1.00  b'01212021'  b'01'  b'21'  b'2021'   1100.00   \n2    1.00    1.00  b'01212021'  b'01'  b'21'  b'2021'   1100.00   \n3    1.00    1.00  b'01172021'  b'01'  b'17'  b'2021'   1100.00   \n4    1.00    1.00  b'01152021'  b'01'  b'15'  b'2021'   1100.00   \n\n           SEQNO          _PSU  CTELENM1  ...  _FRTRES1  _VEGRES1  _FRUTSU1  \\\n0  b'2021000001' 2021000001.00      1.00  ...      1.00      1.00    100.00   \n1  b'2021000002' 2021000002.00      1.00  ...      1.00      1.00    100.00   \n2  b'2021000003' 2021000003.00      1.00  ...      1.00      1.00    100.00   \n3  b'2021000004' 2021000004.00      1.00  ...      1.00      1.00    114.00   \n4  b'2021000005' 2021000005.00      1.00  ...      1.00      1.00    100.00   \n\n   _VEGESU1  _FRTLT1A  _VEGLT1A  _FRT16A  _VEG23A  _FRUITE1  _VEGETE1  \n0    214.00      1.00      1.00     1.00     1.00      0.00      0.00  \n1    128.00      1.00      1.00     1.00     1.00      0.00      0.00  \n2     71.00      1.00      2.00     1.00     1.00      0.00      0.00  \n3    165.00      1.00      1.00     1.00     1.00      0.00      0.00  \n4    258.00      1.00      1.00     1.00     1.00      0.00      0.00  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_FRTRES1</th>\n      <th>_VEGRES1</th>\n      <th>_FRUTSU1</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01192021'</td>\n      <td>b'01'</td>\n      <td>b'19'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000001'</td>\n      <td>2021000001.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>214.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01212021'</td>\n      <td>b'01'</td>\n      <td>b'21'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000002'</td>\n      <td>2021000002.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>128.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01212021'</td>\n      <td>b'01'</td>\n      <td>b'21'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000003'</td>\n      <td>2021000003.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>71.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01172021'</td>\n      <td>b'01'</td>\n      <td>b'17'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000004'</td>\n      <td>2021000004.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>114.00</td>\n      <td>165.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01152021'</td>\n      <td>b'01'</td>\n      <td>b'15'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000005'</td>\n      <td>2021000005.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>258.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 250 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                       Data Frame Setup                                                                                  '''\n",
    "###############################################################################################################################################################################\n",
    "## The first column is index: skipping that column to end read csv to Panda Data Frame\n",
    "df_21 = pd.read_csv(\"res/brfss21-1.csv\")\n",
    "df_21.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "df_21.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n0       1       1  1182019       1    18   2019      1100  2019000001   \n1       1       1  1132019       1    13   2019      1100  2019000002   \n2       1       1  1182019       1    18   2019      1100  2019000003   \n3       1       1  1182019       1    18   2019      1200  2019000004   \n4       1       1  1042019       1     4   2019      1100  2019000005   \n\n         _PSU  CTELENM1  ...  _VEGESU1  _FRTLT1A  _VEGLT1A  _FRT16A  _VEG23A  \\\n0  2019000001      1.00  ...    114.00         1         1        1        1   \n1  2019000002      1.00  ...    121.00         1         1        1        1   \n2  2019000003      1.00  ...    164.00         1         1        1        1   \n3  2019000004      1.00  ...       NaN         9         9        1        1   \n4  2019000005      1.00  ...    178.00         1         1        1        1   \n\n   _FRUITE1  _VEGETE1  _FLSHOT7  _PNEUMO3  _AIDTST4  \n0         0         0      2.00      1.00      2.00  \n1         0         0      1.00      1.00      2.00  \n2         0         0      1.00      2.00      2.00  \n3         1         1      9.00      9.00       NaN  \n4         0         0      2.00      1.00      2.00  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n      <th>_FLSHOT7</th>\n      <th>_PNEUMO3</th>\n      <th>_AIDTST4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000001</td>\n      <td>2019000001</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>114.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1132019</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000002</td>\n      <td>2019000002</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>121.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000003</td>\n      <td>2019000003</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>164.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1200</td>\n      <td>2019000004</td>\n      <td>2019000004</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1042019</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000005</td>\n      <td>2019000005</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>178.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 250 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19 = pd.read_csv(\"res/brfss19-1.csv\")\n",
    "df_19.drop(columns=\"Unnamed: 0\", inplace= True)\n",
    "df_19.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 2: Summary of Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _STATE    FMONTH       IDATE    IMONTH      IDAY     IYEAR  DISPCODE  \\\ncount 418268.00 418268.00   418268.00 418268.00 418268.00 418268.00 418268.00   \nmean      29.62      6.54  6727352.51      6.58     14.53   2019.04   1117.44   \nstd       16.15      3.34  3304672.99      3.31      8.49      0.21     37.95   \nmin        1.00      1.00  1012020.00      1.00      1.00   2019.00   1100.00   \n25%       18.00      4.00  4082019.00      4.00      7.00   2019.00   1100.00   \n50%       27.00      7.00  7012019.00      7.00     14.00   2019.00   1100.00   \n75%       42.00      9.00  9302019.00      9.00     22.00   2019.00   1100.00   \nmax       72.00     12.00 12312019.00     12.00     31.00   2020.00   1200.00   \n\n              SEQNO          _PSU  CTELENM1  ...  _VEGESU1  _FRTLT1A  \\\ncount     418268.00     418268.00 149941.00  ... 364838.00 418268.00   \nmean  2019004884.52 2019004884.52      1.00  ...    204.14      2.19   \nstd         3653.32       3653.32      0.00  ...    267.90      2.40   \nmin   2019000001.00 2019000001.00      1.00  ...      0.00      1.00   \n25%   2019002011.00 2019002011.00      1.00  ...    114.00      1.00   \n50%   2019004137.00 2019004137.00      1.00  ...    165.00      1.00   \n75%   2019006895.00 2019006895.00      1.00  ...    229.00      2.00   \nmax   2019017419.00 2019017419.00      1.00  ...  13204.00      9.00   \n\n       _VEGLT1A   _FRT16A   _VEG23A  _FRUITE1  _VEGETE1  _FLSHOT7  _PNEUMO3  \\\ncount 418268.00 418268.00 418268.00 418268.00 418268.00 159112.00 159112.00   \nmean       2.19      1.00      1.00      0.11      0.13      2.23      2.37   \nstd        2.63      0.04      0.05      0.32      0.35      2.47      2.73   \nmin        1.00      0.00      0.00      0.00      0.00      1.00      1.00   \n25%        1.00      1.00      1.00      0.00      0.00      1.00      1.00   \n50%        1.00      1.00      1.00      0.00      0.00      1.00      1.00   \n75%        2.00      1.00      1.00      0.00      0.00      2.00      2.00   \nmax        9.00      1.00      1.00      2.00      2.00      9.00      9.00   \n\n       _AIDTST4  \ncount 377977.00  \nmean       1.97  \nstd        1.56  \nmin        1.00  \n25%        1.00  \n50%        2.00  \n75%        2.00  \nmax        9.00  \n\n[8 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n      <th>_FLSHOT7</th>\n      <th>_PNEUMO3</th>\n      <th>_AIDTST4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>149941.00</td>\n      <td>...</td>\n      <td>364838.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>159112.00</td>\n      <td>159112.00</td>\n      <td>377977.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29.62</td>\n      <td>6.54</td>\n      <td>6727352.51</td>\n      <td>6.58</td>\n      <td>14.53</td>\n      <td>2019.04</td>\n      <td>1117.44</td>\n      <td>2019004884.52</td>\n      <td>2019004884.52</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>204.14</td>\n      <td>2.19</td>\n      <td>2.19</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.11</td>\n      <td>0.13</td>\n      <td>2.23</td>\n      <td>2.37</td>\n      <td>1.97</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>16.15</td>\n      <td>3.34</td>\n      <td>3304672.99</td>\n      <td>3.31</td>\n      <td>8.49</td>\n      <td>0.21</td>\n      <td>37.95</td>\n      <td>3653.32</td>\n      <td>3653.32</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>267.90</td>\n      <td>2.40</td>\n      <td>2.63</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>0.32</td>\n      <td>0.35</td>\n      <td>2.47</td>\n      <td>2.73</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1012020.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019000001.00</td>\n      <td>2019000001.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>18.00</td>\n      <td>4.00</td>\n      <td>4082019.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019002011.00</td>\n      <td>2019002011.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>114.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>27.00</td>\n      <td>7.00</td>\n      <td>7012019.00</td>\n      <td>7.00</td>\n      <td>14.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019004137.00</td>\n      <td>2019004137.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>165.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>42.00</td>\n      <td>9.00</td>\n      <td>9302019.00</td>\n      <td>9.00</td>\n      <td>22.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019006895.00</td>\n      <td>2019006895.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>229.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>72.00</td>\n      <td>12.00</td>\n      <td>12312019.00</td>\n      <td>12.00</td>\n      <td>31.00</td>\n      <td>2020.00</td>\n      <td>1200.00</td>\n      <td>2019017419.00</td>\n      <td>2019017419.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>13204.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 250 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                    Data Frame Description                                                                               '''\n",
    "###############################################################################################################################################################################\n",
    "df_19.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(418268, 250)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                     Data Frame Shape                                                                                    '''\n",
    "###############################################################################################################################################################################\n",
    "df_19.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _STATE    FMONTH  DISPCODE          _PSU  CTELENM1  PVTRESD1  \\\ncount 438693.00 438693.00 438693.00     438693.00 117786.00 117786.00   \nmean      30.74      6.41   1118.19 2021006064.89      1.00      1.00   \nstd       15.33      3.42     38.58       6383.75      0.00      0.02   \nmin        1.00      1.00   1100.00 2021000001.00      1.00      1.00   \n25%       20.00      3.00   1100.00 2021002091.00      1.00      1.00   \n50%       31.00      6.00   1100.00 2021004338.00      1.00      1.00   \n75%       41.00      9.00   1100.00 2021007674.00      1.00      1.00   \nmax       78.00     12.00   1200.00 2021039095.00      2.00      2.00   \n\n       COLGHOUS  STATERE1   LADULT1  COLGSEX  ...  _FRTRES1  _VEGRES1  \\\ncount     30.00 117786.00 117786.00    30.00  ... 438693.00 438693.00   \nmean       1.00      1.00      1.01     1.63  ...      0.88      0.86   \nstd        0.00      0.00      0.08     0.49  ...      0.32      0.34   \nmin        1.00      1.00      1.00     1.00  ...      0.00      0.00   \n25%        1.00      1.00      1.00     1.00  ...      1.00      1.00   \n50%        1.00      1.00      1.00     2.00  ...      1.00      1.00   \n75%        1.00      1.00      1.00     2.00  ...      1.00      1.00   \nmax        1.00      1.00      2.00     2.00  ...      1.00      1.00   \n\n       _FRUTSU1  _VEGESU1  _FRTLT1A  _VEGLT1A   _FRT16A   _VEG23A  _FRUITE1  \\\ncount 387606.00 378566.00 438693.00 438693.00 438693.00 438693.00 438693.00   \nmean     178.34    271.54      2.27      2.26      0.99      0.99      0.13   \nstd      691.29   1036.23      2.49      2.71      0.07      0.09      0.35   \nmin        0.00      0.00      1.00      1.00      0.00      0.00      0.00   \n25%       57.00    114.00      1.00      1.00      1.00      1.00      0.00   \n50%      100.00    167.00      1.00      1.00      1.00      1.00      0.00   \n75%      200.00    229.00      2.00      2.00      1.00      1.00      0.00   \nmax    19800.00  39600.00      9.00      9.00      1.00      1.00      2.00   \n\n       _VEGETE1  \ncount 438693.00  \nmean       0.15  \nstd        0.38  \nmin        0.00  \n25%        0.00  \n50%        0.00  \n75%        0.00  \nmax        2.00  \n\n[8 rows x 245 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>DISPCODE</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>PVTRESD1</th>\n      <th>COLGHOUS</th>\n      <th>STATERE1</th>\n      <th>LADULT1</th>\n      <th>COLGSEX</th>\n      <th>...</th>\n      <th>_FRTRES1</th>\n      <th>_VEGRES1</th>\n      <th>_FRUTSU1</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>117786.00</td>\n      <td>117786.00</td>\n      <td>30.00</td>\n      <td>117786.00</td>\n      <td>117786.00</td>\n      <td>30.00</td>\n      <td>...</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>387606.00</td>\n      <td>378566.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>30.74</td>\n      <td>6.41</td>\n      <td>1118.19</td>\n      <td>2021006064.89</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.01</td>\n      <td>1.63</td>\n      <td>...</td>\n      <td>0.88</td>\n      <td>0.86</td>\n      <td>178.34</td>\n      <td>271.54</td>\n      <td>2.27</td>\n      <td>2.26</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.13</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>15.33</td>\n      <td>3.42</td>\n      <td>38.58</td>\n      <td>6383.75</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.08</td>\n      <td>0.49</td>\n      <td>...</td>\n      <td>0.32</td>\n      <td>0.34</td>\n      <td>691.29</td>\n      <td>1036.23</td>\n      <td>2.49</td>\n      <td>2.71</td>\n      <td>0.07</td>\n      <td>0.09</td>\n      <td>0.35</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1100.00</td>\n      <td>2021000001.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.00</td>\n      <td>3.00</td>\n      <td>1100.00</td>\n      <td>2021002091.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>57.00</td>\n      <td>114.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>31.00</td>\n      <td>6.00</td>\n      <td>1100.00</td>\n      <td>2021004338.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>167.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>41.00</td>\n      <td>9.00</td>\n      <td>1100.00</td>\n      <td>2021007674.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>200.00</td>\n      <td>229.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.00</td>\n      <td>12.00</td>\n      <td>1200.00</td>\n      <td>2021039095.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>19800.00</td>\n      <td>39600.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 245 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                    Data Frame Description                                                                               '''\n",
    "###############################################################################################################################################################################\n",
    "df_21.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(438693, 250)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                     Data Frame Shape                                                                                    '''\n",
    "###############################################################################################################################################################################\n",
    "df_21.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 3: Choose Feature Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color=white>We will first need to choose our feature space.  The five demographics provided will be the first on the list:\n",
    "<font color= red>\n",
    "* Age:  _AGE_G\n",
    "* Marital: MARITAL\n",
    "* Sex: _SEX\n",
    "* Income: INCOME2\n",
    "* Education: _EDUCAG\n",
    "\n",
    "<font color= white>\n",
    "Next we want to choose some features which we think will have some bearing on the response columns. We also want to pair the 250 features down to 20 (as per professor). Another demographic could be their race and city vs rural living as well as access to health care (insurance) and routine checkups:\n",
    "<br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Race: _RACE\n",
    "* Urban / Rural: _METSTAT\n",
    "* Health Care Access (Insurance): PRIMINSR &ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Health Insurance data not included in the data provided<font color= red>\n",
    "* Health Care Access (Routine checkup): CHECKUP1\n",
    "\n",
    "<font color= white>\n",
    "Also, we should also track physical activity, High blood pressure, High Cholesterol, smoking habits, drinking habits, BMI, kidney disease\n",
    "<br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Physical exersice: _TOTINDA\n",
    "* HBP: _RFHYPE6 &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Blood Pressure metrics not included in the data provided<font color= white><br>\n",
    "\n",
    "Instead we will use Currently taking blood pressure medication and Be very carefull with our clean up <br><font color= red>\n",
    "\n",
    "* High Cholesterol: _RFCHOL3 &ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Cholesterol metrics not included in the data provided<font color= red>\n",
    "* Four level smoker status: _SMOKER3\n",
    "* Number of drinks per week: _DRNKWK1&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total Fruit per Day: _FRUTSU1&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total Vegetables per Day: _VEGESU1&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total French Fry per Day: FRNCHDA_&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Body Mass Index: _BMI5&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Kidney Disease: CHCKDNY2\n",
    "\n",
    "<font color= white>\n",
    "The last demographic that Tony would like to include specifically is whether the participant is a veteran:\n",
    "br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Veteran Status: VETERAN3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(418268, 27)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                               Choosing Response and Features                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "df_19_trim = df_19.loc[:, ['ADDEPEV3', '_CASTHM1', 'CHCCOPD2', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3',\n",
    "                            'DIABETE4', '_AGE_G', 'MARITAL', '_SEX', 'INCOME2', '_EDUCAG', '_RACE', '_METSTAT', 'CHECKUP1',\n",
    "                            'BPMEDS', '_TOTINDA', '_SMOKER3', '_DRNKWK1', '_FRUTSU1', '_VEGESU1','FRNCHDA_', '_BMI5', \n",
    "                            'CHCKDNY2', 'VETERAN3']]\n",
    "df_19_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(438693, 27)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                               Choosing Response and Features                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "df_21_trim = df_21.loc[:, ['ADDEPEV3', '_CASTHM1', 'CHCCOPD3', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3',\n",
    "                            'DIABETE4', '_AGE_G', 'MARITAL', '_SEX', 'INCOME3', '_EDUCAG', '_RACE', '_METSTAT', 'CHECKUP1',\n",
    "                            'BPMEDS', '_TOTINDA', '_SMOKER3', '_DRNKWK1', '_FRUTSU1', '_VEGESU1','FRNCHDA_', '_BMI5', \n",
    "                            'CHCKDNY2', 'VETERAN3']]\n",
    "df_21_trim.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 4: Missing Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### BPMEDS\n",
    "From looking at the data itself, most of the missing values from BPMEDS is because the previous question answered something other than yes to every choice other than yes.  Therefore we can infer that these were a no and that 7 and 9 should be dropped.\n",
    "* 2021-\n",
    "- missing: 266,560 \n",
    "<br>vs<br>\n",
    "- Previous other than yes: 266,560\n",
    "\n",
    "there is only 0.26% which was I don't know or Refused\n",
    "\n",
    "* 2019-\n",
    "- missing: 248,634 \n",
    "<br>vs<br>\n",
    "- Previous other than yes: 248,634\n",
    "\n",
    "there is only 0.21% which was I don't know or Refused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 19 shape:\t (438693, 27)\n",
      "Original 21 shape:\t (438693, 27)\n",
      "Missing values by field (Pre-Interpolate):\n",
      "ADDEPEV3        10\n",
      "_CASTHM1         0\n",
      "CHCCOPD2         8\n",
      "CHCSCNCR         8\n",
      "CHCOCNCR         9\n",
      "CVDCRHD4         8\n",
      "CVDINFR4        10\n",
      "CVDSTRK3        11\n",
      "DIABETE4         9\n",
      "_AGE_G           0\n",
      "MARITAL         49\n",
      "_SEX             0\n",
      "INCOME2       6881\n",
      "_EDUCAG          0\n",
      "_RACE            3\n",
      "_METSTAT      8458\n",
      "CHECKUP1        10\n",
      "BPMEDS      248634\n",
      "_TOTINDA         0\n",
      "_SMOKER3         0\n",
      "_DRNKWK1         0\n",
      "_FRUTSU1     44600\n",
      "_VEGESU1     53430\n",
      "FRNCHDA_     38866\n",
      "_BMI5        36203\n",
      "CHCKDNY2        11\n",
      "VETERAN3      1374\n",
      "dtype: int64 \n",
      "\n",
      "ADDEPEV3         3\n",
      "_CASTHM1         0\n",
      "CHCCOPD3         3\n",
      "CHCSCNCR         2\n",
      "CHCOCNCR         3\n",
      "CVDCRHD4         2\n",
      "CVDINFR4         2\n",
      "CVDSTRK3         2\n",
      "DIABETE4         3\n",
      "_AGE_G           0\n",
      "MARITAL          5\n",
      "_SEX             0\n",
      "INCOME3       8847\n",
      "_EDUCAG          0\n",
      "_RACE            0\n",
      "_METSTAT      7054\n",
      "CHECKUP1         2\n",
      "BPMEDS      266560\n",
      "_TOTINDA         0\n",
      "_SMOKER3         0\n",
      "_DRNKWK1         0\n",
      "_FRUTSU1     51087\n",
      "_VEGESU1     60127\n",
      "FRNCHDA_     44765\n",
      "_BMI5        46852\n",
      "CHCKDNY2         3\n",
      "VETERAN3      1636\n",
      "dtype: int64 \n",
      "\n",
      "ADDEPEV3       10\n",
      "_CASTHM1        0\n",
      "CHCCOPD2        8\n",
      "CHCSCNCR        8\n",
      "CHCOCNCR        9\n",
      "CVDCRHD4        8\n",
      "CVDINFR4       10\n",
      "CVDSTRK3       11\n",
      "DIABETE4        9\n",
      "_AGE_G          0\n",
      "MARITAL        49\n",
      "_SEX            0\n",
      "INCOME2      6874\n",
      "_EDUCAG         0\n",
      "_RACE           3\n",
      "_METSTAT     8456\n",
      "CHECKUP1       10\n",
      "BPMEDS          0\n",
      "_TOTINDA        0\n",
      "_SMOKER3        0\n",
      "_DRNKWK1        0\n",
      "_FRUTSU1    44533\n",
      "_VEGESU1    53322\n",
      "FRNCHDA_    38804\n",
      "_BMI5       36145\n",
      "CHCKDNY2       11\n",
      "VETERAN3     1370\n",
      "dtype: int64 \n",
      "\n",
      "(417916, 27)\n",
      "ADDEPEV3        3\n",
      "_CASTHM1        0\n",
      "CHCCOPD3        3\n",
      "CHCSCNCR        2\n",
      "CHCOCNCR        3\n",
      "CVDCRHD4        2\n",
      "CVDINFR4        2\n",
      "CVDSTRK3        2\n",
      "DIABETE4        3\n",
      "_AGE_G          0\n",
      "MARITAL         5\n",
      "_SEX            0\n",
      "INCOME3      8841\n",
      "_EDUCAG         0\n",
      "_RACE           0\n",
      "_METSTAT     7052\n",
      "CHECKUP1        2\n",
      "BPMEDS          0\n",
      "_TOTINDA        0\n",
      "_SMOKER3        0\n",
      "_DRNKWK1        0\n",
      "_FRUTSU1    50980\n",
      "_VEGESU1    60000\n",
      "FRNCHDA_    44684\n",
      "_BMI5       46735\n",
      "CHCKDNY2        3\n",
      "VETERAN3     1635\n",
      "dtype: int64 \n",
      "\n",
      "(438234, 27)\n",
      "Final 19 shape:\t (330505, 27)\n",
      "Final 21 shape:\t (338998, 27)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Analyze, Clean, and Impute                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "## Print Original Shape for comparisson\n",
    "print('Original 19 shape:\\t', df_21_trim.shape)\n",
    "print('Original 21 shape:\\t', df_21_trim.shape)\n",
    "\n",
    "## Interpret and clean df\n",
    "# output how many NaN there is per column\n",
    "print('Missing values by field (Pre-Interpolate):')\n",
    "\n",
    "# Visualize the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "## Replace missing values in BPMEDS with No answer and drop 7 and 9 response as NAN\n",
    "df_19_trim = df_19_trim[df_19_trim['BPMEDS'] != 7] \n",
    "df_19_trim = df_19_trim[df_19_trim['BPMEDS'] != 9]\n",
    "df_19_trim['BPMEDS'].fillna(2, inplace= True) \n",
    "\n",
    "# How are we doing now\n",
    "print(df_19_trim.isnull().sum(), '\\n')\n",
    "print(df_19_trim.shape)\n",
    "\n",
    "# Drop the remaining NaN\n",
    "df_19_trim.dropna(inplace= True)\n",
    "\n",
    "\n",
    "## Replace missing values in BPMEDS with No answer and drop 7 and 9 response as NAN\n",
    "df_21_trim = df_21_trim[df_21_trim['BPMEDS'] != 7] \n",
    "df_21_trim = df_21_trim[df_21_trim['BPMEDS'] != 9]\n",
    "df_21_trim['BPMEDS'].fillna(2, inplace= True) \n",
    "\n",
    "# How are we doing now\n",
    "print(df_21_trim.isnull().sum(), '\\n')\n",
    "print(df_21_trim.shape)\n",
    "\n",
    "# Drop the remaining NaN\n",
    "df_21_trim.dropna(inplace= True)\n",
    "\n",
    "# Output final shape\n",
    "print('Final 19 shape:\\t', df_19_trim.shape)\n",
    "print('Final 21 shape:\\t', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create categorical columns\n",
    "\n",
    "- Column 1: Binary - indicates whether an individual has haf any of the chronic conditions. \n",
    "- Column 2: Multiclass - create a milticlass column with values that inidicate the total number of chronic conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 5: Binary and Multiclass Response Created"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>First we create the binaries for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression  ADDEPEV3\n",
      "0.00        2.00        264512\n",
      "1.00        1.00         64620\n",
      "dtype: int64\n",
      "1373\n",
      "2.00    264512\n",
      "1.00     64620\n",
      "7.00      1188\n",
      "9.00       185\n",
      "Name: ADDEPEV3, dtype: int64 \n",
      "\n",
      "Asthma  _CASTHM1\n",
      "1.00    1           297376\n",
      "0.00    2            30814\n",
      "dtype: int64\n",
      "2315\n",
      "1    297376\n",
      "2     30814\n",
      "9      2315\n",
      "Name: _CASTHM1, dtype: int64 \n",
      "\n",
      "COPD  CHCCOPD2\n",
      "0.00  2.00        300875\n",
      "1.00  1.00         28179\n",
      "dtype: int64\n",
      "1451\n",
      "2.00    300875\n",
      "1.00     28179\n",
      "7.00      1398\n",
      "9.00        53\n",
      "Name: CHCCOPD2, dtype: int64 \n",
      "\n",
      "Cancer  CHCSCNCR  CHCOCNCR\n",
      "0.00    2.00      2.00        267482\n",
      "1.00    1.00      2.00         26841\n",
      "        2.00      1.00         26565\n",
      "        1.00      1.00          8057\n",
      "0.00    7.00      2.00           660\n",
      "        2.00      7.00           509\n",
      "1.00    7.00      1.00           143\n",
      "        1.00      7.00            89\n",
      "0.00    2.00      9.00            58\n",
      "        9.00      2.00            13\n",
      "1.00    1.00      9.00            10\n",
      "        9.00      1.00             1\n",
      "dtype: int64\n",
      "77\n",
      "2.00    294614\n",
      "1.00     34997\n",
      "7.00       854\n",
      "9.00        40\n",
      "Name: CHCSCNCR, dtype: int64 \n",
      "\n",
      "2.00    294996\n",
      "1.00     34766\n",
      "7.00       649\n",
      "9.00        94\n",
      "Name: CHCOCNCR, dtype: int64 \n",
      "\n",
      "0.00    268722\n",
      "1.00     61706\n",
      "Name: Cancer, dtype: int64 \n",
      "\n",
      "Heart  CVDCRHD4  CVDINFR4  CVDSTRK3\n",
      "0.00   2.00      2.00      2.00        288581\n",
      "1.00   2.00      2.00      1.00          9184\n",
      "       1.00      2.00      2.00          8504\n",
      "       2.00      1.00      2.00          7671\n",
      "       1.00      1.00      2.00          6952\n",
      "                           1.00          1986\n",
      "       2.00      1.00      1.00          1719\n",
      "0.00   7.00      2.00      2.00          1345\n",
      "1.00   1.00      2.00      1.00          1196\n",
      "0.00   2.00      7.00      2.00           844\n",
      "1.00   7.00      1.00      2.00           724\n",
      "0.00   2.00      2.00      7.00           473\n",
      "1.00   7.00      2.00      1.00           194\n",
      "       1.00      7.00      2.00           186\n",
      "       7.00      1.00      1.00           174\n",
      "0.00   7.00      7.00      2.00           164\n",
      "1.00   2.00      7.00      1.00           139\n",
      "                 1.00      7.00            51\n",
      "       1.00      2.00      7.00            49\n",
      "                 7.00      1.00            47\n",
      "                 1.00      7.00            47\n",
      "0.00   2.00      7.00      7.00            44\n",
      "       7.00      2.00      7.00            33\n",
      "1.00   7.00      7.00      1.00            28\n",
      "                 1.00      7.00            21\n",
      "0.00   2.00      2.00      9.00            16\n",
      "       9.00      2.00      2.00            13\n",
      "       2.00      9.00      2.00            13\n",
      "1.00   1.00      7.00      7.00             8\n",
      "                 9.00      2.00             6\n",
      "       9.00      1.00      2.00             5\n",
      "                 2.00      1.00             5\n",
      "0.00   9.00      9.00      2.00             3\n",
      "                 2.00      9.00             3\n",
      "1.00   2.00      9.00      1.00             2\n",
      "       1.00      2.00      9.00             1\n",
      "       9.00      1.00      1.00             1\n",
      "       1.00      9.00      1.00             1\n",
      "       9.00      9.00      1.00             1\n",
      "dtype: int64\n",
      "71\n",
      "2.00    308737\n",
      "1.00     18983\n",
      "7.00      2733\n",
      "9.00        52\n",
      "Name: CVDCRHD4, dtype: int64 \n",
      "\n",
      "2.00    309597\n",
      "1.00     19351\n",
      "7.00      1511\n",
      "9.00        46\n",
      "Name: CVDINFR4, dtype: int64 \n",
      "\n",
      "2.00    315011\n",
      "1.00     14677\n",
      "7.00       775\n",
      "9.00        42\n",
      "Name: CVDSTRK3, dtype: int64 \n",
      "\n",
      "0.00    291532\n",
      "1.00     38902\n",
      "Name: Heart, dtype: int64 \n",
      "\n",
      "Diabetes  DIABETE4\n",
      "0.00      3.00        274993\n",
      "1.00      1.00         44992\n",
      "0.00      4.00          7239\n",
      "          2.00          2862\n",
      "dtype: int64\n",
      "419\n",
      "3.00    274993\n",
      "1.00     44992\n",
      "4.00      7239\n",
      "2.00      2862\n",
      "7.00       364\n",
      "9.00        55\n",
      "Name: DIABETE4, dtype: int64 \n",
      "\n",
      "   ADDEPEV3  _CASTHM1  CHCCOPD2  CHCSCNCR  CHCOCNCR  CVDCRHD4  CVDINFR4  \\\n",
      "0      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "1      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "2      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "4      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "6      2.00         2      1.00      2.00      2.00      2.00      2.00   \n",
      "\n",
      "   CVDSTRK3  DIABETE4  _AGE_G  ...  FRNCHDA_   _BMI5  CHCKDNY2  VETERAN3  \\\n",
      "0      2.00      3.00       6  ...     14.00 2817.00      2.00      2.00   \n",
      "1      2.00      3.00       6  ...      7.00 1854.00      2.00      2.00   \n",
      "2      2.00      1.00       6  ...      7.00 3162.00      2.00      2.00   \n",
      "4      2.00      3.00       6  ...      7.00 2148.00      2.00      2.00   \n",
      "6      2.00      1.00       6  ...     50.00 3298.00      2.00      2.00   \n",
      "\n",
      "   Depression  Asthma  COPD  Cancer  Heart  Diabetes  \n",
      "0        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "1        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "2        0.00    1.00  0.00    0.00   0.00      1.00  \n",
      "4        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "6        0.00    0.00  1.00    0.00   0.00      1.00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2019                                                                      '''\n",
    "###############################################################################################################################################################################\n",
    "## Binary Comorbidity Response Features from our respective responses\n",
    "# Create the Depression comorbidity variable\n",
    "df_19_trim['Depression'] = df_19_trim.apply(lambda row: 1 if row[0] == 1 else (0 if row[0] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['Depression', 'ADDEPEV3']].value_counts())\n",
    "print(df_19_trim['Depression'].isnull().sum())\n",
    "print(df_19_trim['ADDEPEV3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Asthma comorbidity variable\n",
    "df_19_trim['Asthma'] = df_19_trim.apply(lambda row: 1 if row[1] == 1 else (0 if row[1] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['Asthma', '_CASTHM1']].value_counts())\n",
    "print(df_19_trim['Asthma'].isnull().sum())\n",
    "print(df_19_trim['_CASTHM1'].value_counts(), '\\n')\n",
    "\n",
    "# Create the COPD comorbidity variable\n",
    "df_19_trim['COPD'] = df_19_trim.apply(lambda row: 1 if row[2] == 1 else (0 if row[2] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['COPD', 'CHCCOPD2']].value_counts())\n",
    "print(df_19_trim['COPD'].isnull().sum())\n",
    "print(df_19_trim['CHCCOPD2'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Cancer comorbidity variable\n",
    "df_19_trim['Cancer'] = df_19_trim.apply(lambda row: 1 if row[3] == 1 else (1 if row[4] == 1 else (0 if row[3] == 2 else ( 0 if row[4] == 2 else np.NAN))), axis=1)\n",
    "print(df_19_trim[['Cancer', 'CHCSCNCR', 'CHCOCNCR']].value_counts())\n",
    "print(df_19_trim['Cancer'].isnull().sum())\n",
    "print(df_19_trim['CHCSCNCR'].value_counts(), '\\n')\n",
    "print(df_19_trim['CHCOCNCR'].value_counts(), '\\n')\n",
    "print(df_19_trim['Cancer'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Heart Condition comorbidity variable\n",
    "df_19_trim['Heart'] = df_19_trim.apply(lambda row: 1 if row[5] == 1 else (1 if row[6] == 1 else (1 if row[7] == 1 else (0 if row[5] == 2 else (0 if row[6] == 2 else (0 if row[7] == 2 else np.NAN))))), axis=1)\n",
    "print(df_19_trim[['Heart', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3']].value_counts())\n",
    "print(df_19_trim['Heart'].isnull().sum())\n",
    "print(df_19_trim['CVDCRHD4'].value_counts(), '\\n')\n",
    "print(df_19_trim['CVDINFR4'].value_counts(), '\\n')\n",
    "print(df_19_trim['CVDSTRK3'].value_counts(), '\\n')\n",
    "print(df_19_trim['Heart'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Depression comorbidity variable\n",
    "df_19_trim['Diabetes'] = df_19_trim.apply(lambda row: 1 if row[8] == 1 else (0 if row[8] == 2 else (0 if row[8] == 3 else (0 if row[8] == 4 else np.NAN))), axis=1)\n",
    "print(df_19_trim[['Diabetes', 'DIABETE4']].value_counts())\n",
    "print(df_19_trim['Diabetes'].isnull().sum())\n",
    "print(df_19_trim['DIABETE4'].value_counts(), '\\n')\n",
    "\n",
    "print(df_19_trim.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Then we create the binaries for 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression  ADDEPEV3\n",
      "0.00        2.00        268786\n",
      "1.00        1.00         68765\n",
      "dtype: int64\n",
      "1447\n",
      "2.00    268786\n",
      "1.00     68765\n",
      "7.00      1183\n",
      "9.00       264\n",
      "Name: ADDEPEV3, dtype: int64 \n",
      "\n",
      "Asthma  _CASTHM1\n",
      "1.00    1.00        303552\n",
      "0.00    2.00         33089\n",
      "dtype: int64\n",
      "2357\n",
      "1.00    303552\n",
      "2.00     33089\n",
      "9.00      2357\n",
      "Name: _CASTHM1, dtype: int64 \n",
      "\n",
      "COPD  CHCCOPD3\n",
      "0.00  2.00        311016\n",
      "1.00  1.00         26759\n",
      "dtype: int64\n",
      "1223\n",
      "2.00    311016\n",
      "1.00     26759\n",
      "7.00      1157\n",
      "9.00        66\n",
      "Name: CHCCOPD3, dtype: int64 \n",
      "\n",
      "Cancer  CHCSCNCR  CHCOCNCR\n",
      "0.00    2.00      2.00        278474\n",
      "1.00    2.00      1.00         25632\n",
      "        1.00      2.00         25540\n",
      "                  1.00          7869\n",
      "0.00    7.00      2.00           588\n",
      "        2.00      7.00           468\n",
      "1.00    7.00      1.00           137\n",
      "        1.00      7.00            88\n",
      "0.00    2.00      9.00            56\n",
      "        9.00      2.00            17\n",
      "1.00    1.00      9.00            14\n",
      "        9.00      1.00             1\n",
      "dtype: int64\n",
      "114\n",
      "2.00    304630\n",
      "1.00     33511\n",
      "7.00       804\n",
      "9.00        53\n",
      "Name: CHCSCNCR, dtype: int64 \n",
      "\n",
      "2.00    304619\n",
      "1.00     33639\n",
      "7.00       635\n",
      "9.00       105\n",
      "Name: CHCOCNCR, dtype: int64 \n",
      "\n",
      "0.00    279603\n",
      "1.00     59281\n",
      "Name: Cancer, dtype: int64 \n",
      "\n",
      "Heart  CVDCRHD4  CVDINFR4  CVDSTRK3\n",
      "0.00   2.00      2.00      2.00        299147\n",
      "1.00   1.00      2.00      2.00          8565\n",
      "       2.00      2.00      1.00          8562\n",
      "                 1.00      2.00          7228\n",
      "       1.00      1.00      2.00          6611\n",
      "                           1.00          1651\n",
      "0.00   7.00      2.00      2.00          1419\n",
      "1.00   2.00      1.00      1.00          1403\n",
      "       1.00      2.00      1.00          1082\n",
      "0.00   2.00      7.00      2.00           824\n",
      "1.00   7.00      1.00      2.00           683\n",
      "0.00   2.00      2.00      7.00           510\n",
      "1.00   1.00      7.00      2.00           213\n",
      "       7.00      2.00      1.00           206\n",
      "                 1.00      1.00           165\n",
      "0.00   7.00      7.00      2.00           149\n",
      "1.00   2.00      7.00      1.00           108\n",
      "       1.00      1.00      7.00            50\n",
      "0.00   2.00      7.00      7.00            44\n",
      "1.00   1.00      7.00      1.00            42\n",
      "       2.00      1.00      7.00            40\n",
      "       1.00      2.00      7.00            35\n",
      "0.00   7.00      2.00      7.00            29\n",
      "       9.00      2.00      2.00            28\n",
      "1.00   7.00      7.00      1.00            23\n",
      "0.00   2.00      9.00      2.00            21\n",
      "1.00   1.00      7.00      7.00            20\n",
      "0.00   2.00      2.00      9.00            16\n",
      "1.00   7.00      1.00      7.00            12\n",
      "       1.00      9.00      2.00             7\n",
      "0.00   9.00      9.00      2.00             7\n",
      "1.00   1.00      1.00      9.00             3\n",
      "0.00   9.00      2.00      9.00             3\n",
      "       2.00      9.00      9.00             3\n",
      "1.00   2.00      9.00      1.00             2\n",
      "0.00   9.00      7.00      2.00             2\n",
      "1.00   9.00      1.00      2.00             2\n",
      "       2.00      1.00      9.00             1\n",
      "       9.00      1.00      9.00             1\n",
      "dtype: int64\n",
      "81\n",
      "2.00    317909\n",
      "1.00     18279\n",
      "7.00      2737\n",
      "9.00        73\n",
      "Name: CVDCRHD4, dtype: int64 \n",
      "\n",
      "2.00    319602\n",
      "1.00     17850\n",
      "7.00      1476\n",
      "9.00        70\n",
      "Name: CVDINFR4, dtype: int64 \n",
      "\n",
      "2.00    324906\n",
      "1.00     13244\n",
      "7.00       791\n",
      "9.00        57\n",
      "Name: CVDSTRK3, dtype: int64 \n",
      "\n",
      "0.00    302202\n",
      "1.00     36715\n",
      "Name: Heart, dtype: int64 \n",
      "\n",
      "Diabetes  DIABETE4\n",
      "0.00      3.00        283623\n",
      "1.00      1.00         44343\n",
      "0.00      4.00          7698\n",
      "          2.00          2920\n",
      "dtype: int64\n",
      "414\n",
      "3.00    283623\n",
      "1.00     44343\n",
      "4.00      7698\n",
      "2.00      2920\n",
      "7.00       350\n",
      "9.00        64\n",
      "Name: DIABETE4, dtype: int64 \n",
      "\n",
      "   ADDEPEV3  _CASTHM1  CHCCOPD3  CHCSCNCR  CHCOCNCR  CVDCRHD4  CVDINFR4  \\\n",
      "0      2.00      2.00      1.00      2.00      2.00      2.00      2.00   \n",
      "2      2.00      1.00      2.00      2.00      2.00      1.00      2.00   \n",
      "3      2.00      1.00      2.00      2.00      2.00      2.00      2.00   \n",
      "4      2.00      1.00      2.00      2.00      2.00      7.00      1.00   \n",
      "5      2.00      1.00      1.00      2.00      2.00      2.00      2.00   \n",
      "\n",
      "   CVDSTRK3  DIABETE4  _AGE_G  ...  FRNCHDA_   _BMI5  CHCKDNY2  VETERAN3  \\\n",
      "0      2.00      3.00    6.00  ...     43.00 1454.00      2.00      2.00   \n",
      "2      2.00      1.00    6.00  ...     14.00 2829.00      2.00      2.00   \n",
      "3      2.00      1.00    5.00  ...     57.00 3347.00      2.00      2.00   \n",
      "4      1.00      1.00    6.00  ...     29.00 2873.00      2.00      2.00   \n",
      "5      2.00      3.00    6.00  ...      0.00 2437.00      2.00      2.00   \n",
      "\n",
      "   Depression  Asthma  COPD  Cancer  Heart  Diabetes  \n",
      "0        0.00    0.00  1.00    0.00   0.00      0.00  \n",
      "2        0.00    1.00  0.00    0.00   1.00      1.00  \n",
      "3        0.00    1.00  0.00    0.00   0.00      1.00  \n",
      "4        0.00    1.00  0.00    0.00   1.00      1.00  \n",
      "5        0.00    1.00  1.00    0.00   0.00      0.00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2021                                                                      '''\n",
    "###############################################################################################################################################################################\n",
    "## Binary Comorbidity Response Features from our respective responses\n",
    "# Create the Depression comorbidity variable\n",
    "df_21_trim['Depression'] = df_21_trim.apply(lambda row: 1 if row[0] == 1 else (0 if row[0] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['Depression', 'ADDEPEV3']].value_counts())\n",
    "print(df_21_trim['Depression'].isnull().sum())\n",
    "print(df_21_trim['ADDEPEV3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Asthma comorbidity variable\n",
    "df_21_trim['Asthma'] = df_21_trim.apply(lambda row: 1 if row[1] == 1 else (0 if row[1] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['Asthma', '_CASTHM1']].value_counts())\n",
    "print(df_21_trim['Asthma'].isnull().sum())\n",
    "print(df_21_trim['_CASTHM1'].value_counts(), '\\n')\n",
    "\n",
    "# Create the COPD comorbidity variable\n",
    "df_21_trim['COPD'] = df_21_trim.apply(lambda row: 1 if row[2] == 1 else (0 if row[2] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['COPD', 'CHCCOPD3']].value_counts())\n",
    "print(df_21_trim['COPD'].isnull().sum())\n",
    "print(df_21_trim['CHCCOPD3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Cancer comorbidity variable\n",
    "df_21_trim['Cancer'] = df_21_trim.apply(lambda row: 1 if row[3] == 1 else (1 if row[4] == 1 else (0 if row[3] == 2 else ( 0 if row[4] == 2 else np.NAN))), axis=1)\n",
    "print(df_21_trim[['Cancer', 'CHCSCNCR', 'CHCOCNCR']].value_counts())\n",
    "print(df_21_trim['Cancer'].isnull().sum())\n",
    "print(df_21_trim['CHCSCNCR'].value_counts(), '\\n')\n",
    "print(df_21_trim['CHCOCNCR'].value_counts(), '\\n')\n",
    "print(df_21_trim['Cancer'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Heart Condition comorbidity variable\n",
    "df_21_trim['Heart'] = df_21_trim.apply(lambda row: 1 if row[5] == 1 else (1 if row[6] == 1 else (1 if row[7] == 1 else (0 if row[5] == 2 else (0 if row[6] == 2 else (0 if row[7] == 2 else np.NAN))))), axis=1)\n",
    "print(df_21_trim[['Heart', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3']].value_counts())\n",
    "print(df_21_trim['Heart'].isnull().sum())\n",
    "print(df_21_trim['CVDCRHD4'].value_counts(), '\\n')\n",
    "print(df_21_trim['CVDINFR4'].value_counts(), '\\n')\n",
    "print(df_21_trim['CVDSTRK3'].value_counts(), '\\n')\n",
    "print(df_21_trim['Heart'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Depression comorbidity variable\n",
    "df_21_trim['Diabetes'] = df_21_trim.apply(lambda row: 1 if row[8] == 1 else (0 if row[8] == 2 else (0 if row[8] == 3 else (0 if row[8] == 4 else np.NAN))), axis=1)\n",
    "print(df_21_trim[['Diabetes', 'DIABETE4']].value_counts())\n",
    "print(df_21_trim['Diabetes'].isnull().sum())\n",
    "print(df_21_trim['DIABETE4'].value_counts(), '\\n')\n",
    "\n",
    "print(df_21_trim.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Drop the coloumns no longer needed and any missing values introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_19_trim Original Shape_\t (330505, 33)\n",
      "df_19_trim New Shape_\t (325245, 24) \n",
      "\n",
      "df_21_trim Original Shape_\t (338998, 33)\n",
      "df_19_trim New Shape_\t (333899, 24)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Re-Clean Data fropm both years                                                                        '''\n",
    "###############################################################################################################################################################################\n",
    "## First we need to drop the columns we no longer need and then the new NaNs for 2019\n",
    "print('df_19_trim Original Shape_\\t', df_19_trim.shape)\n",
    "df_19_trim.drop(columns=['ADDEPEV3', '_CASTHM1', 'CHCCOPD2', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3', 'DIABETE4'], inplace=True)\n",
    "df_19_trim.dropna(inplace= True)\n",
    "print('df_19_trim New Shape_\\t', df_19_trim.shape, '\\n')\n",
    "\n",
    "## First we need to drop the columns we no longer need and then the new NaNs for 2021\n",
    "print('df_21_trim Original Shape_\\t', df_21_trim.shape)\n",
    "df_21_trim.drop(columns=['ADDEPEV3', '_CASTHM1', 'CHCCOPD3', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3', 'DIABETE4'], inplace=True)\n",
    "df_21_trim.dropna(inplace= True)\n",
    "print('df_19_trim New Shape_\\t', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Now we can move on to our last Comorbidity Variable for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2019/2021                                                                 '''\n",
    "###############################################################################################################################################################################\n",
    "## Multiclass Response from the Binary Comorbidities\n",
    "# First for 2019\n",
    "df_19_trim['Comorbidity'] = df_19_trim.apply(lambda row: 1 if row[18] == 1 else (1 if row[19] == 1 else (1 if row[20] == 1 else (1 if row[21] == 1 else (1 if row[22] == 1 else (1 if row[23] == 1 else 0))))), axis=1)\n",
    "\n",
    "# Then for 2021\n",
    "df_21_trim['Comorbidity'] = df_21_trim.apply(lambda row: 1 if row[18] == 1 else (1 if row[19] == 1 else (1 if row[20] == 1 else (1 if row[21] == 1 else (1 if row[22] == 1 else (1 if row[23] == 1 else 0))))), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 6: Make sure there are no NaNs left over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values by field (Pre-Interpolate):\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME3        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "Final Shapes:\n",
      " (325245, 25) \n",
      " (333899, 25)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                            Check for missing values again for 2019/2021                                                                 '''\n",
    "###############################################################################################################################################################################\n",
    "# output how many NaN there is per column\n",
    "print('Missing values by field (Pre-Interpolate):')\n",
    "\n",
    "# Visualize the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "# We can see that there is one column left in each that have a different name so let us fix this now\n",
    "df_21_trim = df_21_trim.rename(columns={'INCOME3': 'INCOME2'})\n",
    "\n",
    "# Recheck by visualizing the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "# Final shape of DF's\n",
    "print('Final Shapes:\\n', df_19_trim.shape, '\\n', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 6: Merge Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _AGE_G  MARITAL  _SEX  INCOME2  _EDUCAG  _RACE  _METSTAT  CHECKUP1  BPMEDS  \\\n0    6.00     2.00  2.00     3.00     1.00   2.00      1.00      1.00    1.00   \n1    6.00     1.00  2.00     5.00     3.00   1.00      1.00      1.00    2.00   \n2    6.00     3.00  2.00     7.00     4.00   2.00      1.00      1.00    1.00   \n4    6.00     1.00  2.00    99.00     3.00   1.00      2.00      1.00    2.00   \n6    6.00     2.00  1.00     7.00     4.00   1.00      2.00      1.00    2.00   \n\n   _TOTINDA  ...   _BMI5  CHCKDNY2  VETERAN3  Depression  Asthma  COPD  \\\n0      2.00  ... 2817.00      2.00      2.00        0.00    1.00  0.00   \n1      1.00  ... 1854.00      2.00      2.00        0.00    1.00  0.00   \n2      1.00  ... 3162.00      2.00      2.00        0.00    1.00  0.00   \n4      2.00  ... 2148.00      2.00      2.00        0.00    1.00  0.00   \n6      1.00  ... 3298.00      2.00      2.00        0.00    0.00  1.00   \n\n   Cancer  Heart  Diabetes  Comorbidity  \n0    0.00   0.00      0.00            1  \n1    0.00   0.00      0.00            1  \n2    0.00   0.00      1.00            1  \n4    0.00   0.00      0.00            1  \n6    0.00   0.00      1.00            1  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_AGE_G</th>\n      <th>MARITAL</th>\n      <th>_SEX</th>\n      <th>INCOME2</th>\n      <th>_EDUCAG</th>\n      <th>_RACE</th>\n      <th>_METSTAT</th>\n      <th>CHECKUP1</th>\n      <th>BPMEDS</th>\n      <th>_TOTINDA</th>\n      <th>...</th>\n      <th>_BMI5</th>\n      <th>CHCKDNY2</th>\n      <th>VETERAN3</th>\n      <th>Depression</th>\n      <th>Asthma</th>\n      <th>COPD</th>\n      <th>Cancer</th>\n      <th>Heart</th>\n      <th>Diabetes</th>\n      <th>Comorbidity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>2817.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>5.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1854.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>4.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3162.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>99.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>2148.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>7.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3298.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_19_trim, df_21_trim])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _AGE_G   MARITAL      _SEX   INCOME2   _EDUCAG     _RACE  _METSTAT  \\\ncount 659144.00 659144.00 659144.00 659144.00 659144.00 659144.00 659144.00   \nmean       4.42      2.31      1.53     18.67      3.06      1.97      1.31   \nstd        1.59      1.72      0.50     29.69      0.97      2.21      0.46   \nmin        1.00      1.00      1.00      1.00      1.00      1.00      1.00   \n25%        3.00      1.00      1.00      5.00      2.00      1.00      1.00   \n50%        5.00      1.00      2.00      7.00      3.00      1.00      1.00   \n75%        6.00      3.00      2.00      9.00      4.00      1.00      2.00   \nmax        6.00      9.00      2.00     99.00      9.00      9.00      2.00   \n\n       CHECKUP1    BPMEDS  _TOTINDA  ...     _BMI5  CHCKDNY2  VETERAN3  \\\ncount 659144.00 659144.00 659144.00  ... 659144.00 659144.00 659144.00   \nmean       1.43      1.67      1.25  ...   2847.10      1.97      1.88   \nstd        1.04      0.47      0.51  ...    647.48      0.33      0.41   \nmin        1.00      1.00      1.00  ...   1200.00      1.00      1.00   \n25%        1.00      1.00      1.00  ...   2412.00      2.00      2.00   \n50%        1.00      2.00      1.00  ...   2741.00      2.00      2.00   \n75%        1.00      2.00      1.00  ...   3162.00      2.00      2.00   \nmax        9.00      2.00      9.00  ...   9933.00      9.00      9.00   \n\n       Depression    Asthma      COPD    Cancer     Heart  Diabetes  \\\ncount   659144.00 659144.00 659144.00 659144.00 659144.00 659144.00   \nmean         0.20      0.90      0.08      0.18      0.11      0.13   \nstd          0.40      0.29      0.27      0.38      0.32      0.34   \nmin          0.00      0.00      0.00      0.00      0.00      0.00   \n25%          0.00      1.00      0.00      0.00      0.00      0.00   \n50%          0.00      1.00      0.00      0.00      0.00      0.00   \n75%          0.00      1.00      0.00      0.00      0.00      0.00   \nmax          1.00      1.00      1.00      1.00      1.00      1.00   \n\n       Comorbidity  \ncount    659144.00  \nmean          0.97  \nstd           0.18  \nmin           0.00  \n25%           1.00  \n50%           1.00  \n75%           1.00  \nmax           1.00  \n\n[8 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_AGE_G</th>\n      <th>MARITAL</th>\n      <th>_SEX</th>\n      <th>INCOME2</th>\n      <th>_EDUCAG</th>\n      <th>_RACE</th>\n      <th>_METSTAT</th>\n      <th>CHECKUP1</th>\n      <th>BPMEDS</th>\n      <th>_TOTINDA</th>\n      <th>...</th>\n      <th>_BMI5</th>\n      <th>CHCKDNY2</th>\n      <th>VETERAN3</th>\n      <th>Depression</th>\n      <th>Asthma</th>\n      <th>COPD</th>\n      <th>Cancer</th>\n      <th>Heart</th>\n      <th>Diabetes</th>\n      <th>Comorbidity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>...</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.42</td>\n      <td>2.31</td>\n      <td>1.53</td>\n      <td>18.67</td>\n      <td>3.06</td>\n      <td>1.97</td>\n      <td>1.31</td>\n      <td>1.43</td>\n      <td>1.67</td>\n      <td>1.25</td>\n      <td>...</td>\n      <td>2847.10</td>\n      <td>1.97</td>\n      <td>1.88</td>\n      <td>0.20</td>\n      <td>0.90</td>\n      <td>0.08</td>\n      <td>0.18</td>\n      <td>0.11</td>\n      <td>0.13</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.59</td>\n      <td>1.72</td>\n      <td>0.50</td>\n      <td>29.69</td>\n      <td>0.97</td>\n      <td>2.21</td>\n      <td>0.46</td>\n      <td>1.04</td>\n      <td>0.47</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>647.48</td>\n      <td>0.33</td>\n      <td>0.41</td>\n      <td>0.40</td>\n      <td>0.29</td>\n      <td>0.27</td>\n      <td>0.38</td>\n      <td>0.32</td>\n      <td>0.34</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1200.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>2412.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>2741.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3162.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>99.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>9933.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(659144, 25)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= white>The final Data Frames have the following Response Columns<font color= red>\n",
    "\n",
    "* Depression\n",
    "* Asthma\n",
    "* COPD\n",
    "* Cancer\n",
    "* Heart\n",
    "* Diabetes\n",
    "* Comorbidity\n",
    "\n",
    "<font color=white>And the following Feature Space<font color= red>\n",
    "\n",
    "* _AGE_G\n",
    "* MARITAL\n",
    "* _SEX\n",
    "* INCOME2\n",
    "* _EDUCAG\n",
    "* _RACE\n",
    "* _METSTAT\n",
    "* CHECKUP1\n",
    "* BPMEDS\n",
    "* _TOTINDA\n",
    "* _SMOKER3\n",
    "* _DRNKWK1\n",
    "* _FRUTSU1\n",
    "* _VEGESU1\n",
    "* FRNCHDA_\n",
    "* _BMI5\n",
    "* CHCKDNY2\n",
    "* VETERAN3\n",
    "\n",
    "<font color=white>The shapes of the different Dat Frames are as follows:<font color= red>\n",
    "\n",
    "1. 2019: <br>\n",
    "325245, 25<br><br>\n",
    "2. 2021: <br>\n",
    "333899, 25<br><br>\n",
    "3. Merged: <br>\n",
    "659144, 25<br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis 1\n",
    "Using both years, run exploratory data analysis using crosstabs, visuals, and basic frequency distributions to understand how chronic conditions are distribituted across geography and demography. You may also use the newly created comorbidity variables for this analysis. \n",
    "\n",
    "- Summarize salient features of the healthiest and least healthy states in the country.\n",
    "- Discuss if you noticed any associations of the risk factors such as Age, Sex, Income, Education, Marital Status etc. with the level of comorbidities, while comparing the two years of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis 2\n",
    "1. Using only 2021, use several classification algorithms to classify comorbility variables 1 and 2:\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- RF\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "- Catboost\n",
    "\n",
    "2. Write a short report describing the performance metrics. \n",
    "3. In the end, choose one model each for the classification of both categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Packages Used"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Test Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature space size:  (333899, 18) \n",
      "\n",
      "Response size:\n",
      "Binary:  (333899, 6)\n",
      "Multi:  (333899, 1) \n",
      "\n",
      "Train set for  Depression (479453, 18)\n",
      "Train set for  Asthma (542296, 18)\n",
      "Train set for  COPD (554112, 18)\n",
      "Train set for  Cancer (495964, 18)\n",
      "Train set for  Heart (536263, 18)\n",
      "Train set for  Diabetes (522509, 18)\n",
      "Train set for multi case (581113, 18)\n"
     ]
    }
   ],
   "source": [
    "# Get feature space and response\n",
    "binary = ['Depression', 'Asthma', 'COPD', 'Cancer', 'Heart', 'Diabetes']\n",
    "multi = ['Comorbidity']\n",
    "\n",
    "# Feature space\n",
    "X = df_21_trim.copy()\n",
    "X.drop(binary, inplace=True, axis=1)\n",
    "X.drop(multi, inplace=True, axis=1)\n",
    "print('Feature space size: ', X.shape, '\\n')\n",
    "\n",
    "# Standarize\n",
    "std = ['_DRNKWK1', '_FRUTSU1', '_VEGESU1', 'FRNCHDA_', '_BMI5']\n",
    "scalar = StandardScaler()\n",
    "X[std] = scalar.fit_transform(X[std])\n",
    "\n",
    "# Response\n",
    "y_binary = df_21_trim[binary].copy()\n",
    "y_multi = df_21_trim[multi].copy()\n",
    "print('Response size:')\n",
    "print('Binary: ', y_binary.shape)\n",
    "print('Multi: ', y_multi.shape, '\\n')\n",
    "\n",
    "# Over sample\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "# Train Test Split\n",
    "# Since we have many rows, 10% test is enough.\n",
    "# Responses are highly imbalanced, so we over sample for each response.\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = {}, {}, {}, {}\n",
    "for response in binary:\n",
    "    # Over sample for each response.\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled_binary, y_resampled_binary = ros.fit_resample(X, y_binary[response])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled_binary, y_resampled_binary, test_size=0.1, random_state=42)\n",
    "    X_train_binary[response] = X_train.reset_index(drop=True)\n",
    "    X_test_binary[response] = X_test.reset_index(drop=True)\n",
    "    y_train_binary[response] = y_train.reset_index(drop=True)\n",
    "    y_test_binary[response] = y_test.reset_index(drop=True)\n",
    "    print('Train set for ', response, X_train.shape)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled_multi, y_resampled_multi = ros.fit_resample(X, y_multi)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_resampled_multi, y_resampled_multi, test_size=0.1, random_state=42)\n",
    "X_train_multi.reset_index(inplace=True, drop=True)\n",
    "X_test_multi.reset_index(inplace=True, drop=True)\n",
    "y_train_multi.reset_index(inplace=True, drop=True)\n",
    "y_test_multi.reset_index(inplace=True, drop=True)\n",
    "print('Train set for multi case', X_train_multi.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistic Regresison"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.65      0.64     26722\n",
      "         1.0       0.64      0.62      0.63     26551\n",
      "\n",
      "    accuracy                           0.64     53273\n",
      "   macro avg       0.64      0.64      0.64     53273\n",
      "weighted avg       0.64      0.64      0.64     53273\n",
      "\n",
      "Best parameters are:  {'C': 1}\n",
      "Best score on train set is:  0.6354637501815812\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       17454  10095\n",
      "1.00        9268  16456\n",
      "\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.59      0.60     30197\n",
      "         1.0       0.60      0.62      0.61     30059\n",
      "\n",
      "    accuracy                           0.61     60256\n",
      "   macro avg       0.61      0.61      0.61     60256\n",
      "weighted avg       0.61      0.61      0.61     60256\n",
      "\n",
      "Best parameters are:  {'C': 0.001}\n",
      "Best score on train set is:  0.607242175691469\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       17786  11289\n",
      "1.00       12411  18770\n",
      "\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.70      0.72     30786\n",
      "         1.0       0.72      0.75      0.73     30782\n",
      "\n",
      "    accuracy                           0.73     61568\n",
      "   macro avg       0.73      0.73      0.73     61568\n",
      "weighted avg       0.73      0.73      0.73     61568\n",
      "\n",
      "Best parameters are:  {'C': 0.01}\n",
      "Best score on train set is:  0.7282968037686393\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       21674   7603\n",
      "1.00        9112  23179\n",
      "\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.62      0.67     27421\n",
      "         1.0       0.68      0.79      0.73     27687\n",
      "\n",
      "    accuracy                           0.70     55108\n",
      "   macro avg       0.71      0.70      0.70     55108\n",
      "weighted avg       0.71      0.70      0.70     55108\n",
      "\n",
      "Best parameters are:  {'C': 0.01}\n",
      "Best score on train set is:  0.702915935564031\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       16867   5742\n",
      "1.00       10554  21945\n",
      "\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71     29754\n",
      "         1.0       0.71      0.77      0.74     29831\n",
      "\n",
      "    accuracy                           0.73     59585\n",
      "   macro avg       0.73      0.73      0.72     59585\n",
      "weighted avg       0.73      0.73      0.72     59585\n",
      "\n",
      "Best parameters are:  {'C': 0.001}\n",
      "Best score on train set is:  0.7256290291906105\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       20095   6719\n",
      "1.00        9659  23112\n",
      "\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.70      0.72     29116\n",
      "         1.0       0.71      0.76      0.74     28941\n",
      "\n",
      "    accuracy                           0.73     58057\n",
      "   macro avg       0.73      0.73      0.73     58057\n",
      "weighted avg       0.73      0.73      0.73     58057\n",
      "\n",
      "Best parameters are:  {'C': 0.001}\n",
      "Best score on train set is:  0.7287032316182762\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       20338   6985\n",
      "1.00        8778  21956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "lgr = LogisticRegression(random_state=42,\n",
    "                         class_weight='balanced')\n",
    "parameters = {\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "# Grid search for 5 reponses\n",
    "for response in binary:\n",
    "    clf = GridSearchCV(lgr, param_grid=parameters)\n",
    "    clf.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = clf.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print('Best parameters are: ', clf.best_params_)\n",
    "    print('Best score on train set is: ', clf.best_score_)\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61     32363\n",
      "           1       0.61      0.61      0.61     32206\n",
      "\n",
      "    accuracy                           0.61     64569\n",
      "   macro avg       0.61      0.61      0.61     64569\n",
      "weighted avg       0.61      0.61      0.61     64569\n",
      "\n",
      "Best parameters are:  {'C': 1}\n",
      "Best score on train set is:  0.6092343494889769\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          19673  12628\n",
      "1          12690  19578\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "lgr = LogisticRegression(random_state=42,\n",
    "                         class_weight='balanced')\n",
    "parameters = {\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "# Grid search for multi response\n",
    "clf = GridSearchCV(lgr, param_grid=parameters)\n",
    "clf.fit(X_train_multi, y_train_multi)\n",
    "y_predict = clf.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print('Best parameters are: ', clf.best_params_)\n",
    "print('Best score on train set is: ', clf.best_score_)\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.38      0.41     26722\n",
      "         1.0       0.46      0.52      0.49     26551\n",
      "\n",
      "    accuracy                           0.45     53273\n",
      "   macro avg       0.45      0.45      0.45     53273\n",
      "weighted avg       0.45      0.45      0.45     53273\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          10253  12646\n",
      "1          16469  13905\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.46      0.50     30197\n",
      "         1.0       0.53      0.61      0.57     30059\n",
      "\n",
      "    accuracy                           0.54     60256\n",
      "   macro avg       0.54      0.54      0.54     60256\n",
      "weighted avg       0.54      0.54      0.54     60256\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          14035  11667\n",
      "1          16162  18392\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.42      0.54     30786\n",
      "         1.0       0.59      0.85      0.70     30782\n",
      "\n",
      "    accuracy                           0.64     61568\n",
      "   macro avg       0.67      0.64      0.62     61568\n",
      "weighted avg       0.67      0.64      0.62     61568\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          12928   4549\n",
      "1          17858  26233\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.45      0.55     27421\n",
      "         1.0       0.60      0.83      0.70     27687\n",
      "\n",
      "    accuracy                           0.64     55108\n",
      "   macro avg       0.66      0.64      0.63     55108\n",
      "weighted avg       0.66      0.64      0.63     55108\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          12352   4831\n",
      "1          15069  22856\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.43      0.57     29754\n",
      "         1.0       0.61      0.90      0.73     29831\n",
      "\n",
      "    accuracy                           0.67     59585\n",
      "   macro avg       0.71      0.67      0.65     59585\n",
      "weighted avg       0.71      0.67      0.65     59585\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          12908   2973\n",
      "1          16846  26858\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.43      0.53     29116\n",
      "         1.0       0.59      0.81      0.68     28941\n",
      "\n",
      "    accuracy                           0.62     58057\n",
      "   macro avg       0.64      0.62      0.61     58057\n",
      "weighted avg       0.64      0.62      0.61     58057\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          12477   5369\n",
      "1          16639  23572\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size=10)\n",
    "\n",
    "# Train and test for 5 reponses\n",
    "for response in binary:\n",
    "    knn.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = clf.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     32363\n",
      "           1       1.00      0.90      0.95     32206\n",
      "\n",
      "    accuracy                           0.95     64569\n",
      "   macro avg       0.95      0.95      0.95     64569\n",
      "weighted avg       0.95      0.95      0.95     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          32363   3316\n",
      "1              0  28890\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size=10)\n",
    "\n",
    "\n",
    "# Train and test for multi response\n",
    "knn.fit(X_train_multi, y_train_multi)\n",
    "y_predict = knn.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.96     26722\n",
      "         1.0       0.94      0.98      0.96     26551\n",
      "\n",
      "    accuracy                           0.96     53273\n",
      "   macro avg       0.96      0.96      0.96     53273\n",
      "weighted avg       0.96      0.96      0.96     53273\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       24958    460\n",
      "1.00        1764  26091\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     30197\n",
      "         1.0       1.00      0.99      1.00     30059\n",
      "\n",
      "    accuracy                           1.00     60256\n",
      "   macro avg       1.00      1.00      1.00     60256\n",
      "weighted avg       1.00      1.00      1.00     60256\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       30188    166\n",
      "1.00           9  29893\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     30786\n",
      "         1.0       0.98      1.00      0.99     30782\n",
      "\n",
      "    accuracy                           0.99     61568\n",
      "   macro avg       0.99      0.99      0.99     61568\n",
      "weighted avg       0.99      0.99      0.99     61568\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       30297      0\n",
      "1.00         489  30782\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.96     27421\n",
      "         1.0       0.93      0.99      0.96     27687\n",
      "\n",
      "    accuracy                           0.96     55108\n",
      "   macro avg       0.96      0.96      0.96     55108\n",
      "weighted avg       0.96      0.96      0.96     55108\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       25280    212\n",
      "1.00        2141  27475\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98     29754\n",
      "         1.0       0.97      1.00      0.98     29831\n",
      "\n",
      "    accuracy                           0.98     59585\n",
      "   macro avg       0.98      0.98      0.98     59585\n",
      "weighted avg       0.98      0.98      0.98     59585\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       28818      7\n",
      "1.00         936  29824\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97     29116\n",
      "         1.0       0.95      1.00      0.97     28941\n",
      "\n",
      "    accuracy                           0.97     58057\n",
      "   macro avg       0.97      0.97      0.97     58057\n",
      "weighted avg       0.97      0.97      0.97     58057\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       27596     32\n",
      "1.00        1520  28909\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "rf = RandomForestClassifier(n_jobs=5)\n",
    "\n",
    "\n",
    "# Train and test for 5 reponses\n",
    "for response in binary:\n",
    "    rf.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = rf.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     32363\n",
      "           1       1.00      1.00      1.00     32206\n",
      "\n",
      "    accuracy                           1.00     64569\n",
      "   macro avg       1.00      1.00      1.00     64569\n",
      "weighted avg       1.00      1.00      1.00     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          32363      4\n",
      "1              0  32202\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "rf = RandomForestClassifier(n_jobs=5)\n",
    "\n",
    "# Train and test for multi response\n",
    "rf.fit(X_train_multi, y_train_multi)\n",
    "y_predict = rf.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.69      0.67     26722\n",
      "         1.0       0.67      0.63      0.65     26551\n",
      "\n",
      "    accuracy                           0.66     53273\n",
      "   macro avg       0.66      0.66      0.66     53273\n",
      "weighted avg       0.66      0.66      0.66     53273\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       18408   9757\n",
      "1.00        8314  16794\n",
      "\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.57      0.60     30197\n",
      "         1.0       0.61      0.67      0.64     30059\n",
      "\n",
      "    accuracy                           0.62     60256\n",
      "   macro avg       0.62      0.62      0.62     60256\n",
      "weighted avg       0.62      0.62      0.62     60256\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       17222   9853\n",
      "1.00       12975  20206\n",
      "\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75     30786\n",
      "         1.0       0.75      0.76      0.75     30782\n",
      "\n",
      "    accuracy                           0.75     61568\n",
      "   macro avg       0.75      0.75      0.75     61568\n",
      "weighted avg       0.75      0.75      0.75     61568\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       22821   7349\n",
      "1.00        7965  23433\n",
      "\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.63      0.69     27421\n",
      "         1.0       0.69      0.79      0.74     27687\n",
      "\n",
      "    accuracy                           0.71     55108\n",
      "   macro avg       0.72      0.71      0.71     55108\n",
      "weighted avg       0.72      0.71      0.71     55108\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       17392   5702\n",
      "1.00       10029  21985\n",
      "\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72     29754\n",
      "         1.0       0.72      0.80      0.76     29831\n",
      "\n",
      "    accuracy                           0.74     59585\n",
      "   macro avg       0.74      0.74      0.74     59585\n",
      "weighted avg       0.74      0.74      0.74     59585\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       20226   5925\n",
      "1.00        9528  23906\n",
      "\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74     29116\n",
      "         1.0       0.73      0.79      0.76     28941\n",
      "\n",
      "    accuracy                           0.75     58057\n",
      "   macro avg       0.75      0.75      0.75     58057\n",
      "weighted avg       0.75      0.75      0.75     58057\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       20615   6075\n",
      "1.00        8501  22866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Train and test for 5 reponses\n",
    "for response in binary:\n",
    "    gbc.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = gbc.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.64     32363\n",
      "           1       0.64      0.58      0.61     32206\n",
      "\n",
      "    accuracy                           0.63     64569\n",
      "   macro avg       0.63      0.63      0.63     64569\n",
      "weighted avg       0.63      0.63      0.63     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          21880  13636\n",
      "1          10483  18570\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Train and test for multi response\n",
    "gbc.fit(X_train_multi, y_train_multi)\n",
    "y_predict = gbc.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.70      0.68     26722\n",
      "         1.0       0.68      0.65      0.67     26551\n",
      "\n",
      "    accuracy                           0.68     53273\n",
      "   macro avg       0.68      0.68      0.68     53273\n",
      "weighted avg       0.68      0.68      0.68     53273\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          18685   9185\n",
      "1           8037  17366\n",
      "\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.61      0.64     30197\n",
      "         1.0       0.64      0.71      0.67     30059\n",
      "\n",
      "    accuracy                           0.66     60256\n",
      "   macro avg       0.66      0.66      0.66     60256\n",
      "weighted avg       0.66      0.66      0.66     60256\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          18443   8850\n",
      "1          11754  21209\n",
      "\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.76      0.78     30786\n",
      "         1.0       0.77      0.79      0.78     30782\n",
      "\n",
      "    accuracy                           0.78     61568\n",
      "   macro avg       0.78      0.78      0.78     61568\n",
      "weighted avg       0.78      0.78      0.78     61568\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          23527   6361\n",
      "1           7259  24421\n",
      "\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.65      0.70     27421\n",
      "         1.0       0.70      0.81      0.75     27687\n",
      "\n",
      "    accuracy                           0.73     55108\n",
      "   macro avg       0.73      0.73      0.72     55108\n",
      "weighted avg       0.73      0.73      0.72     55108\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          17722   5371\n",
      "1           9699  22316\n",
      "\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.68      0.74     29754\n",
      "         1.0       0.72      0.83      0.77     29831\n",
      "\n",
      "    accuracy                           0.76     59585\n",
      "   macro avg       0.76      0.76      0.76     59585\n",
      "weighted avg       0.76      0.76      0.76     59585\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          20334   5017\n",
      "1           9420  24814\n",
      "\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.70      0.75     29116\n",
      "         1.0       0.73      0.82      0.77     28941\n",
      "\n",
      "    accuracy                           0.76     58057\n",
      "   macro avg       0.76      0.76      0.76     58057\n",
      "weighted avg       0.76      0.76      0.76     58057\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0          20511   5260\n",
      "1           8605  23681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "xbc = xgb.XGBClassifier(n_estimators=100,\n",
    "\t\t\t\t\t\tmax_depth=10,\n",
    "\t\t\t\t\t\teta=0.01,\n",
    "\t\t\t\t\t\tmin_child_weight=5,\n",
    "\t\t\t\t\t\trandom_state=100)\n",
    "\n",
    "# Train and test for 5 reponses\n",
    "for response in binary:\n",
    "    xbc.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = xbc.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73     32363\n",
      "           1       0.75      0.61      0.67     32206\n",
      "\n",
      "    accuracy                           0.70     64569\n",
      "   macro avg       0.71      0.70      0.70     64569\n",
      "weighted avg       0.71      0.70      0.70     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          25720  12630\n",
      "1           6643  19576\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "xbg = xgb.XGBClassifier(n_estimators=100,\n",
    "\t\t\t\t\t\tmax_depth=10,\n",
    "\t\t\t\t\t\teta=0.01,\n",
    "\t\t\t\t\t\tmin_child_weight=5,\n",
    "\t\t\t\t\t\trandom_state=100)\n",
    "\n",
    "# Train and test for multi response\n",
    "xbg.fit(X_train_multi, y_train_multi)\n",
    "y_predict = xbg.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6678843\ttotal: 16.8ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.6509854\ttotal: 29.1ms\tremaining: 0us\n",
      "For the response  Depression , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.70      0.65     26722\n",
      "         1.0       0.64      0.54      0.59     26551\n",
      "\n",
      "    accuracy                           0.62     53273\n",
      "   macro avg       0.62      0.62      0.62     53273\n",
      "weighted avg       0.62      0.62      0.62     53273\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       18704  12242\n",
      "1.00        8018  14309\n",
      "\n",
      "0:\tlearn: 0.6696567\ttotal: 19.5ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.6641108\ttotal: 36.6ms\tremaining: 0us\n",
      "For the response  Asthma , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.59      0.59     30197\n",
      "         1.0       0.59      0.60      0.60     30059\n",
      "\n",
      "    accuracy                           0.60     60256\n",
      "   macro avg       0.60      0.60      0.60     60256\n",
      "weighted avg       0.60      0.60      0.60     60256\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       17887  12073\n",
      "1.00       12310  17986\n",
      "\n",
      "0:\tlearn: 0.5895388\ttotal: 15.8ms\tremaining: 15.8ms\n",
      "1:\tlearn: 0.5592174\ttotal: 29.2ms\tremaining: 0us\n",
      "For the response  COPD , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.70      0.72     30786\n",
      "         1.0       0.71      0.75      0.73     30782\n",
      "\n",
      "    accuracy                           0.72     61568\n",
      "   macro avg       0.72      0.72      0.72     61568\n",
      "weighted avg       0.72      0.72      0.72     61568\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       21528   7781\n",
      "1.00        9258  23001\n",
      "\n",
      "0:\tlearn: 0.5933598\ttotal: 16.7ms\tremaining: 16.7ms\n",
      "1:\tlearn: 0.5780439\ttotal: 28.3ms\tremaining: 0us\n",
      "For the response  Cancer , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.56      0.65     27421\n",
      "         1.0       0.66      0.84      0.74     27687\n",
      "\n",
      "    accuracy                           0.70     55108\n",
      "   macro avg       0.72      0.70      0.70     55108\n",
      "weighted avg       0.72      0.70      0.70     55108\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       15447   4332\n",
      "1.00       11974  23355\n",
      "\n",
      "0:\tlearn: 0.5818770\ttotal: 17.1ms\tremaining: 17.1ms\n",
      "1:\tlearn: 0.5647177\ttotal: 29.4ms\tremaining: 0us\n",
      "For the response  Heart , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.63      0.68     29754\n",
      "         1.0       0.68      0.78      0.73     29831\n",
      "\n",
      "    accuracy                           0.71     59585\n",
      "   macro avg       0.71      0.71      0.70     59585\n",
      "weighted avg       0.71      0.71      0.70     59585\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       18715   6512\n",
      "1.00       11039  23319\n",
      "\n",
      "0:\tlearn: 0.5882346\ttotal: 13.2ms\tremaining: 13.2ms\n",
      "1:\tlearn: 0.5567083\ttotal: 25.6ms\tremaining: 0us\n",
      "For the response  Diabetes , classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72     29116\n",
      "         1.0       0.72      0.72      0.72     28941\n",
      "\n",
      "    accuracy                           0.72     58057\n",
      "   macro avg       0.72      0.72      0.72     58057\n",
      "weighted avg       0.72      0.72      0.72     58057\n",
      "\n",
      "y_test      0.00   1.00\n",
      "y_predict              \n",
      "0.00       20841   8068\n",
      "1.00        8275  20873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "cbc = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "\n",
    "# Train and test for 5 reponses\n",
    "for response in binary:\n",
    "    cbc.fit(X_train_binary[response], y_train_binary[response])\n",
    "    y_predict = cbc.predict(X_test_binary[response])\n",
    "    print('For the response ', response, ', classification report on test set is:')\n",
    "    print(classification_report(y_test_binary[response], y_predict))\n",
    "    print(pd.crosstab(y_predict, y_test_binary[response], rownames=['y_predict'], colnames=['y_test']))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6711616\ttotal: 18.8ms\tremaining: 18.8ms\n",
      "1:\tlearn: 0.6655812\ttotal: 31ms\tremaining: 0us\n",
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64     32363\n",
      "           1       0.63      0.50      0.55     32206\n",
      "\n",
      "    accuracy                           0.60     64569\n",
      "   macro avg       0.61      0.60      0.60     64569\n",
      "weighted avg       0.60      0.60      0.60     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          22763  16174\n",
      "1           9600  16032\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "cbc = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "\n",
    "# Train and test for multi response\n",
    "cbc.fit(X_train_multi, y_train_multi)\n",
    "y_predict = cbc.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis 2 Report\n",
    "\n",
    "At first, I was trying to use a single train set and test set for all those chronic conditions and all models. But when I finished running those models, the performance on each condition is really poor that the model tend to predict most samples into one class. The multiclass case is even worse that actually all test cases are classified as 0 for all models.\n",
    "\n",
    "The reason is that the classes are highly imbalanced for each chronic condition since only a small population has those conditions. Moreover, the population who have each condition is different from each other. So I over sampled for each condition, and over sampled again for the multiclass case. The resulting performance is then improved dramatically.\n",
    "\n",
    "There are 5 features with a large range, `'_DRNKWK1', '_FRUTSU1', '_VEGESU1', 'FRNCHDA_', '_BMI5'`, that may affect the performance. So standardization is applied to those features. All other features have small range with 10, all they are categorical, so the rest are kept unchanged. The resulting performance is then slightly improved.\n",
    "\n",
    "The test accuracy for Logistic Regression ranges from 0.61 to 0.73 for binary cases, and is 0.61 for the multiclass case. KNN has poorer performance for the binary cases ranging from 0.45 to 0.67. But in multiclass situation, it archives 0.95 accuracy which is a huge improvement. Random Forest has accuracy from 0.96 to 1.00 on binary cases and archives 1.00 accuracy on the multiclass situation. Scores of Gradient Boost is from 0.62 to 0.75 for binary and 0.63 for the multiclass case. XGBoost has accuracy for binary cases from 0.66 to 0.78 and 0.70 for multiclass case. CatBoost has accuracy for binary cases from 0.60 to 0.72 and 0.60 for multiclass case.\n",
    "\n",
    "Among those models random forest would be chosen as the model for classification because of its impressive performance. KNN could also be used for classify the multiclass category as it has a relative high score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}