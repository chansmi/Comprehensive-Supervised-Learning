{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW6 Comprehensive Supervised Learning\n",
    "Contributors: Zongyu Wu, Tony Wilson, Chandler Smith\n",
    "\n",
    "Summary: The overall purpose of this assignment is to tie together a variety of supervised learning techniques in order to appropriately analyze several questions related to the Behavioral Risk Factor Surveillance System. More specifically, the goal is to use supervised ML to identify patterns of comorbidity among the survey respondents. This is a comparative exercise focusing on pre (2019) and post (2021) covid health. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notes from discussion:\n",
    "\n",
    "Approach: One approach for understanding behavioral factors behind comorbidity is to apply classification algorithms to the BRFSS data. Such algorithms can be trained to predict whether an individual has multiple chronic conditions based on their responses to the survey questions. By analyzing the features that are most important for predicting comorbidity, one can identify risk factors and inform the development of targeted prevention and intervention strategies.\n",
    "\n",
    "Response related:\n",
    "Depression = ADDEPEV3\n",
    " Ever told Asthma = _CASTHM1\n",
    " COPD = (CHCCOPD2 for 2019 and CHCCOPD3 for 2021)\n",
    " Cancer = (combine CHCSCNCR and CHCOCNCR)\n",
    " Ever told Heart Condition = combination of CVDCRHD4, CVDINFR4 and CVDSTRK3\n",
    " Diabetes = DIABETE4\n",
    " \n",
    "\n",
    "Key demographic features:\n",
    "Age: _AGE_G\n",
    " Marital: MARITAL\n",
    " Sex: _SEX\n",
    " Income: INCOME2\n",
    " Education: _EDUCAG\n",
    "\n",
    "- Do NOT refer to correlation\n",
    "- BRFSS data can be used to understand comorbidity, which refers to the presence of multiple chronic conditions in an individual. \n",
    "- RFSS uses a complex sampling and weighting scheme to measure prevalence of many health conditions, behavioral and lifestyle related risk factors and emerging health issues in states. \n",
    "- Do not use the weight variable as we are conducting estimations. \n",
    "\n",
    "\n",
    "- 2019 Codebook: https://www.cdc.gov/brfss/annual_data/2019/pdf/codebook19_llcp-v2-508.HTML\n",
    "- 2021 Codebook: https://www.cdc.gov/brfss/annual_data/2021/pdf/codebook21_llcp-v2-508.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clean, Standardize, and Merge data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn \n",
    "\n",
    "# Libraries related to outlier detection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <font color= darkgreen> Basic EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 1: Read the data and merge into Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE  \\\n0    1.00    1.00  b'01192021'  b'01'  b'19'  b'2021'   1100.00   \n1    1.00    1.00  b'01212021'  b'01'  b'21'  b'2021'   1100.00   \n2    1.00    1.00  b'01212021'  b'01'  b'21'  b'2021'   1100.00   \n3    1.00    1.00  b'01172021'  b'01'  b'17'  b'2021'   1100.00   \n4    1.00    1.00  b'01152021'  b'01'  b'15'  b'2021'   1100.00   \n\n           SEQNO          _PSU  CTELENM1  ...  _FRTRES1  _VEGRES1  _FRUTSU1  \\\n0  b'2021000001' 2021000001.00      1.00  ...      1.00      1.00    100.00   \n1  b'2021000002' 2021000002.00      1.00  ...      1.00      1.00    100.00   \n2  b'2021000003' 2021000003.00      1.00  ...      1.00      1.00    100.00   \n3  b'2021000004' 2021000004.00      1.00  ...      1.00      1.00    114.00   \n4  b'2021000005' 2021000005.00      1.00  ...      1.00      1.00    100.00   \n\n   _VEGESU1  _FRTLT1A  _VEGLT1A  _FRT16A  _VEG23A  _FRUITE1  _VEGETE1  \n0    214.00      1.00      1.00     1.00     1.00      0.00      0.00  \n1    128.00      1.00      1.00     1.00     1.00      0.00      0.00  \n2     71.00      1.00      2.00     1.00     1.00      0.00      0.00  \n3    165.00      1.00      1.00     1.00     1.00      0.00      0.00  \n4    258.00      1.00      1.00     1.00     1.00      0.00      0.00  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_FRTRES1</th>\n      <th>_VEGRES1</th>\n      <th>_FRUTSU1</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01192021'</td>\n      <td>b'01'</td>\n      <td>b'19'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000001'</td>\n      <td>2021000001.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>214.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01212021'</td>\n      <td>b'01'</td>\n      <td>b'21'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000002'</td>\n      <td>2021000002.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>128.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01212021'</td>\n      <td>b'01'</td>\n      <td>b'21'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000003'</td>\n      <td>2021000003.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>71.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01172021'</td>\n      <td>b'01'</td>\n      <td>b'17'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000004'</td>\n      <td>2021000004.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>114.00</td>\n      <td>165.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>b'01152021'</td>\n      <td>b'01'</td>\n      <td>b'15'</td>\n      <td>b'2021'</td>\n      <td>1100.00</td>\n      <td>b'2021000005'</td>\n      <td>2021000005.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>258.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 250 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                       Data Frame Setup                                                                                  '''\n",
    "###############################################################################################################################################################################\n",
    "## The first column is index: skipping that column to end read csv to Panda Data Frame\n",
    "df_21 = pd.read_csv(\"res/brfss21-1.csv\")\n",
    "df_21.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "df_21.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n0       1       1  1182019       1    18   2019      1100  2019000001   \n1       1       1  1132019       1    13   2019      1100  2019000002   \n2       1       1  1182019       1    18   2019      1100  2019000003   \n3       1       1  1182019       1    18   2019      1200  2019000004   \n4       1       1  1042019       1     4   2019      1100  2019000005   \n\n         _PSU  CTELENM1  ...  _VEGESU1  _FRTLT1A  _VEGLT1A  _FRT16A  _VEG23A  \\\n0  2019000001      1.00  ...    114.00         1         1        1        1   \n1  2019000002      1.00  ...    121.00         1         1        1        1   \n2  2019000003      1.00  ...    164.00         1         1        1        1   \n3  2019000004      1.00  ...       NaN         9         9        1        1   \n4  2019000005      1.00  ...    178.00         1         1        1        1   \n\n   _FRUITE1  _VEGETE1  _FLSHOT7  _PNEUMO3  _AIDTST4  \n0         0         0      2.00      1.00      2.00  \n1         0         0      1.00      1.00      2.00  \n2         0         0      1.00      2.00      2.00  \n3         1         1      9.00      9.00       NaN  \n4         0         0      2.00      1.00      2.00  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n      <th>_FLSHOT7</th>\n      <th>_PNEUMO3</th>\n      <th>_AIDTST4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000001</td>\n      <td>2019000001</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>114.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1132019</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000002</td>\n      <td>2019000002</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>121.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000003</td>\n      <td>2019000003</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>164.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1182019</td>\n      <td>1</td>\n      <td>18</td>\n      <td>2019</td>\n      <td>1200</td>\n      <td>2019000004</td>\n      <td>2019000004</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1042019</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2019</td>\n      <td>1100</td>\n      <td>2019000005</td>\n      <td>2019000005</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>178.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 250 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_19 = pd.read_csv(\"res/brfss19-1.csv\")\n",
    "df_19.drop(columns=\"Unnamed: 0\", inplace= True)\n",
    "df_19.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 2: Summary of Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _STATE    FMONTH       IDATE    IMONTH      IDAY     IYEAR  DISPCODE  \\\ncount 418268.00 418268.00   418268.00 418268.00 418268.00 418268.00 418268.00   \nmean      29.62      6.54  6727352.51      6.58     14.53   2019.04   1117.44   \nstd       16.15      3.34  3304672.99      3.31      8.49      0.21     37.95   \nmin        1.00      1.00  1012020.00      1.00      1.00   2019.00   1100.00   \n25%       18.00      4.00  4082019.00      4.00      7.00   2019.00   1100.00   \n50%       27.00      7.00  7012019.00      7.00     14.00   2019.00   1100.00   \n75%       42.00      9.00  9302019.00      9.00     22.00   2019.00   1100.00   \nmax       72.00     12.00 12312019.00     12.00     31.00   2020.00   1200.00   \n\n              SEQNO          _PSU  CTELENM1  ...  _VEGESU1  _FRTLT1A  \\\ncount     418268.00     418268.00 149941.00  ... 364838.00 418268.00   \nmean  2019004884.52 2019004884.52      1.00  ...    204.14      2.19   \nstd         3653.32       3653.32      0.00  ...    267.90      2.40   \nmin   2019000001.00 2019000001.00      1.00  ...      0.00      1.00   \n25%   2019002011.00 2019002011.00      1.00  ...    114.00      1.00   \n50%   2019004137.00 2019004137.00      1.00  ...    165.00      1.00   \n75%   2019006895.00 2019006895.00      1.00  ...    229.00      2.00   \nmax   2019017419.00 2019017419.00      1.00  ...  13204.00      9.00   \n\n       _VEGLT1A   _FRT16A   _VEG23A  _FRUITE1  _VEGETE1  _FLSHOT7  _PNEUMO3  \\\ncount 418268.00 418268.00 418268.00 418268.00 418268.00 159112.00 159112.00   \nmean       2.19      1.00      1.00      0.11      0.13      2.23      2.37   \nstd        2.63      0.04      0.05      0.32      0.35      2.47      2.73   \nmin        1.00      0.00      0.00      0.00      0.00      1.00      1.00   \n25%        1.00      1.00      1.00      0.00      0.00      1.00      1.00   \n50%        1.00      1.00      1.00      0.00      0.00      1.00      1.00   \n75%        2.00      1.00      1.00      0.00      0.00      2.00      2.00   \nmax        9.00      1.00      1.00      2.00      2.00      9.00      9.00   \n\n       _AIDTST4  \ncount 377977.00  \nmean       1.97  \nstd        1.56  \nmin        1.00  \n25%        1.00  \n50%        2.00  \n75%        2.00  \nmax        9.00  \n\n[8 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>IDATE</th>\n      <th>IMONTH</th>\n      <th>IDAY</th>\n      <th>IYEAR</th>\n      <th>DISPCODE</th>\n      <th>SEQNO</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>...</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n      <th>_FLSHOT7</th>\n      <th>_PNEUMO3</th>\n      <th>_AIDTST4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>149941.00</td>\n      <td>...</td>\n      <td>364838.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>418268.00</td>\n      <td>159112.00</td>\n      <td>159112.00</td>\n      <td>377977.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29.62</td>\n      <td>6.54</td>\n      <td>6727352.51</td>\n      <td>6.58</td>\n      <td>14.53</td>\n      <td>2019.04</td>\n      <td>1117.44</td>\n      <td>2019004884.52</td>\n      <td>2019004884.52</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>204.14</td>\n      <td>2.19</td>\n      <td>2.19</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.11</td>\n      <td>0.13</td>\n      <td>2.23</td>\n      <td>2.37</td>\n      <td>1.97</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>16.15</td>\n      <td>3.34</td>\n      <td>3304672.99</td>\n      <td>3.31</td>\n      <td>8.49</td>\n      <td>0.21</td>\n      <td>37.95</td>\n      <td>3653.32</td>\n      <td>3653.32</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>267.90</td>\n      <td>2.40</td>\n      <td>2.63</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>0.32</td>\n      <td>0.35</td>\n      <td>2.47</td>\n      <td>2.73</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1012020.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019000001.00</td>\n      <td>2019000001.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>18.00</td>\n      <td>4.00</td>\n      <td>4082019.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019002011.00</td>\n      <td>2019002011.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>114.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>27.00</td>\n      <td>7.00</td>\n      <td>7012019.00</td>\n      <td>7.00</td>\n      <td>14.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019004137.00</td>\n      <td>2019004137.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>165.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>42.00</td>\n      <td>9.00</td>\n      <td>9302019.00</td>\n      <td>9.00</td>\n      <td>22.00</td>\n      <td>2019.00</td>\n      <td>1100.00</td>\n      <td>2019006895.00</td>\n      <td>2019006895.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>229.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>72.00</td>\n      <td>12.00</td>\n      <td>12312019.00</td>\n      <td>12.00</td>\n      <td>31.00</td>\n      <td>2020.00</td>\n      <td>1200.00</td>\n      <td>2019017419.00</td>\n      <td>2019017419.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>13204.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 250 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                    Data Frame Description                                                                               '''\n",
    "###############################################################################################################################################################################\n",
    "df_19.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(418268, 250)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                     Data Frame Shape                                                                                    '''\n",
    "###############################################################################################################################################################################\n",
    "df_19.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _STATE    FMONTH  DISPCODE          _PSU  CTELENM1  PVTRESD1  \\\ncount 438693.00 438693.00 438693.00     438693.00 117786.00 117786.00   \nmean      30.74      6.41   1118.19 2021006064.89      1.00      1.00   \nstd       15.33      3.42     38.58       6383.75      0.00      0.02   \nmin        1.00      1.00   1100.00 2021000001.00      1.00      1.00   \n25%       20.00      3.00   1100.00 2021002091.00      1.00      1.00   \n50%       31.00      6.00   1100.00 2021004338.00      1.00      1.00   \n75%       41.00      9.00   1100.00 2021007674.00      1.00      1.00   \nmax       78.00     12.00   1200.00 2021039095.00      2.00      2.00   \n\n       COLGHOUS  STATERE1   LADULT1  COLGSEX  ...  _FRTRES1  _VEGRES1  \\\ncount     30.00 117786.00 117786.00    30.00  ... 438693.00 438693.00   \nmean       1.00      1.00      1.01     1.63  ...      0.88      0.86   \nstd        0.00      0.00      0.08     0.49  ...      0.32      0.34   \nmin        1.00      1.00      1.00     1.00  ...      0.00      0.00   \n25%        1.00      1.00      1.00     1.00  ...      1.00      1.00   \n50%        1.00      1.00      1.00     2.00  ...      1.00      1.00   \n75%        1.00      1.00      1.00     2.00  ...      1.00      1.00   \nmax        1.00      1.00      2.00     2.00  ...      1.00      1.00   \n\n       _FRUTSU1  _VEGESU1  _FRTLT1A  _VEGLT1A   _FRT16A   _VEG23A  _FRUITE1  \\\ncount 387606.00 378566.00 438693.00 438693.00 438693.00 438693.00 438693.00   \nmean     178.34    271.54      2.27      2.26      0.99      0.99      0.13   \nstd      691.29   1036.23      2.49      2.71      0.07      0.09      0.35   \nmin        0.00      0.00      1.00      1.00      0.00      0.00      0.00   \n25%       57.00    114.00      1.00      1.00      1.00      1.00      0.00   \n50%      100.00    167.00      1.00      1.00      1.00      1.00      0.00   \n75%      200.00    229.00      2.00      2.00      1.00      1.00      0.00   \nmax    19800.00  39600.00      9.00      9.00      1.00      1.00      2.00   \n\n       _VEGETE1  \ncount 438693.00  \nmean       0.15  \nstd        0.38  \nmin        0.00  \n25%        0.00  \n50%        0.00  \n75%        0.00  \nmax        2.00  \n\n[8 rows x 245 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_STATE</th>\n      <th>FMONTH</th>\n      <th>DISPCODE</th>\n      <th>_PSU</th>\n      <th>CTELENM1</th>\n      <th>PVTRESD1</th>\n      <th>COLGHOUS</th>\n      <th>STATERE1</th>\n      <th>LADULT1</th>\n      <th>COLGSEX</th>\n      <th>...</th>\n      <th>_FRTRES1</th>\n      <th>_VEGRES1</th>\n      <th>_FRUTSU1</th>\n      <th>_VEGESU1</th>\n      <th>_FRTLT1A</th>\n      <th>_VEGLT1A</th>\n      <th>_FRT16A</th>\n      <th>_VEG23A</th>\n      <th>_FRUITE1</th>\n      <th>_VEGETE1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>117786.00</td>\n      <td>117786.00</td>\n      <td>30.00</td>\n      <td>117786.00</td>\n      <td>117786.00</td>\n      <td>30.00</td>\n      <td>...</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>387606.00</td>\n      <td>378566.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n      <td>438693.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>30.74</td>\n      <td>6.41</td>\n      <td>1118.19</td>\n      <td>2021006064.89</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.01</td>\n      <td>1.63</td>\n      <td>...</td>\n      <td>0.88</td>\n      <td>0.86</td>\n      <td>178.34</td>\n      <td>271.54</td>\n      <td>2.27</td>\n      <td>2.26</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.13</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>15.33</td>\n      <td>3.42</td>\n      <td>38.58</td>\n      <td>6383.75</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.08</td>\n      <td>0.49</td>\n      <td>...</td>\n      <td>0.32</td>\n      <td>0.34</td>\n      <td>691.29</td>\n      <td>1036.23</td>\n      <td>2.49</td>\n      <td>2.71</td>\n      <td>0.07</td>\n      <td>0.09</td>\n      <td>0.35</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1100.00</td>\n      <td>2021000001.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.00</td>\n      <td>3.00</td>\n      <td>1100.00</td>\n      <td>2021002091.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>57.00</td>\n      <td>114.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>31.00</td>\n      <td>6.00</td>\n      <td>1100.00</td>\n      <td>2021004338.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>100.00</td>\n      <td>167.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>41.00</td>\n      <td>9.00</td>\n      <td>1100.00</td>\n      <td>2021007674.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>200.00</td>\n      <td>229.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.00</td>\n      <td>12.00</td>\n      <td>1200.00</td>\n      <td>2021039095.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>19800.00</td>\n      <td>39600.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 245 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                    Data Frame Description                                                                               '''\n",
    "###############################################################################################################################################################################\n",
    "df_21.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(438693, 250)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                     Data Frame Shape                                                                                    '''\n",
    "###############################################################################################################################################################################\n",
    "df_21.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 3: Choose Feature Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color=white>We will first need to choose our feature space.  The five demographics provided will be the first on the list:\n",
    "<font color= red>\n",
    "* Age:  _AGE_G\n",
    "* Marital: MARITAL\n",
    "* Sex: _SEX\n",
    "* Income: INCOME2\n",
    "* Education: _EDUCAG\n",
    "\n",
    "<font color= white>\n",
    "Next we want to choose some features which we think will have some bearing on the response columns. We also want to pair the 250 features down to 20 (as per professor). Another demographic could be their race and city vs rural living as well as access to health care (insurance) and routine checkups:\n",
    "<br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Race: _RACE\n",
    "* Urban / Rural: _METSTAT\n",
    "* Health Care Access (Insurance): PRIMINSR &ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Health Insurance data not included in the data provided<font color= red>\n",
    "* Health Care Access (Routine checkup): CHECKUP1\n",
    "\n",
    "<font color= white>\n",
    "Also, we should also track physical activity, High blood pressure, High Cholesterol, smoking habits, drinking habits, BMI, kidney disease\n",
    "<br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Physical exersice: _TOTINDA\n",
    "* HBP: _RFHYPE6 &ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Blood Pressure metrics not included in the data provided<font color= white><br>\n",
    "\n",
    "Instead we will use Currently taking blood pressure medication and Be very carefull with our clean up <br><font color= red>\n",
    "\n",
    "* High Cholesterol: _RFCHOL3 &ensp;&ensp;&ensp;&ensp;<font color=lightblue>-- Cholesterol metrics not included in the data provided<font color= red>\n",
    "* Four level smoker status: _SMOKER3\n",
    "* Number of drinks per week: _DRNKWK1&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total Fruit per Day: _FRUTSU1&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total Vegetables per Day: _VEGESU1&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Total French Fry per Day: FRNCHDA_&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Body Mass Index: _BMI5&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<font color=lightblue> Continuous Data<font color= red>\n",
    "* Kidney Disease: CHCKDNY2\n",
    "\n",
    "<font color= white>\n",
    "The last demographic that Tony would like to include specifically is whether the participant is a veteran:\n",
    "br><br>\n",
    "<font color= red>\n",
    "\n",
    "* Veteran Status: VETERAN3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(418268, 27)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                               Choosing Response and Features                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "df_19_trim = df_19.loc[:, ['ADDEPEV3', '_CASTHM1', 'CHCCOPD2', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3',\n",
    "                            'DIABETE4', '_AGE_G', 'MARITAL', '_SEX', 'INCOME2', '_EDUCAG', '_RACE', '_METSTAT', 'CHECKUP1',\n",
    "                            'BPMEDS', '_TOTINDA', '_SMOKER3', '_DRNKWK1', '_FRUTSU1', '_VEGESU1','FRNCHDA_', '_BMI5', \n",
    "                            'CHCKDNY2', 'VETERAN3']]\n",
    "df_19_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(438693, 27)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                               Choosing Response and Features                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "df_21_trim = df_21.loc[:, ['ADDEPEV3', '_CASTHM1', 'CHCCOPD3', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3',\n",
    "                            'DIABETE4', '_AGE_G', 'MARITAL', '_SEX', 'INCOME3', '_EDUCAG', '_RACE', '_METSTAT', 'CHECKUP1',\n",
    "                            'BPMEDS', '_TOTINDA', '_SMOKER3', '_DRNKWK1', '_FRUTSU1', '_VEGESU1','FRNCHDA_', '_BMI5', \n",
    "                            'CHCKDNY2', 'VETERAN3']]\n",
    "df_21_trim.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 4: Missing Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### BPMEDS\n",
    "From looking at the data itself, most of the missing values from BPMEDS is because the previous question answered something other than yes to every choice other than yes.  Therefore we can infer that these were a no and that 7 and 9 should be dropped.\n",
    "* 2021-\n",
    "- missing: 266,560 \n",
    "<br>vs<br>\n",
    "- Previous other than yes: 266,560\n",
    "\n",
    "there is only 0.26% which was I don't know or Refused\n",
    "\n",
    "* 2019-\n",
    "- missing: 248,634 \n",
    "<br>vs<br>\n",
    "- Previous other than yes: 248,634\n",
    "\n",
    "there is only 0.21% which was I don't know or Refused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 19 shape:\t (438693, 27)\n",
      "Original 21 shape:\t (438693, 27)\n",
      "Missing values by field (Pre-Interpolate):\n",
      "ADDEPEV3        10\n",
      "_CASTHM1         0\n",
      "CHCCOPD2         8\n",
      "CHCSCNCR         8\n",
      "CHCOCNCR         9\n",
      "CVDCRHD4         8\n",
      "CVDINFR4        10\n",
      "CVDSTRK3        11\n",
      "DIABETE4         9\n",
      "_AGE_G           0\n",
      "MARITAL         49\n",
      "_SEX             0\n",
      "INCOME2       6881\n",
      "_EDUCAG          0\n",
      "_RACE            3\n",
      "_METSTAT      8458\n",
      "CHECKUP1        10\n",
      "BPMEDS      248634\n",
      "_TOTINDA         0\n",
      "_SMOKER3         0\n",
      "_DRNKWK1         0\n",
      "_FRUTSU1     44600\n",
      "_VEGESU1     53430\n",
      "FRNCHDA_     38866\n",
      "_BMI5        36203\n",
      "CHCKDNY2        11\n",
      "VETERAN3      1374\n",
      "dtype: int64 \n",
      "\n",
      "ADDEPEV3         3\n",
      "_CASTHM1         0\n",
      "CHCCOPD3         3\n",
      "CHCSCNCR         2\n",
      "CHCOCNCR         3\n",
      "CVDCRHD4         2\n",
      "CVDINFR4         2\n",
      "CVDSTRK3         2\n",
      "DIABETE4         3\n",
      "_AGE_G           0\n",
      "MARITAL          5\n",
      "_SEX             0\n",
      "INCOME3       8847\n",
      "_EDUCAG          0\n",
      "_RACE            0\n",
      "_METSTAT      7054\n",
      "CHECKUP1         2\n",
      "BPMEDS      266560\n",
      "_TOTINDA         0\n",
      "_SMOKER3         0\n",
      "_DRNKWK1         0\n",
      "_FRUTSU1     51087\n",
      "_VEGESU1     60127\n",
      "FRNCHDA_     44765\n",
      "_BMI5        46852\n",
      "CHCKDNY2         3\n",
      "VETERAN3      1636\n",
      "dtype: int64 \n",
      "\n",
      "ADDEPEV3       10\n",
      "_CASTHM1        0\n",
      "CHCCOPD2        8\n",
      "CHCSCNCR        8\n",
      "CHCOCNCR        9\n",
      "CVDCRHD4        8\n",
      "CVDINFR4       10\n",
      "CVDSTRK3       11\n",
      "DIABETE4        9\n",
      "_AGE_G          0\n",
      "MARITAL        49\n",
      "_SEX            0\n",
      "INCOME2      6874\n",
      "_EDUCAG         0\n",
      "_RACE           3\n",
      "_METSTAT     8456\n",
      "CHECKUP1       10\n",
      "BPMEDS          0\n",
      "_TOTINDA        0\n",
      "_SMOKER3        0\n",
      "_DRNKWK1        0\n",
      "_FRUTSU1    44533\n",
      "_VEGESU1    53322\n",
      "FRNCHDA_    38804\n",
      "_BMI5       36145\n",
      "CHCKDNY2       11\n",
      "VETERAN3     1370\n",
      "dtype: int64 \n",
      "\n",
      "(417916, 27)\n",
      "ADDEPEV3        3\n",
      "_CASTHM1        0\n",
      "CHCCOPD3        3\n",
      "CHCSCNCR        2\n",
      "CHCOCNCR        3\n",
      "CVDCRHD4        2\n",
      "CVDINFR4        2\n",
      "CVDSTRK3        2\n",
      "DIABETE4        3\n",
      "_AGE_G          0\n",
      "MARITAL         5\n",
      "_SEX            0\n",
      "INCOME3      8841\n",
      "_EDUCAG         0\n",
      "_RACE           0\n",
      "_METSTAT     7052\n",
      "CHECKUP1        2\n",
      "BPMEDS          0\n",
      "_TOTINDA        0\n",
      "_SMOKER3        0\n",
      "_DRNKWK1        0\n",
      "_FRUTSU1    50980\n",
      "_VEGESU1    60000\n",
      "FRNCHDA_    44684\n",
      "_BMI5       46735\n",
      "CHCKDNY2        3\n",
      "VETERAN3     1635\n",
      "dtype: int64 \n",
      "\n",
      "(438234, 27)\n",
      "Final 19 shape:\t (330505, 27)\n",
      "Final 21 shape:\t (338998, 27)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Analyze, Clean, and Impute                                                                            '''\n",
    "###############################################################################################################################################################################\n",
    "## Print Original Shape for comparisson\n",
    "print('Original 19 shape:\\t', df_21_trim.shape)\n",
    "print('Original 21 shape:\\t', df_21_trim.shape)\n",
    "\n",
    "## Interpret and clean df\n",
    "# output how many NaN there is per column\n",
    "print('Missing values by field (Pre-Interpolate):')\n",
    "\n",
    "# Visualize the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "## Replace missing values in BPMEDS with No answer and drop 7 and 9 response as NAN\n",
    "df_19_trim = df_19_trim[df_19_trim['BPMEDS'] != 7] \n",
    "df_19_trim = df_19_trim[df_19_trim['BPMEDS'] != 9]\n",
    "df_19_trim['BPMEDS'].fillna(2, inplace= True) \n",
    "\n",
    "# How are we doing now\n",
    "print(df_19_trim.isnull().sum(), '\\n')\n",
    "print(df_19_trim.shape)\n",
    "\n",
    "# Drop the remaining NaN\n",
    "df_19_trim.dropna(inplace= True)\n",
    "\n",
    "\n",
    "## Replace missing values in BPMEDS with No answer and drop 7 and 9 response as NAN\n",
    "df_21_trim = df_21_trim[df_21_trim['BPMEDS'] != 7] \n",
    "df_21_trim = df_21_trim[df_21_trim['BPMEDS'] != 9]\n",
    "df_21_trim['BPMEDS'].fillna(2, inplace= True) \n",
    "\n",
    "# How are we doing now\n",
    "print(df_21_trim.isnull().sum(), '\\n')\n",
    "print(df_21_trim.shape)\n",
    "\n",
    "# Drop the remaining NaN\n",
    "df_21_trim.dropna(inplace= True)\n",
    "\n",
    "# Output final shape\n",
    "print('Final 19 shape:\\t', df_19_trim.shape)\n",
    "print('Final 21 shape:\\t', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create categorical columns\n",
    "\n",
    "- Column 1: Binary - indicates whether an individual has haf any of the chronic conditions. \n",
    "- Column 2: Multiclass - create a milticlass column with values that inidicate the total number of chronic conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 5: Binary and Multiclass Response Created"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>First we create the binaries for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression  ADDEPEV3\n",
      "0.00        2.00        264512\n",
      "1.00        1.00         64620\n",
      "dtype: int64\n",
      "1373\n",
      "2.00    264512\n",
      "1.00     64620\n",
      "7.00      1188\n",
      "9.00       185\n",
      "Name: ADDEPEV3, dtype: int64 \n",
      "\n",
      "Asthma  _CASTHM1\n",
      "1.00    1           297376\n",
      "0.00    2            30814\n",
      "dtype: int64\n",
      "2315\n",
      "1    297376\n",
      "2     30814\n",
      "9      2315\n",
      "Name: _CASTHM1, dtype: int64 \n",
      "\n",
      "COPD  CHCCOPD2\n",
      "0.00  2.00        300875\n",
      "1.00  1.00         28179\n",
      "dtype: int64\n",
      "1451\n",
      "2.00    300875\n",
      "1.00     28179\n",
      "7.00      1398\n",
      "9.00        53\n",
      "Name: CHCCOPD2, dtype: int64 \n",
      "\n",
      "Cancer  CHCSCNCR  CHCOCNCR\n",
      "0.00    2.00      2.00        267482\n",
      "1.00    1.00      2.00         26841\n",
      "        2.00      1.00         26565\n",
      "        1.00      1.00          8057\n",
      "0.00    7.00      2.00           660\n",
      "        2.00      7.00           509\n",
      "1.00    7.00      1.00           143\n",
      "        1.00      7.00            89\n",
      "0.00    2.00      9.00            58\n",
      "        9.00      2.00            13\n",
      "1.00    1.00      9.00            10\n",
      "        9.00      1.00             1\n",
      "dtype: int64\n",
      "77\n",
      "2.00    294614\n",
      "1.00     34997\n",
      "7.00       854\n",
      "9.00        40\n",
      "Name: CHCSCNCR, dtype: int64 \n",
      "\n",
      "2.00    294996\n",
      "1.00     34766\n",
      "7.00       649\n",
      "9.00        94\n",
      "Name: CHCOCNCR, dtype: int64 \n",
      "\n",
      "0.00    268722\n",
      "1.00     61706\n",
      "Name: Cancer, dtype: int64 \n",
      "\n",
      "Heart  CVDCRHD4  CVDINFR4  CVDSTRK3\n",
      "0.00   2.00      2.00      2.00        288581\n",
      "1.00   2.00      2.00      1.00          9184\n",
      "       1.00      2.00      2.00          8504\n",
      "       2.00      1.00      2.00          7671\n",
      "       1.00      1.00      2.00          6952\n",
      "                           1.00          1986\n",
      "       2.00      1.00      1.00          1719\n",
      "0.00   7.00      2.00      2.00          1345\n",
      "1.00   1.00      2.00      1.00          1196\n",
      "0.00   2.00      7.00      2.00           844\n",
      "1.00   7.00      1.00      2.00           724\n",
      "0.00   2.00      2.00      7.00           473\n",
      "1.00   7.00      2.00      1.00           194\n",
      "       1.00      7.00      2.00           186\n",
      "       7.00      1.00      1.00           174\n",
      "0.00   7.00      7.00      2.00           164\n",
      "1.00   2.00      7.00      1.00           139\n",
      "                 1.00      7.00            51\n",
      "       1.00      2.00      7.00            49\n",
      "                 7.00      1.00            47\n",
      "                 1.00      7.00            47\n",
      "0.00   2.00      7.00      7.00            44\n",
      "       7.00      2.00      7.00            33\n",
      "1.00   7.00      7.00      1.00            28\n",
      "                 1.00      7.00            21\n",
      "0.00   2.00      2.00      9.00            16\n",
      "       9.00      2.00      2.00            13\n",
      "       2.00      9.00      2.00            13\n",
      "1.00   1.00      7.00      7.00             8\n",
      "                 9.00      2.00             6\n",
      "       9.00      1.00      2.00             5\n",
      "                 2.00      1.00             5\n",
      "0.00   9.00      9.00      2.00             3\n",
      "                 2.00      9.00             3\n",
      "1.00   2.00      9.00      1.00             2\n",
      "       1.00      2.00      9.00             1\n",
      "       9.00      1.00      1.00             1\n",
      "       1.00      9.00      1.00             1\n",
      "       9.00      9.00      1.00             1\n",
      "dtype: int64\n",
      "71\n",
      "2.00    308737\n",
      "1.00     18983\n",
      "7.00      2733\n",
      "9.00        52\n",
      "Name: CVDCRHD4, dtype: int64 \n",
      "\n",
      "2.00    309597\n",
      "1.00     19351\n",
      "7.00      1511\n",
      "9.00        46\n",
      "Name: CVDINFR4, dtype: int64 \n",
      "\n",
      "2.00    315011\n",
      "1.00     14677\n",
      "7.00       775\n",
      "9.00        42\n",
      "Name: CVDSTRK3, dtype: int64 \n",
      "\n",
      "0.00    291532\n",
      "1.00     38902\n",
      "Name: Heart, dtype: int64 \n",
      "\n",
      "Diabetes  DIABETE4\n",
      "0.00      3.00        274993\n",
      "1.00      1.00         44992\n",
      "0.00      4.00          7239\n",
      "          2.00          2862\n",
      "dtype: int64\n",
      "419\n",
      "3.00    274993\n",
      "1.00     44992\n",
      "4.00      7239\n",
      "2.00      2862\n",
      "7.00       364\n",
      "9.00        55\n",
      "Name: DIABETE4, dtype: int64 \n",
      "\n",
      "   ADDEPEV3  _CASTHM1  CHCCOPD2  CHCSCNCR  CHCOCNCR  CVDCRHD4  CVDINFR4  \\\n",
      "0      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "1      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "2      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "4      2.00         1      2.00      2.00      2.00      2.00      2.00   \n",
      "6      2.00         2      1.00      2.00      2.00      2.00      2.00   \n",
      "\n",
      "   CVDSTRK3  DIABETE4  _AGE_G  ...  FRNCHDA_   _BMI5  CHCKDNY2  VETERAN3  \\\n",
      "0      2.00      3.00       6  ...     14.00 2817.00      2.00      2.00   \n",
      "1      2.00      3.00       6  ...      7.00 1854.00      2.00      2.00   \n",
      "2      2.00      1.00       6  ...      7.00 3162.00      2.00      2.00   \n",
      "4      2.00      3.00       6  ...      7.00 2148.00      2.00      2.00   \n",
      "6      2.00      1.00       6  ...     50.00 3298.00      2.00      2.00   \n",
      "\n",
      "   Depression  Asthma  COPD  Cancer  Heart  Diabetes  \n",
      "0        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "1        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "2        0.00    1.00  0.00    0.00   0.00      1.00  \n",
      "4        0.00    1.00  0.00    0.00   0.00      0.00  \n",
      "6        0.00    0.00  1.00    0.00   0.00      1.00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2019                                                                      '''\n",
    "###############################################################################################################################################################################\n",
    "## Binary Comorbidity Response Features from our respective responses\n",
    "# Create the Depression comorbidity variable\n",
    "df_19_trim['Depression'] = df_19_trim.apply(lambda row: 1 if row[0] == 1 else (0 if row[0] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['Depression', 'ADDEPEV3']].value_counts())\n",
    "print(df_19_trim['Depression'].isnull().sum())\n",
    "print(df_19_trim['ADDEPEV3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Asthma comorbidity variable\n",
    "df_19_trim['Asthma'] = df_19_trim.apply(lambda row: 1 if row[1] == 1 else (0 if row[1] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['Asthma', '_CASTHM1']].value_counts())\n",
    "print(df_19_trim['Asthma'].isnull().sum())\n",
    "print(df_19_trim['_CASTHM1'].value_counts(), '\\n')\n",
    "\n",
    "# Create the COPD comorbidity variable\n",
    "df_19_trim['COPD'] = df_19_trim.apply(lambda row: 1 if row[2] == 1 else (0 if row[2] == 2 else np.NAN), axis=1)\n",
    "print(df_19_trim[['COPD', 'CHCCOPD2']].value_counts())\n",
    "print(df_19_trim['COPD'].isnull().sum())\n",
    "print(df_19_trim['CHCCOPD2'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Cancer comorbidity variable\n",
    "df_19_trim['Cancer'] = df_19_trim.apply(lambda row: 1 if row[3] == 1 else (1 if row[4] == 1 else (0 if row[3] == 2 else ( 0 if row[4] == 2 else np.NAN))), axis=1)\n",
    "print(df_19_trim[['Cancer', 'CHCSCNCR', 'CHCOCNCR']].value_counts())\n",
    "print(df_19_trim['Cancer'].isnull().sum())\n",
    "print(df_19_trim['CHCSCNCR'].value_counts(), '\\n')\n",
    "print(df_19_trim['CHCOCNCR'].value_counts(), '\\n')\n",
    "print(df_19_trim['Cancer'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Heart Condition comorbidity variable\n",
    "df_19_trim['Heart'] = df_19_trim.apply(lambda row: 1 if row[5] == 1 else (1 if row[6] == 1 else (1 if row[7] == 1 else (0 if row[5] == 2 else (0 if row[6] == 2 else (0 if row[7] == 2 else np.NAN))))), axis=1)\n",
    "print(df_19_trim[['Heart', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3']].value_counts())\n",
    "print(df_19_trim['Heart'].isnull().sum())\n",
    "print(df_19_trim['CVDCRHD4'].value_counts(), '\\n')\n",
    "print(df_19_trim['CVDINFR4'].value_counts(), '\\n')\n",
    "print(df_19_trim['CVDSTRK3'].value_counts(), '\\n')\n",
    "print(df_19_trim['Heart'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Depression comorbidity variable\n",
    "df_19_trim['Diabetes'] = df_19_trim.apply(lambda row: 1 if row[8] == 1 else (0 if row[8] == 2 else (0 if row[8] == 3 else (0 if row[8] == 4 else np.NAN))), axis=1)\n",
    "print(df_19_trim[['Diabetes', 'DIABETE4']].value_counts())\n",
    "print(df_19_trim['Diabetes'].isnull().sum())\n",
    "print(df_19_trim['DIABETE4'].value_counts(), '\\n')\n",
    "\n",
    "print(df_19_trim.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Then we create the binaries for 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression  ADDEPEV3\n",
      "0.00        2.00        268786\n",
      "1.00        1.00         68765\n",
      "dtype: int64\n",
      "1447\n",
      "2.00    268786\n",
      "1.00     68765\n",
      "7.00      1183\n",
      "9.00       264\n",
      "Name: ADDEPEV3, dtype: int64 \n",
      "\n",
      "Asthma  _CASTHM1\n",
      "1.00    1.00        303552\n",
      "0.00    2.00         33089\n",
      "dtype: int64\n",
      "2357\n",
      "1.00    303552\n",
      "2.00     33089\n",
      "9.00      2357\n",
      "Name: _CASTHM1, dtype: int64 \n",
      "\n",
      "COPD  CHCCOPD3\n",
      "0.00  2.00        311016\n",
      "1.00  1.00         26759\n",
      "dtype: int64\n",
      "1223\n",
      "2.00    311016\n",
      "1.00     26759\n",
      "7.00      1157\n",
      "9.00        66\n",
      "Name: CHCCOPD3, dtype: int64 \n",
      "\n",
      "Cancer  CHCSCNCR  CHCOCNCR\n",
      "0.00    2.00      2.00        278474\n",
      "1.00    2.00      1.00         25632\n",
      "        1.00      2.00         25540\n",
      "                  1.00          7869\n",
      "0.00    7.00      2.00           588\n",
      "        2.00      7.00           468\n",
      "1.00    7.00      1.00           137\n",
      "        1.00      7.00            88\n",
      "0.00    2.00      9.00            56\n",
      "        9.00      2.00            17\n",
      "1.00    1.00      9.00            14\n",
      "        9.00      1.00             1\n",
      "dtype: int64\n",
      "114\n",
      "2.00    304630\n",
      "1.00     33511\n",
      "7.00       804\n",
      "9.00        53\n",
      "Name: CHCSCNCR, dtype: int64 \n",
      "\n",
      "2.00    304619\n",
      "1.00     33639\n",
      "7.00       635\n",
      "9.00       105\n",
      "Name: CHCOCNCR, dtype: int64 \n",
      "\n",
      "0.00    279603\n",
      "1.00     59281\n",
      "Name: Cancer, dtype: int64 \n",
      "\n",
      "Heart  CVDCRHD4  CVDINFR4  CVDSTRK3\n",
      "0.00   2.00      2.00      2.00        299147\n",
      "1.00   1.00      2.00      2.00          8565\n",
      "       2.00      2.00      1.00          8562\n",
      "                 1.00      2.00          7228\n",
      "       1.00      1.00      2.00          6611\n",
      "                           1.00          1651\n",
      "0.00   7.00      2.00      2.00          1419\n",
      "1.00   2.00      1.00      1.00          1403\n",
      "       1.00      2.00      1.00          1082\n",
      "0.00   2.00      7.00      2.00           824\n",
      "1.00   7.00      1.00      2.00           683\n",
      "0.00   2.00      2.00      7.00           510\n",
      "1.00   1.00      7.00      2.00           213\n",
      "       7.00      2.00      1.00           206\n",
      "                 1.00      1.00           165\n",
      "0.00   7.00      7.00      2.00           149\n",
      "1.00   2.00      7.00      1.00           108\n",
      "       1.00      1.00      7.00            50\n",
      "0.00   2.00      7.00      7.00            44\n",
      "1.00   1.00      7.00      1.00            42\n",
      "       2.00      1.00      7.00            40\n",
      "       1.00      2.00      7.00            35\n",
      "0.00   7.00      2.00      7.00            29\n",
      "       9.00      2.00      2.00            28\n",
      "1.00   7.00      7.00      1.00            23\n",
      "0.00   2.00      9.00      2.00            21\n",
      "1.00   1.00      7.00      7.00            20\n",
      "0.00   2.00      2.00      9.00            16\n",
      "1.00   7.00      1.00      7.00            12\n",
      "       1.00      9.00      2.00             7\n",
      "0.00   9.00      9.00      2.00             7\n",
      "1.00   1.00      1.00      9.00             3\n",
      "0.00   9.00      2.00      9.00             3\n",
      "       2.00      9.00      9.00             3\n",
      "1.00   2.00      9.00      1.00             2\n",
      "0.00   9.00      7.00      2.00             2\n",
      "1.00   9.00      1.00      2.00             2\n",
      "       2.00      1.00      9.00             1\n",
      "       9.00      1.00      9.00             1\n",
      "dtype: int64\n",
      "81\n",
      "2.00    317909\n",
      "1.00     18279\n",
      "7.00      2737\n",
      "9.00        73\n",
      "Name: CVDCRHD4, dtype: int64 \n",
      "\n",
      "2.00    319602\n",
      "1.00     17850\n",
      "7.00      1476\n",
      "9.00        70\n",
      "Name: CVDINFR4, dtype: int64 \n",
      "\n",
      "2.00    324906\n",
      "1.00     13244\n",
      "7.00       791\n",
      "9.00        57\n",
      "Name: CVDSTRK3, dtype: int64 \n",
      "\n",
      "0.00    302202\n",
      "1.00     36715\n",
      "Name: Heart, dtype: int64 \n",
      "\n",
      "Diabetes  DIABETE4\n",
      "0.00      3.00        283623\n",
      "1.00      1.00         44343\n",
      "0.00      4.00          7698\n",
      "          2.00          2920\n",
      "dtype: int64\n",
      "414\n",
      "3.00    283623\n",
      "1.00     44343\n",
      "4.00      7698\n",
      "2.00      2920\n",
      "7.00       350\n",
      "9.00        64\n",
      "Name: DIABETE4, dtype: int64 \n",
      "\n",
      "   ADDEPEV3  _CASTHM1  CHCCOPD3  CHCSCNCR  CHCOCNCR  CVDCRHD4  CVDINFR4  \\\n",
      "0      2.00      2.00      1.00      2.00      2.00      2.00      2.00   \n",
      "2      2.00      1.00      2.00      2.00      2.00      1.00      2.00   \n",
      "3      2.00      1.00      2.00      2.00      2.00      2.00      2.00   \n",
      "4      2.00      1.00      2.00      2.00      2.00      7.00      1.00   \n",
      "5      2.00      1.00      1.00      2.00      2.00      2.00      2.00   \n",
      "\n",
      "   CVDSTRK3  DIABETE4  _AGE_G  ...  FRNCHDA_   _BMI5  CHCKDNY2  VETERAN3  \\\n",
      "0      2.00      3.00    6.00  ...     43.00 1454.00      2.00      2.00   \n",
      "2      2.00      1.00    6.00  ...     14.00 2829.00      2.00      2.00   \n",
      "3      2.00      1.00    5.00  ...     57.00 3347.00      2.00      2.00   \n",
      "4      1.00      1.00    6.00  ...     29.00 2873.00      2.00      2.00   \n",
      "5      2.00      3.00    6.00  ...      0.00 2437.00      2.00      2.00   \n",
      "\n",
      "   Depression  Asthma  COPD  Cancer  Heart  Diabetes  \n",
      "0        0.00    0.00  1.00    0.00   0.00      0.00  \n",
      "2        0.00    1.00  0.00    0.00   1.00      1.00  \n",
      "3        0.00    1.00  0.00    0.00   0.00      1.00  \n",
      "4        0.00    1.00  0.00    0.00   1.00      1.00  \n",
      "5        0.00    1.00  1.00    0.00   0.00      0.00  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2021                                                                      '''\n",
    "###############################################################################################################################################################################\n",
    "## Binary Comorbidity Response Features from our respective responses\n",
    "# Create the Depression comorbidity variable\n",
    "df_21_trim['Depression'] = df_21_trim.apply(lambda row: 1 if row[0] == 1 else (0 if row[0] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['Depression', 'ADDEPEV3']].value_counts())\n",
    "print(df_21_trim['Depression'].isnull().sum())\n",
    "print(df_21_trim['ADDEPEV3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Asthma comorbidity variable\n",
    "df_21_trim['Asthma'] = df_21_trim.apply(lambda row: 1 if row[1] == 1 else (0 if row[1] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['Asthma', '_CASTHM1']].value_counts())\n",
    "print(df_21_trim['Asthma'].isnull().sum())\n",
    "print(df_21_trim['_CASTHM1'].value_counts(), '\\n')\n",
    "\n",
    "# Create the COPD comorbidity variable\n",
    "df_21_trim['COPD'] = df_21_trim.apply(lambda row: 1 if row[2] == 1 else (0 if row[2] == 2 else np.NAN), axis=1)\n",
    "print(df_21_trim[['COPD', 'CHCCOPD3']].value_counts())\n",
    "print(df_21_trim['COPD'].isnull().sum())\n",
    "print(df_21_trim['CHCCOPD3'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Cancer comorbidity variable\n",
    "df_21_trim['Cancer'] = df_21_trim.apply(lambda row: 1 if row[3] == 1 else (1 if row[4] == 1 else (0 if row[3] == 2 else ( 0 if row[4] == 2 else np.NAN))), axis=1)\n",
    "print(df_21_trim[['Cancer', 'CHCSCNCR', 'CHCOCNCR']].value_counts())\n",
    "print(df_21_trim['Cancer'].isnull().sum())\n",
    "print(df_21_trim['CHCSCNCR'].value_counts(), '\\n')\n",
    "print(df_21_trim['CHCOCNCR'].value_counts(), '\\n')\n",
    "print(df_21_trim['Cancer'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Heart Condition comorbidity variable\n",
    "df_21_trim['Heart'] = df_21_trim.apply(lambda row: 1 if row[5] == 1 else (1 if row[6] == 1 else (1 if row[7] == 1 else (0 if row[5] == 2 else (0 if row[6] == 2 else (0 if row[7] == 2 else np.NAN))))), axis=1)\n",
    "print(df_21_trim[['Heart', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3']].value_counts())\n",
    "print(df_21_trim['Heart'].isnull().sum())\n",
    "print(df_21_trim['CVDCRHD4'].value_counts(), '\\n')\n",
    "print(df_21_trim['CVDINFR4'].value_counts(), '\\n')\n",
    "print(df_21_trim['CVDSTRK3'].value_counts(), '\\n')\n",
    "print(df_21_trim['Heart'].value_counts(), '\\n')\n",
    "\n",
    "# Create the Depression comorbidity variable\n",
    "df_21_trim['Diabetes'] = df_21_trim.apply(lambda row: 1 if row[8] == 1 else (0 if row[8] == 2 else (0 if row[8] == 3 else (0 if row[8] == 4 else np.NAN))), axis=1)\n",
    "print(df_21_trim[['Diabetes', 'DIABETE4']].value_counts())\n",
    "print(df_21_trim['Diabetes'].isnull().sum())\n",
    "print(df_21_trim['DIABETE4'].value_counts(), '\\n')\n",
    "\n",
    "print(df_21_trim.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Drop the coloumns no longer needed and any missing values introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_19_trim Original Shape_\t (330505, 33)\n",
      "df_19_trim New Shape_\t (325245, 24) \n",
      "\n",
      "df_21_trim Original Shape_\t (338998, 33)\n",
      "df_19_trim New Shape_\t (333899, 24)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Re-Clean Data fropm both years                                                                        '''\n",
    "###############################################################################################################################################################################\n",
    "## First we need to drop the columns we no longer need and then the new NaNs for 2019\n",
    "print('df_19_trim Original Shape_\\t', df_19_trim.shape)\n",
    "df_19_trim.drop(columns=['ADDEPEV3', '_CASTHM1', 'CHCCOPD2', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3', 'DIABETE4'], inplace=True)\n",
    "df_19_trim.dropna(inplace= True)\n",
    "print('df_19_trim New Shape_\\t', df_19_trim.shape, '\\n')\n",
    "\n",
    "## First we need to drop the columns we no longer need and then the new NaNs for 2021\n",
    "print('df_21_trim Original Shape_\\t', df_21_trim.shape)\n",
    "df_21_trim.drop(columns=['ADDEPEV3', '_CASTHM1', 'CHCCOPD3', 'CHCSCNCR', 'CHCOCNCR', 'CVDCRHD4', 'CVDINFR4', 'CVDSTRK3', 'DIABETE4'], inplace=True)\n",
    "df_21_trim.dropna(inplace= True)\n",
    "print('df_19_trim New Shape_\\t', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= yellow>Now we can move on to our last Comorbidity Variable for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                                   Convert Response Column for 2019/2021                                                                 '''\n",
    "###############################################################################################################################################################################\n",
    "## Multiclass Response from the Binary Comorbidities\n",
    "# First for 2019\n",
    "df_19_trim['Comorbidity'] = df_19_trim.apply(lambda row: 1 if row[18] == 1 else (1 if row[19] == 1 else (1 if row[20] == 1 else (1 if row[21] == 1 else (1 if row[22] == 1 else (1 if row[23] == 1 else 0))))), axis=1)\n",
    "\n",
    "# Then for 2021\n",
    "df_21_trim['Comorbidity'] = df_21_trim.apply(lambda row: 1 if row[18] == 1 else (1 if row[19] == 1 else (1 if row[20] == 1 else (1 if row[21] == 1 else (1 if row[22] == 1 else (1 if row[23] == 1 else 0))))), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 6: Make sure there are no NaNs left over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values by field (Pre-Interpolate):\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME3        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "_AGE_G         0\n",
      "MARITAL        0\n",
      "_SEX           0\n",
      "INCOME2        0\n",
      "_EDUCAG        0\n",
      "_RACE          0\n",
      "_METSTAT       0\n",
      "CHECKUP1       0\n",
      "BPMEDS         0\n",
      "_TOTINDA       0\n",
      "_SMOKER3       0\n",
      "_DRNKWK1       0\n",
      "_FRUTSU1       0\n",
      "_VEGESU1       0\n",
      "FRNCHDA_       0\n",
      "_BMI5          0\n",
      "CHCKDNY2       0\n",
      "VETERAN3       0\n",
      "Depression     0\n",
      "Asthma         0\n",
      "COPD           0\n",
      "Cancer         0\n",
      "Heart          0\n",
      "Diabetes       0\n",
      "Comorbidity    0\n",
      "dtype: int64 \n",
      "\n",
      "Final Shapes:\n",
      " (325245, 25) \n",
      " (333899, 25)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################################################\n",
    "'''                                                            Check for missing values again for 2019/2021                                                                 '''\n",
    "###############################################################################################################################################################################\n",
    "# output how many NaN there is per column\n",
    "print('Missing values by field (Pre-Interpolate):')\n",
    "\n",
    "# Visualize the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "# We can see that there is one column left in each that have a different name so let us fix this now\n",
    "df_21_trim = df_21_trim.rename(columns={'INCOME3': 'INCOME2'})\n",
    "\n",
    "# Recheck by visualizing the finished Data Frame\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_19_trim.isnull().sum(), '\\n')\n",
    "    print(df_21_trim.isnull().sum(), '\\n')\n",
    "\n",
    "# Final shape of DF's\n",
    "print('Final Shapes:\\n', df_19_trim.shape, '\\n', df_21_trim.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color= lightblue> Step 6: Merge Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   _AGE_G  MARITAL  _SEX  INCOME2  _EDUCAG  _RACE  _METSTAT  CHECKUP1  BPMEDS  \\\n0    6.00     2.00  2.00     3.00     1.00   2.00      1.00      1.00    1.00   \n1    6.00     1.00  2.00     5.00     3.00   1.00      1.00      1.00    2.00   \n2    6.00     3.00  2.00     7.00     4.00   2.00      1.00      1.00    1.00   \n4    6.00     1.00  2.00    99.00     3.00   1.00      2.00      1.00    2.00   \n6    6.00     2.00  1.00     7.00     4.00   1.00      2.00      1.00    2.00   \n\n   _TOTINDA  ...   _BMI5  CHCKDNY2  VETERAN3  Depression  Asthma  COPD  \\\n0      2.00  ... 2817.00      2.00      2.00        0.00    1.00  0.00   \n1      1.00  ... 1854.00      2.00      2.00        0.00    1.00  0.00   \n2      1.00  ... 3162.00      2.00      2.00        0.00    1.00  0.00   \n4      2.00  ... 2148.00      2.00      2.00        0.00    1.00  0.00   \n6      1.00  ... 3298.00      2.00      2.00        0.00    0.00  1.00   \n\n   Cancer  Heart  Diabetes  Comorbidity  \n0    0.00   0.00      0.00            1  \n1    0.00   0.00      0.00            1  \n2    0.00   0.00      1.00            1  \n4    0.00   0.00      0.00            1  \n6    0.00   0.00      1.00            1  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_AGE_G</th>\n      <th>MARITAL</th>\n      <th>_SEX</th>\n      <th>INCOME2</th>\n      <th>_EDUCAG</th>\n      <th>_RACE</th>\n      <th>_METSTAT</th>\n      <th>CHECKUP1</th>\n      <th>BPMEDS</th>\n      <th>_TOTINDA</th>\n      <th>...</th>\n      <th>_BMI5</th>\n      <th>CHCKDNY2</th>\n      <th>VETERAN3</th>\n      <th>Depression</th>\n      <th>Asthma</th>\n      <th>COPD</th>\n      <th>Cancer</th>\n      <th>Heart</th>\n      <th>Diabetes</th>\n      <th>Comorbidity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>2817.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>5.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1854.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>4.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3162.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>99.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>...</td>\n      <td>2148.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>7.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3298.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_19_trim, df_21_trim])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         _AGE_G   MARITAL      _SEX   INCOME2   _EDUCAG     _RACE  _METSTAT  \\\ncount 659144.00 659144.00 659144.00 659144.00 659144.00 659144.00 659144.00   \nmean       4.42      2.31      1.53     18.67      3.06      1.97      1.31   \nstd        1.59      1.72      0.50     29.69      0.97      2.21      0.46   \nmin        1.00      1.00      1.00      1.00      1.00      1.00      1.00   \n25%        3.00      1.00      1.00      5.00      2.00      1.00      1.00   \n50%        5.00      1.00      2.00      7.00      3.00      1.00      1.00   \n75%        6.00      3.00      2.00      9.00      4.00      1.00      2.00   \nmax        6.00      9.00      2.00     99.00      9.00      9.00      2.00   \n\n       CHECKUP1    BPMEDS  _TOTINDA  ...     _BMI5  CHCKDNY2  VETERAN3  \\\ncount 659144.00 659144.00 659144.00  ... 659144.00 659144.00 659144.00   \nmean       1.43      1.67      1.25  ...   2847.10      1.97      1.88   \nstd        1.04      0.47      0.51  ...    647.48      0.33      0.41   \nmin        1.00      1.00      1.00  ...   1200.00      1.00      1.00   \n25%        1.00      1.00      1.00  ...   2412.00      2.00      2.00   \n50%        1.00      2.00      1.00  ...   2741.00      2.00      2.00   \n75%        1.00      2.00      1.00  ...   3162.00      2.00      2.00   \nmax        9.00      2.00      9.00  ...   9933.00      9.00      9.00   \n\n       Depression    Asthma      COPD    Cancer     Heart  Diabetes  \\\ncount   659144.00 659144.00 659144.00 659144.00 659144.00 659144.00   \nmean         0.20      0.90      0.08      0.18      0.11      0.13   \nstd          0.40      0.29      0.27      0.38      0.32      0.34   \nmin          0.00      0.00      0.00      0.00      0.00      0.00   \n25%          0.00      1.00      0.00      0.00      0.00      0.00   \n50%          0.00      1.00      0.00      0.00      0.00      0.00   \n75%          0.00      1.00      0.00      0.00      0.00      0.00   \nmax          1.00      1.00      1.00      1.00      1.00      1.00   \n\n       Comorbidity  \ncount    659144.00  \nmean          0.97  \nstd           0.18  \nmin           0.00  \n25%           1.00  \n50%           1.00  \n75%           1.00  \nmax           1.00  \n\n[8 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_AGE_G</th>\n      <th>MARITAL</th>\n      <th>_SEX</th>\n      <th>INCOME2</th>\n      <th>_EDUCAG</th>\n      <th>_RACE</th>\n      <th>_METSTAT</th>\n      <th>CHECKUP1</th>\n      <th>BPMEDS</th>\n      <th>_TOTINDA</th>\n      <th>...</th>\n      <th>_BMI5</th>\n      <th>CHCKDNY2</th>\n      <th>VETERAN3</th>\n      <th>Depression</th>\n      <th>Asthma</th>\n      <th>COPD</th>\n      <th>Cancer</th>\n      <th>Heart</th>\n      <th>Diabetes</th>\n      <th>Comorbidity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>...</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n      <td>659144.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.42</td>\n      <td>2.31</td>\n      <td>1.53</td>\n      <td>18.67</td>\n      <td>3.06</td>\n      <td>1.97</td>\n      <td>1.31</td>\n      <td>1.43</td>\n      <td>1.67</td>\n      <td>1.25</td>\n      <td>...</td>\n      <td>2847.10</td>\n      <td>1.97</td>\n      <td>1.88</td>\n      <td>0.20</td>\n      <td>0.90</td>\n      <td>0.08</td>\n      <td>0.18</td>\n      <td>0.11</td>\n      <td>0.13</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.59</td>\n      <td>1.72</td>\n      <td>0.50</td>\n      <td>29.69</td>\n      <td>0.97</td>\n      <td>2.21</td>\n      <td>0.46</td>\n      <td>1.04</td>\n      <td>0.47</td>\n      <td>0.51</td>\n      <td>...</td>\n      <td>647.48</td>\n      <td>0.33</td>\n      <td>0.41</td>\n      <td>0.40</td>\n      <td>0.29</td>\n      <td>0.27</td>\n      <td>0.38</td>\n      <td>0.32</td>\n      <td>0.34</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1200.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>2412.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>2741.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>3162.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>99.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>9933.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(659144, 25)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color= white>The final Data Frames have the following Response Columns<font color= red>\n",
    "\n",
    "* Depression\n",
    "* Asthma\n",
    "* COPD\n",
    "* Cancer\n",
    "* Heart\n",
    "* Diabetes\n",
    "* Comorbidity\n",
    "\n",
    "<font color=white>And the following Feature Space<font color= red>\n",
    "\n",
    "* _AGE_G\n",
    "* MARITAL\n",
    "* _SEX\n",
    "* INCOME2\n",
    "* _EDUCAG\n",
    "* _RACE\n",
    "* _METSTAT\n",
    "* CHECKUP1\n",
    "* BPMEDS\n",
    "* _TOTINDA\n",
    "* _SMOKER3\n",
    "* _DRNKWK1\n",
    "* _FRUTSU1\n",
    "* _VEGESU1\n",
    "* FRNCHDA_\n",
    "* _BMI5\n",
    "* CHCKDNY2\n",
    "* VETERAN3\n",
    "\n",
    "<font color=white>The shapes of the different Dat Frames are as follows:<font color= red>\n",
    "\n",
    "1. 2019: <br>\n",
    "325245, 25<br><br>\n",
    "2. 2021: <br>\n",
    "333899, 25<br><br>\n",
    "3. Merged: <br>\n",
    "659144, 25<br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis 1\n",
    "Using both years, run exploratory data analysis using crosstabs, visuals, and basic frequency distributions to understand how chronic conditions are distribituted across geography and demography. You may also use the newly created comorbidity variables for this analysis. \n",
    "\n",
    "- Summarize salient features of the healthiest and least healthy states in the country.\n",
    "- Discuss if you noticed any associations of the risk factors such as Age, Sex, Income, Education, Marital Status etc. with the level of comorbidities, while comparing the two years of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis 2\n",
    "1. Using only 2021, use several classification algorithms to classify comorbility variables 1 and 2:\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- RF\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "- Catboost\n",
    "\n",
    "2. Write a short report describing the performance metrics. \n",
    "3. In the end, choose one model each for the classification of both categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Packages Used"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Test Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature space size:  (333899, 18) \n",
      "\n",
      "Response size:\n",
      "Binary:  (333899, 1)\n",
      "Multi:  (333899,) \n",
      "\n",
      "Train set for binary case (581113, 18)\n",
      "Train set for multi case (1107225, 18)\n"
     ]
    }
   ],
   "source": [
    "# Get feature space and response\n",
    "multi = ['Depression', 'Asthma', 'COPD', 'Cancer', 'Heart', 'Diabetes']\n",
    "binary = ['Comorbidity']\n",
    "\n",
    "# Feature space\n",
    "X = df_21_trim.copy()\n",
    "X.drop(binary, inplace=True, axis=1)\n",
    "X.drop(multi, inplace=True, axis=1)\n",
    "print('Feature space size: ', X.shape, '\\n')\n",
    "\n",
    "# Standarize\n",
    "std = ['_DRNKWK1', '_FRUTSU1', '_VEGESU1', 'FRNCHDA_', '_BMI5']\n",
    "scalar = StandardScaler()\n",
    "X[std] = scalar.fit_transform(X[std])\n",
    "\n",
    "# Response\n",
    "y_binary = df_21_trim[binary].copy()\n",
    "y_multi = df_21_trim.apply(lambda row: sum(row[multi]), axis=1)\n",
    "print('Response size:')\n",
    "print('Binary: ', y_binary.shape)\n",
    "print('Multi: ', y_multi.shape, '\\n')\n",
    "\n",
    "# Train Test Split\n",
    "# Since we have many rows, 10% test is enough.\n",
    "# Responses are highly imbalanced, so we over sample for each response.\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled_binary, y_resampled_binary = ros.fit_resample(X, y_binary)\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_resampled_binary, y_resampled_binary, test_size=0.1, random_state=42)\n",
    "X_train_binary.reset_index(inplace=True, drop=True)\n",
    "X_test_binary.reset_index(inplace=True, drop=True)\n",
    "y_train_binary.reset_index(inplace=True, drop=True)\n",
    "y_test_binary.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled_multi, y_resampled_multi = ros.fit_resample(X, y_multi)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_resampled_multi, y_resampled_multi, test_size=0.1, random_state=42)\n",
    "X_train_multi.reset_index(inplace=True, drop=True)\n",
    "X_test_multi.reset_index(inplace=True, drop=True)\n",
    "y_train_multi.reset_index(inplace=True, drop=True)\n",
    "y_test_multi.reset_index(inplace=True, drop=True)\n",
    "print('Train set for binary case', X_train_binary.shape)\n",
    "print('Train set for multi case', X_train_multi.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistic Regresison"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the binary case, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61     32363\n",
      "           1       0.61      0.61      0.61     32206\n",
      "\n",
      "    accuracy                           0.61     64569\n",
      "   macro avg       0.61      0.61      0.61     64569\n",
      "weighted avg       0.61      0.61      0.61     64569\n",
      "\n",
      "Best parameters are:  {'C': 1}\n",
      "Best score on train set is:  0.6092343494889769\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          19673  12628\n",
      "1          12690  19578\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "lgr = LogisticRegression(random_state=42,\n",
    "                         class_weight='balanced')\n",
    "parameters = {\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "# Grid search for binary case\n",
    "clf = GridSearchCV(lgr, param_grid=parameters)\n",
    "clf.fit(X_train_binary, y_train_binary)\n",
    "y_predict = clf.predict(X_test_binary)\n",
    "print('For the binary case, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print('Best parameters are: ', clf.best_params_)\n",
    "print('Best score on train set is: ', clf.best_score_)\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.43      0.40     17896\n",
      "         1.0       0.38      0.34      0.36     17641\n",
      "         2.0       0.21      0.16      0.18     17445\n",
      "         3.0       0.19      0.22      0.20     17475\n",
      "         4.0       0.22      0.15      0.18     17440\n",
      "         5.0       0.29      0.14      0.19     17583\n",
      "         6.0       0.31      0.59      0.41     17545\n",
      "\n",
      "    accuracy                           0.29    123025\n",
      "   macro avg       0.28      0.29      0.27    123025\n",
      "weighted avg       0.28      0.29      0.27    123025\n",
      "\n",
      "Best parameters are:  {'C': 1}\n",
      "Best score on train set is:  0.2884318905371537\n",
      "y_test     0.00  1.00  2.00  3.00  4.00  5.00   6.00\n",
      "y_predict                                           \n",
      "0.00       7671  5244  3987  1889   851   507     99\n",
      "1.00       4414  6083  2984  1319   767   510     98\n",
      "2.00       2212  2272  2774  2512  1589  1147    612\n",
      "3.00       1905  2073  3265  3774  3283  2441   2984\n",
      "4.00        565   703  1490  2347  2569  2284   1896\n",
      "5.00        309   368   715  1233  1790  2399   1462\n",
      "6.00        820   898  2230  4401  6591  8295  10394\n",
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.43      0.40     17896\n",
      "         1.0       0.38      0.34      0.36     17641\n",
      "         2.0       0.21      0.16      0.18     17445\n",
      "         3.0       0.19      0.22      0.20     17475\n",
      "         4.0       0.22      0.15      0.18     17440\n",
      "         5.0       0.29      0.14      0.19     17583\n",
      "         6.0       0.31      0.59      0.41     17545\n",
      "\n",
      "    accuracy                           0.29    123025\n",
      "   macro avg       0.28      0.29      0.27    123025\n",
      "weighted avg       0.28      0.29      0.27    123025\n",
      "\n",
      "Best parameters are:  {'C': 1}\n",
      "Best score on train set is:  0.2884318905371537\n",
      "y_test     0.00  1.00  2.00  3.00  4.00  5.00   6.00\n",
      "y_predict                                           \n",
      "0.00       7671  5244  3987  1889   851   507     99\n",
      "1.00       4414  6083  2984  1319   767   510     98\n",
      "2.00       2212  2272  2774  2512  1589  1147    612\n",
      "3.00       1905  2073  3265  3774  3283  2441   2984\n",
      "4.00        565   703  1490  2347  2569  2284   1896\n",
      "5.00        309   368   715  1233  1790  2399   1462\n",
      "6.00        820   898  2230  4401  6591  8295  10394\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "lgr = LogisticRegression(random_state=42,\n",
    "                         class_weight='balanced')\n",
    "parameters = {\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1],\n",
    "}\n",
    "\n",
    "# Grid search for multi response\n",
    "clf = GridSearchCV(lgr, param_grid=parameters)\n",
    "clf.fit(X_train_multi, y_train_multi)\n",
    "y_predict = clf.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print('Best parameters are: ', clf.best_params_)\n",
    "print('Best score on train set is: ', clf.best_score_)\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the binary case, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     32363\n",
      "           1       1.00      0.90      0.95     32206\n",
      "\n",
      "    accuracy                           0.95     64569\n",
      "   macro avg       0.95      0.95      0.95     64569\n",
      "weighted avg       0.95      0.95      0.95     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          32363   3316\n",
      "1              0  28890\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size=10)\n",
    "\n",
    "# Train and test binary case\n",
    "knn.fit(X_train_binary, y_train_binary)\n",
    "y_predict = knn.predict(X_test_binary)\n",
    "print('For the binary case, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92     17896\n",
      "         1.0       0.63      0.45      0.53     17641\n",
      "         2.0       0.61      0.48      0.54     17445\n",
      "         3.0       0.75      0.90      0.81     17475\n",
      "         4.0       0.91      1.00      0.95     17440\n",
      "         5.0       0.98      1.00      0.99     17583\n",
      "         6.0       1.00      1.00      1.00     17545\n",
      "\n",
      "    accuracy                           0.83    123025\n",
      "   macro avg       0.82      0.83      0.82    123025\n",
      "weighted avg       0.82      0.83      0.82    123025\n",
      "\n",
      "y_test      0.00  1.00  2.00   3.00   4.00   5.00   6.00\n",
      "y_predict                                               \n",
      "0.00       17896  1942  1160    137      0      0      0\n",
      "1.00           0  7920  4047    547      0      0      0\n",
      "2.00           0  4553  8385    908      3      0      0\n",
      "3.00           0  2493  2792  15641      0      0      0\n",
      "4.00           0   618   875    200  17437      0      0\n",
      "5.00           0   102   163     42      0  17583      0\n",
      "6.00           0    13    23      0      0      0  17545\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size=10)\n",
    "\n",
    "\n",
    "# Train and test for multi response\n",
    "knn.fit(X_train_multi, y_train_multi)\n",
    "y_predict = knn.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the binary response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     32363\n",
      "           1       1.00      1.00      1.00     32206\n",
      "\n",
      "    accuracy                           1.00     64569\n",
      "   macro avg       1.00      1.00      1.00     64569\n",
      "weighted avg       1.00      1.00      1.00     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          32363      2\n",
      "1              0  32204\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "rf = RandomForestClassifier(n_jobs=5)\n",
    "\n",
    "# Train and test for binary response\n",
    "rf.fit(X_train_binary, y_train_binary)\n",
    "y_predict = rf.predict(X_test_binary)\n",
    "print('For the binary response, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     17896\n",
      "         1.0       0.83      0.75      0.79     17641\n",
      "         2.0       0.79      0.82      0.80     17445\n",
      "         3.0       0.94      0.99      0.97     17475\n",
      "         4.0       1.00      1.00      1.00     17440\n",
      "         5.0       1.00      1.00      1.00     17583\n",
      "         6.0       1.00      1.00      1.00     17545\n",
      "\n",
      "    accuracy                           0.94    123025\n",
      "   macro avg       0.94      0.94      0.94    123025\n",
      "weighted avg       0.94      0.94      0.94    123025\n",
      "\n",
      "y_test      0.00   1.00   2.00   3.00   4.00   5.00   6.00\n",
      "y_predict                                                 \n",
      "0.00       17896     20      3      0      0      0      0\n",
      "1.00           0  13204   2680     37      0      0      0\n",
      "2.00           0   3777  14274     63      0      0      0\n",
      "3.00           0    604    450  17368      0      0      0\n",
      "4.00           0     35     37      7  17440      0      0\n",
      "5.00           0      1      1      0      0  17583      0\n",
      "6.00           0      0      0      0      0      0  17545\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "rf = RandomForestClassifier(n_jobs=5)\n",
    "\n",
    "# Train and test for multi response\n",
    "rf.fit(X_train_multi, y_train_multi)\n",
    "y_predict = rf.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the binary response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.64     32363\n",
      "           1       0.64      0.58      0.61     32206\n",
      "\n",
      "    accuracy                           0.63     64569\n",
      "   macro avg       0.63      0.63      0.63     64569\n",
      "weighted avg       0.63      0.63      0.63     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          21880  13636\n",
      "1          10483  18570\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Train and test for binary response\n",
    "gbc.fit(X_train_binary, y_train_binary)\n",
    "y_predict = gbc.predict(X_test_binary)\n",
    "print('For the binary response, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.47      0.43     17896\n",
      "         1.0       0.40      0.35      0.37     17641\n",
      "         2.0       0.25      0.21      0.23     17445\n",
      "         3.0       0.24      0.18      0.21     17475\n",
      "         4.0       0.31      0.23      0.26     17440\n",
      "         5.0       0.45      0.50      0.47     17583\n",
      "         6.0       0.59      0.88      0.70     17545\n",
      "\n",
      "    accuracy                           0.40    123025\n",
      "   macro avg       0.38      0.40      0.38    123025\n",
      "weighted avg       0.38      0.40      0.38    123025\n",
      "\n",
      "y_test     0.00  1.00  2.00  3.00  4.00  5.00   6.00\n",
      "y_predict                                           \n",
      "0.00       8362  5716  4174  1805   633   258      0\n",
      "1.00       4125  6117  2825  1242   621   215    192\n",
      "2.00       2362  2552  3648  2949  1730   991    535\n",
      "3.00       1313  1394  2401  3219  2556  1813    536\n",
      "4.00        746   832  1682  2948  3969  2000    611\n",
      "5.00        593   573  1547  3198  4760  8810    276\n",
      "6.00        395   457  1168  2114  3171  3496  15395\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Train and test for multi response\n",
    "gbc.fit(X_train_multi, y_train_multi)\n",
    "y_predict = gbc.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the binary response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73     32363\n",
      "           1       0.75      0.61      0.67     32206\n",
      "\n",
      "    accuracy                           0.70     64569\n",
      "   macro avg       0.71      0.70      0.70     64569\n",
      "weighted avg       0.71      0.70      0.70     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          25720  12630\n",
      "1           6643  19576\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "xbc = xgb.XGBClassifier(n_estimators=100,\n",
    "\t\t\t\t\t\tmax_depth=10,\n",
    "\t\t\t\t\t\teta=0.01,\n",
    "\t\t\t\t\t\tmin_child_weight=5,\n",
    "\t\t\t\t\t\trandom_state=100)\n",
    "\n",
    "# Train and test for binary response\n",
    "xbc.fit(X_train_binary, y_train_binary)\n",
    "y_predict = xbc.predict(X_test_binary)\n",
    "print('For the binary response, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.60      0.53     17896\n",
      "         1.0       0.42      0.38      0.40     17641\n",
      "         2.0       0.31      0.23      0.26     17445\n",
      "         3.0       0.41      0.21      0.28     17475\n",
      "         4.0       0.50      0.46      0.48     17440\n",
      "         5.0       0.62      0.81      0.70     17583\n",
      "         6.0       0.73      1.00      0.85     17545\n",
      "\n",
      "    accuracy                           0.53    123025\n",
      "   macro avg       0.50      0.53      0.50    123025\n",
      "weighted avg       0.50      0.53      0.50    123025\n",
      "\n",
      "y_test      0.00  1.00  2.00  3.00  4.00   5.00   6.00\n",
      "y_predict                                             \n",
      "0          10745  5445  3942  1723   551    131      0\n",
      "1           3398  6645  3393  1532   573     95      0\n",
      "2           1595  2522  4014  3026  1524    365      0\n",
      "3            656   940  1598  3644  1541    537      0\n",
      "4            649  1023  2102  3297  7966    752      0\n",
      "5            516   698  1528  2740  3344  14307      0\n",
      "6            337   368   868  1513  1941   1396  17545\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "xbg = xgb.XGBClassifier(n_estimators=100,\n",
    "\t\t\t\t\t\tmax_depth=10,\n",
    "\t\t\t\t\t\teta=0.01,\n",
    "\t\t\t\t\t\tmin_child_weight=5,\n",
    "\t\t\t\t\t\trandom_state=100)\n",
    "\n",
    "# Train and test for multi response\n",
    "xbg.fit(X_train_multi, y_train_multi)\n",
    "y_predict = xbg.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6711616\ttotal: 27.9ms\tremaining: 27.9ms\n",
      "1:\tlearn: 0.6655812\ttotal: 41ms\tremaining: 0us\n",
      "For the binary response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64     32363\n",
      "           1       0.63      0.50      0.55     32206\n",
      "\n",
      "    accuracy                           0.60     64569\n",
      "   macro avg       0.61      0.60      0.60     64569\n",
      "weighted avg       0.60      0.60      0.60     64569\n",
      "\n",
      "y_test         0      1\n",
      "y_predict              \n",
      "0          22763  16174\n",
      "1           9600  16032\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "cbc = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True)\n",
    "\n",
    "# Train and test for binary response\n",
    "cbc.fit(X_train_binary, y_train_binary)\n",
    "y_predict = cbc.predict(X_test_binary)\n",
    "print('For the binary response, classification report on test set is:')\n",
    "print(classification_report(y_test_binary, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_binary.Comorbidity, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.11313\n",
      "0:\tlearn: 1.8906563\ttotal: 682ms\tremaining: 11m 20s\n",
      "1:\tlearn: 1.8475926\ttotal: 1.43s\tremaining: 11m 52s\n",
      "2:\tlearn: 1.8131224\ttotal: 1.88s\tremaining: 10m 24s\n",
      "3:\tlearn: 1.7843307\ttotal: 2.29s\tremaining: 9m 30s\n",
      "4:\tlearn: 1.7600900\ttotal: 2.69s\tremaining: 8m 56s\n",
      "5:\tlearn: 1.7376300\ttotal: 3.03s\tremaining: 8m 22s\n",
      "6:\tlearn: 1.7188428\ttotal: 3.28s\tremaining: 7m 45s\n",
      "7:\tlearn: 1.7029984\ttotal: 3.55s\tremaining: 7m 20s\n",
      "8:\tlearn: 1.6889682\ttotal: 3.85s\tremaining: 7m 3s\n",
      "9:\tlearn: 1.6767446\ttotal: 4.14s\tremaining: 6m 49s\n",
      "10:\tlearn: 1.6649258\ttotal: 4.42s\tremaining: 6m 37s\n",
      "11:\tlearn: 1.6545250\ttotal: 4.67s\tremaining: 6m 24s\n",
      "12:\tlearn: 1.6443511\ttotal: 4.97s\tremaining: 6m 17s\n",
      "13:\tlearn: 1.6360854\ttotal: 5.22s\tremaining: 6m 7s\n",
      "14:\tlearn: 1.6271393\ttotal: 5.52s\tremaining: 6m 2s\n",
      "15:\tlearn: 1.6193288\ttotal: 5.78s\tremaining: 5m 55s\n",
      "16:\tlearn: 1.6131532\ttotal: 6.06s\tremaining: 5m 50s\n",
      "17:\tlearn: 1.6074141\ttotal: 6.31s\tremaining: 5m 44s\n",
      "18:\tlearn: 1.6015096\ttotal: 6.56s\tremaining: 5m 38s\n",
      "19:\tlearn: 1.5952895\ttotal: 6.91s\tremaining: 5m 38s\n",
      "20:\tlearn: 1.5892055\ttotal: 7.24s\tremaining: 5m 37s\n",
      "21:\tlearn: 1.5851519\ttotal: 7.57s\tremaining: 5m 36s\n",
      "22:\tlearn: 1.5797450\ttotal: 7.89s\tremaining: 5m 35s\n",
      "23:\tlearn: 1.5745432\ttotal: 8.14s\tremaining: 5m 31s\n",
      "24:\tlearn: 1.5685716\ttotal: 8.47s\tremaining: 5m 30s\n",
      "25:\tlearn: 1.5632927\ttotal: 8.82s\tremaining: 5m 30s\n",
      "26:\tlearn: 1.5585691\ttotal: 9.15s\tremaining: 5m 29s\n",
      "27:\tlearn: 1.5556434\ttotal: 9.57s\tremaining: 5m 32s\n",
      "28:\tlearn: 1.5516758\ttotal: 9.91s\tremaining: 5m 31s\n",
      "29:\tlearn: 1.5486186\ttotal: 10.2s\tremaining: 5m 28s\n",
      "30:\tlearn: 1.5445221\ttotal: 10.4s\tremaining: 5m 25s\n",
      "31:\tlearn: 1.5408558\ttotal: 10.7s\tremaining: 5m 22s\n",
      "32:\tlearn: 1.5383611\ttotal: 10.9s\tremaining: 5m 18s\n",
      "33:\tlearn: 1.5347936\ttotal: 11.1s\tremaining: 5m 16s\n",
      "34:\tlearn: 1.5307584\ttotal: 11.4s\tremaining: 5m 15s\n",
      "35:\tlearn: 1.5280945\ttotal: 11.7s\tremaining: 5m 13s\n",
      "36:\tlearn: 1.5261341\ttotal: 12s\tremaining: 5m 12s\n",
      "37:\tlearn: 1.5230193\ttotal: 12.3s\tremaining: 5m 10s\n",
      "38:\tlearn: 1.5205730\ttotal: 12.5s\tremaining: 5m 8s\n",
      "39:\tlearn: 1.5171309\ttotal: 12.8s\tremaining: 5m 8s\n",
      "40:\tlearn: 1.5146027\ttotal: 13.1s\tremaining: 5m 7s\n",
      "41:\tlearn: 1.5126274\ttotal: 13.3s\tremaining: 5m 4s\n",
      "42:\tlearn: 1.5093990\ttotal: 13.6s\tremaining: 5m 2s\n",
      "43:\tlearn: 1.5061330\ttotal: 13.9s\tremaining: 5m 1s\n",
      "44:\tlearn: 1.5041768\ttotal: 14.1s\tremaining: 4m 59s\n",
      "45:\tlearn: 1.5003168\ttotal: 14.4s\tremaining: 4m 57s\n",
      "46:\tlearn: 1.4980694\ttotal: 14.6s\tremaining: 4m 56s\n",
      "47:\tlearn: 1.4960987\ttotal: 14.8s\tremaining: 4m 54s\n",
      "48:\tlearn: 1.4936714\ttotal: 15.1s\tremaining: 4m 52s\n",
      "49:\tlearn: 1.4917738\ttotal: 15.4s\tremaining: 4m 52s\n",
      "50:\tlearn: 1.4896282\ttotal: 15.7s\tremaining: 4m 52s\n",
      "51:\tlearn: 1.4873356\ttotal: 16.1s\tremaining: 4m 54s\n",
      "52:\tlearn: 1.4854309\ttotal: 16.5s\tremaining: 4m 54s\n",
      "53:\tlearn: 1.4836838\ttotal: 16.7s\tremaining: 4m 53s\n",
      "54:\tlearn: 1.4818709\ttotal: 17s\tremaining: 4m 52s\n",
      "55:\tlearn: 1.4793484\ttotal: 17.3s\tremaining: 4m 52s\n",
      "56:\tlearn: 1.4779989\ttotal: 17.7s\tremaining: 4m 52s\n",
      "57:\tlearn: 1.4760996\ttotal: 17.9s\tremaining: 4m 51s\n",
      "58:\tlearn: 1.4741243\ttotal: 18.2s\tremaining: 4m 49s\n",
      "59:\tlearn: 1.4721199\ttotal: 18.5s\tremaining: 4m 49s\n",
      "60:\tlearn: 1.4701729\ttotal: 18.7s\tremaining: 4m 47s\n",
      "61:\tlearn: 1.4687857\ttotal: 18.9s\tremaining: 4m 46s\n",
      "62:\tlearn: 1.4669526\ttotal: 19.1s\tremaining: 4m 44s\n",
      "63:\tlearn: 1.4642202\ttotal: 19.4s\tremaining: 4m 43s\n",
      "64:\tlearn: 1.4631542\ttotal: 19.6s\tremaining: 4m 42s\n",
      "65:\tlearn: 1.4608340\ttotal: 19.9s\tremaining: 4m 41s\n",
      "66:\tlearn: 1.4590150\ttotal: 20.1s\tremaining: 4m 39s\n",
      "67:\tlearn: 1.4579869\ttotal: 20.3s\tremaining: 4m 38s\n",
      "68:\tlearn: 1.4565811\ttotal: 20.6s\tremaining: 4m 38s\n",
      "69:\tlearn: 1.4552785\ttotal: 20.9s\tremaining: 4m 37s\n",
      "70:\tlearn: 1.4541520\ttotal: 21.1s\tremaining: 4m 36s\n",
      "71:\tlearn: 1.4531454\ttotal: 21.4s\tremaining: 4m 35s\n",
      "72:\tlearn: 1.4516279\ttotal: 21.6s\tremaining: 4m 34s\n",
      "73:\tlearn: 1.4500991\ttotal: 21.9s\tremaining: 4m 33s\n",
      "74:\tlearn: 1.4488549\ttotal: 22.1s\tremaining: 4m 32s\n",
      "75:\tlearn: 1.4475600\ttotal: 22.4s\tremaining: 4m 31s\n",
      "76:\tlearn: 1.4460917\ttotal: 22.6s\tremaining: 4m 30s\n",
      "77:\tlearn: 1.4438944\ttotal: 22.8s\tremaining: 4m 29s\n",
      "78:\tlearn: 1.4421497\ttotal: 23.1s\tremaining: 4m 29s\n",
      "79:\tlearn: 1.4400252\ttotal: 23.4s\tremaining: 4m 28s\n",
      "80:\tlearn: 1.4382731\ttotal: 23.6s\tremaining: 4m 28s\n",
      "81:\tlearn: 1.4367110\ttotal: 23.9s\tremaining: 4m 27s\n",
      "82:\tlearn: 1.4356164\ttotal: 24.1s\tremaining: 4m 26s\n",
      "83:\tlearn: 1.4340028\ttotal: 24.5s\tremaining: 4m 27s\n",
      "84:\tlearn: 1.4324632\ttotal: 24.9s\tremaining: 4m 27s\n",
      "85:\tlearn: 1.4304945\ttotal: 25.2s\tremaining: 4m 27s\n",
      "86:\tlearn: 1.4290537\ttotal: 25.5s\tremaining: 4m 28s\n",
      "87:\tlearn: 1.4271249\ttotal: 25.9s\tremaining: 4m 28s\n",
      "88:\tlearn: 1.4251935\ttotal: 26.3s\tremaining: 4m 29s\n",
      "89:\tlearn: 1.4239751\ttotal: 26.6s\tremaining: 4m 29s\n",
      "90:\tlearn: 1.4219373\ttotal: 26.9s\tremaining: 4m 29s\n",
      "91:\tlearn: 1.4205787\ttotal: 27.3s\tremaining: 4m 28s\n",
      "92:\tlearn: 1.4192455\ttotal: 27.5s\tremaining: 4m 28s\n",
      "93:\tlearn: 1.4171276\ttotal: 27.9s\tremaining: 4m 28s\n",
      "94:\tlearn: 1.4157444\ttotal: 28.2s\tremaining: 4m 28s\n",
      "95:\tlearn: 1.4146452\ttotal: 28.4s\tremaining: 4m 27s\n",
      "96:\tlearn: 1.4135352\ttotal: 28.6s\tremaining: 4m 26s\n",
      "97:\tlearn: 1.4122678\ttotal: 28.9s\tremaining: 4m 25s\n",
      "98:\tlearn: 1.4103717\ttotal: 29.1s\tremaining: 4m 25s\n",
      "99:\tlearn: 1.4090746\ttotal: 29.4s\tremaining: 4m 24s\n",
      "100:\tlearn: 1.4073029\ttotal: 29.6s\tremaining: 4m 23s\n",
      "101:\tlearn: 1.4056805\ttotal: 29.9s\tremaining: 4m 23s\n",
      "102:\tlearn: 1.4044740\ttotal: 30.1s\tremaining: 4m 22s\n",
      "103:\tlearn: 1.4032483\ttotal: 30.4s\tremaining: 4m 21s\n",
      "104:\tlearn: 1.4018402\ttotal: 30.6s\tremaining: 4m 20s\n",
      "105:\tlearn: 1.4002605\ttotal: 30.9s\tremaining: 4m 20s\n",
      "106:\tlearn: 1.3991762\ttotal: 31.1s\tremaining: 4m 19s\n",
      "107:\tlearn: 1.3976321\ttotal: 31.4s\tremaining: 4m 19s\n",
      "108:\tlearn: 1.3964051\ttotal: 31.8s\tremaining: 4m 19s\n",
      "109:\tlearn: 1.3956361\ttotal: 32s\tremaining: 4m 19s\n",
      "110:\tlearn: 1.3943549\ttotal: 32.4s\tremaining: 4m 19s\n",
      "111:\tlearn: 1.3927066\ttotal: 32.6s\tremaining: 4m 18s\n",
      "112:\tlearn: 1.3909495\ttotal: 32.9s\tremaining: 4m 18s\n",
      "113:\tlearn: 1.3896929\ttotal: 33.2s\tremaining: 4m 17s\n",
      "114:\tlearn: 1.3882657\ttotal: 33.5s\tremaining: 4m 17s\n",
      "115:\tlearn: 1.3874548\ttotal: 33.7s\tremaining: 4m 17s\n",
      "116:\tlearn: 1.3864716\ttotal: 34s\tremaining: 4m 16s\n",
      "117:\tlearn: 1.3856931\ttotal: 34.2s\tremaining: 4m 15s\n",
      "118:\tlearn: 1.3843697\ttotal: 34.5s\tremaining: 4m 15s\n",
      "119:\tlearn: 1.3836307\ttotal: 34.8s\tremaining: 4m 15s\n",
      "120:\tlearn: 1.3824493\ttotal: 35s\tremaining: 4m 14s\n",
      "121:\tlearn: 1.3817518\ttotal: 35.2s\tremaining: 4m 13s\n",
      "122:\tlearn: 1.3808494\ttotal: 35.5s\tremaining: 4m 12s\n",
      "123:\tlearn: 1.3796313\ttotal: 35.7s\tremaining: 4m 12s\n",
      "124:\tlearn: 1.3784005\ttotal: 36s\tremaining: 4m 12s\n",
      "125:\tlearn: 1.3777403\ttotal: 36.3s\tremaining: 4m 11s\n",
      "126:\tlearn: 1.3770365\ttotal: 36.5s\tremaining: 4m 11s\n",
      "127:\tlearn: 1.3761375\ttotal: 36.8s\tremaining: 4m 10s\n",
      "128:\tlearn: 1.3752757\ttotal: 37.1s\tremaining: 4m 10s\n",
      "129:\tlearn: 1.3740944\ttotal: 37.4s\tremaining: 4m 10s\n",
      "130:\tlearn: 1.3728062\ttotal: 37.7s\tremaining: 4m 9s\n",
      "131:\tlearn: 1.3717813\ttotal: 38s\tremaining: 4m 9s\n",
      "132:\tlearn: 1.3705202\ttotal: 38.3s\tremaining: 4m 9s\n",
      "133:\tlearn: 1.3698587\ttotal: 38.5s\tremaining: 4m 9s\n",
      "134:\tlearn: 1.3690534\ttotal: 38.8s\tremaining: 4m 8s\n",
      "135:\tlearn: 1.3683848\ttotal: 39.1s\tremaining: 4m 8s\n",
      "136:\tlearn: 1.3671980\ttotal: 39.3s\tremaining: 4m 7s\n",
      "137:\tlearn: 1.3662889\ttotal: 39.6s\tremaining: 4m 7s\n",
      "138:\tlearn: 1.3651562\ttotal: 39.9s\tremaining: 4m 6s\n",
      "139:\tlearn: 1.3645125\ttotal: 40.1s\tremaining: 4m 6s\n",
      "140:\tlearn: 1.3633427\ttotal: 40.4s\tremaining: 4m 6s\n",
      "141:\tlearn: 1.3622022\ttotal: 40.7s\tremaining: 4m 5s\n",
      "142:\tlearn: 1.3612841\ttotal: 40.9s\tremaining: 4m 5s\n",
      "143:\tlearn: 1.3602341\ttotal: 41.2s\tremaining: 4m 5s\n",
      "144:\tlearn: 1.3592516\ttotal: 41.5s\tremaining: 4m 4s\n",
      "145:\tlearn: 1.3585214\ttotal: 41.7s\tremaining: 4m 4s\n",
      "146:\tlearn: 1.3580024\ttotal: 42s\tremaining: 4m 3s\n",
      "147:\tlearn: 1.3566218\ttotal: 42.3s\tremaining: 4m 3s\n",
      "148:\tlearn: 1.3554348\ttotal: 42.5s\tremaining: 4m 2s\n",
      "149:\tlearn: 1.3549756\ttotal: 42.7s\tremaining: 4m 2s\n",
      "150:\tlearn: 1.3541114\ttotal: 43s\tremaining: 4m 1s\n",
      "151:\tlearn: 1.3529185\ttotal: 43.3s\tremaining: 4m 1s\n",
      "152:\tlearn: 1.3520282\ttotal: 43.6s\tremaining: 4m 1s\n",
      "153:\tlearn: 1.3510859\ttotal: 43.8s\tremaining: 4m\n",
      "154:\tlearn: 1.3502346\ttotal: 44s\tremaining: 4m\n",
      "155:\tlearn: 1.3494884\ttotal: 44.2s\tremaining: 3m 59s\n",
      "156:\tlearn: 1.3487731\ttotal: 44.5s\tremaining: 3m 58s\n",
      "157:\tlearn: 1.3476370\ttotal: 44.7s\tremaining: 3m 58s\n",
      "158:\tlearn: 1.3469376\ttotal: 45s\tremaining: 3m 57s\n",
      "159:\tlearn: 1.3464256\ttotal: 45.2s\tremaining: 3m 57s\n",
      "160:\tlearn: 1.3453734\ttotal: 45.4s\tremaining: 3m 56s\n",
      "161:\tlearn: 1.3443161\ttotal: 45.8s\tremaining: 3m 56s\n",
      "162:\tlearn: 1.3437739\ttotal: 46.1s\tremaining: 3m 56s\n",
      "163:\tlearn: 1.3431391\ttotal: 47s\tremaining: 3m 59s\n",
      "164:\tlearn: 1.3422749\ttotal: 47.4s\tremaining: 4m\n",
      "165:\tlearn: 1.3413248\ttotal: 47.8s\tremaining: 4m\n",
      "166:\tlearn: 1.3405765\ttotal: 48.1s\tremaining: 4m\n",
      "167:\tlearn: 1.3395214\ttotal: 48.4s\tremaining: 3m 59s\n",
      "168:\tlearn: 1.3386793\ttotal: 48.7s\tremaining: 3m 59s\n",
      "169:\tlearn: 1.3377482\ttotal: 48.9s\tremaining: 3m 58s\n",
      "170:\tlearn: 1.3366726\ttotal: 49.2s\tremaining: 3m 58s\n",
      "171:\tlearn: 1.3361638\ttotal: 49.4s\tremaining: 3m 57s\n",
      "172:\tlearn: 1.3351435\ttotal: 49.7s\tremaining: 3m 57s\n",
      "173:\tlearn: 1.3340447\ttotal: 50s\tremaining: 3m 57s\n",
      "174:\tlearn: 1.3330507\ttotal: 50.3s\tremaining: 3m 57s\n",
      "175:\tlearn: 1.3321648\ttotal: 50.5s\tremaining: 3m 56s\n",
      "176:\tlearn: 1.3312495\ttotal: 50.8s\tremaining: 3m 56s\n",
      "177:\tlearn: 1.3305831\ttotal: 51s\tremaining: 3m 55s\n",
      "178:\tlearn: 1.3299757\ttotal: 51.4s\tremaining: 3m 55s\n",
      "179:\tlearn: 1.3290857\ttotal: 51.8s\tremaining: 3m 55s\n",
      "180:\tlearn: 1.3281669\ttotal: 52.1s\tremaining: 3m 55s\n",
      "181:\tlearn: 1.3277136\ttotal: 52.3s\tremaining: 3m 54s\n",
      "182:\tlearn: 1.3265467\ttotal: 52.5s\tremaining: 3m 54s\n",
      "183:\tlearn: 1.3257540\ttotal: 52.8s\tremaining: 3m 54s\n",
      "184:\tlearn: 1.3250261\ttotal: 53.1s\tremaining: 3m 54s\n",
      "185:\tlearn: 1.3244334\ttotal: 53.4s\tremaining: 3m 53s\n",
      "186:\tlearn: 1.3237761\ttotal: 53.6s\tremaining: 3m 53s\n",
      "187:\tlearn: 1.3234179\ttotal: 53.9s\tremaining: 3m 52s\n",
      "188:\tlearn: 1.3226504\ttotal: 54.1s\tremaining: 3m 52s\n",
      "189:\tlearn: 1.3221394\ttotal: 54.4s\tremaining: 3m 51s\n",
      "190:\tlearn: 1.3216034\ttotal: 54.6s\tremaining: 3m 51s\n",
      "191:\tlearn: 1.3210901\ttotal: 54.8s\tremaining: 3m 50s\n",
      "192:\tlearn: 1.3206470\ttotal: 55.1s\tremaining: 3m 50s\n",
      "193:\tlearn: 1.3197246\ttotal: 55.4s\tremaining: 3m 49s\n",
      "194:\tlearn: 1.3189218\ttotal: 55.6s\tremaining: 3m 49s\n",
      "195:\tlearn: 1.3180103\ttotal: 55.9s\tremaining: 3m 49s\n",
      "196:\tlearn: 1.3167872\ttotal: 56.1s\tremaining: 3m 48s\n",
      "197:\tlearn: 1.3157544\ttotal: 56.4s\tremaining: 3m 48s\n",
      "198:\tlearn: 1.3151230\ttotal: 56.6s\tremaining: 3m 47s\n",
      "199:\tlearn: 1.3144923\ttotal: 56.9s\tremaining: 3m 47s\n",
      "200:\tlearn: 1.3137981\ttotal: 57.2s\tremaining: 3m 47s\n",
      "201:\tlearn: 1.3129096\ttotal: 57.5s\tremaining: 3m 47s\n",
      "202:\tlearn: 1.3119605\ttotal: 57.7s\tremaining: 3m 46s\n",
      "203:\tlearn: 1.3112698\ttotal: 58s\tremaining: 3m 46s\n",
      "204:\tlearn: 1.3104440\ttotal: 58.3s\tremaining: 3m 45s\n",
      "205:\tlearn: 1.3098024\ttotal: 58.6s\tremaining: 3m 45s\n",
      "206:\tlearn: 1.3093120\ttotal: 58.9s\tremaining: 3m 45s\n",
      "207:\tlearn: 1.3081287\ttotal: 59.2s\tremaining: 3m 45s\n",
      "208:\tlearn: 1.3076478\ttotal: 59.5s\tremaining: 3m 45s\n",
      "209:\tlearn: 1.3070462\ttotal: 59.7s\tremaining: 3m 44s\n",
      "210:\tlearn: 1.3061334\ttotal: 59.9s\tremaining: 3m 44s\n",
      "211:\tlearn: 1.3053453\ttotal: 1m\tremaining: 3m 43s\n",
      "212:\tlearn: 1.3043967\ttotal: 1m\tremaining: 3m 43s\n",
      "213:\tlearn: 1.3034783\ttotal: 1m\tremaining: 3m 42s\n",
      "214:\tlearn: 1.3024086\ttotal: 1m\tremaining: 3m 42s\n",
      "215:\tlearn: 1.3013910\ttotal: 1m 1s\tremaining: 3m 41s\n",
      "216:\tlearn: 1.3007464\ttotal: 1m 1s\tremaining: 3m 41s\n",
      "217:\tlearn: 1.3001295\ttotal: 1m 1s\tremaining: 3m 41s\n",
      "218:\tlearn: 1.2998081\ttotal: 1m 1s\tremaining: 3m 40s\n",
      "219:\tlearn: 1.2993645\ttotal: 1m 2s\tremaining: 3m 39s\n",
      "220:\tlearn: 1.2989846\ttotal: 1m 2s\tremaining: 3m 39s\n",
      "221:\tlearn: 1.2982776\ttotal: 1m 2s\tremaining: 3m 38s\n",
      "222:\tlearn: 1.2975593\ttotal: 1m 2s\tremaining: 3m 38s\n",
      "223:\tlearn: 1.2969120\ttotal: 1m 2s\tremaining: 3m 38s\n",
      "224:\tlearn: 1.2963790\ttotal: 1m 3s\tremaining: 3m 37s\n",
      "225:\tlearn: 1.2954026\ttotal: 1m 3s\tremaining: 3m 37s\n",
      "226:\tlearn: 1.2947804\ttotal: 1m 3s\tremaining: 3m 36s\n",
      "227:\tlearn: 1.2942690\ttotal: 1m 4s\tremaining: 3m 36s\n",
      "228:\tlearn: 1.2936218\ttotal: 1m 4s\tremaining: 3m 36s\n",
      "229:\tlearn: 1.2927827\ttotal: 1m 4s\tremaining: 3m 36s\n",
      "230:\tlearn: 1.2922644\ttotal: 1m 4s\tremaining: 3m 35s\n",
      "231:\tlearn: 1.2915965\ttotal: 1m 5s\tremaining: 3m 35s\n",
      "232:\tlearn: 1.2907770\ttotal: 1m 5s\tremaining: 3m 35s\n",
      "233:\tlearn: 1.2900638\ttotal: 1m 5s\tremaining: 3m 34s\n",
      "234:\tlearn: 1.2891984\ttotal: 1m 5s\tremaining: 3m 34s\n",
      "235:\tlearn: 1.2886864\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "236:\tlearn: 1.2879890\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "237:\tlearn: 1.2874155\ttotal: 1m 6s\tremaining: 3m 33s\n",
      "238:\tlearn: 1.2867115\ttotal: 1m 6s\tremaining: 3m 32s\n",
      "239:\tlearn: 1.2860421\ttotal: 1m 7s\tremaining: 3m 32s\n",
      "240:\tlearn: 1.2856244\ttotal: 1m 7s\tremaining: 3m 31s\n",
      "241:\tlearn: 1.2848732\ttotal: 1m 7s\tremaining: 3m 31s\n",
      "242:\tlearn: 1.2842322\ttotal: 1m 7s\tremaining: 3m 31s\n",
      "243:\tlearn: 1.2834396\ttotal: 1m 8s\tremaining: 3m 31s\n",
      "244:\tlearn: 1.2828336\ttotal: 1m 8s\tremaining: 3m 30s\n",
      "245:\tlearn: 1.2823686\ttotal: 1m 8s\tremaining: 3m 30s\n",
      "246:\tlearn: 1.2817849\ttotal: 1m 8s\tremaining: 3m 30s\n",
      "247:\tlearn: 1.2809818\ttotal: 1m 9s\tremaining: 3m 30s\n",
      "248:\tlearn: 1.2802854\ttotal: 1m 9s\tremaining: 3m 29s\n",
      "249:\tlearn: 1.2797049\ttotal: 1m 9s\tremaining: 3m 29s\n",
      "250:\tlearn: 1.2791518\ttotal: 1m 10s\tremaining: 3m 29s\n",
      "251:\tlearn: 1.2788868\ttotal: 1m 10s\tremaining: 3m 28s\n",
      "252:\tlearn: 1.2786384\ttotal: 1m 10s\tremaining: 3m 28s\n",
      "253:\tlearn: 1.2782766\ttotal: 1m 10s\tremaining: 3m 27s\n",
      "254:\tlearn: 1.2779508\ttotal: 1m 11s\tremaining: 3m 27s\n",
      "255:\tlearn: 1.2774162\ttotal: 1m 11s\tremaining: 3m 27s\n",
      "256:\tlearn: 1.2768706\ttotal: 1m 11s\tremaining: 3m 27s\n",
      "257:\tlearn: 1.2764716\ttotal: 1m 11s\tremaining: 3m 26s\n",
      "258:\tlearn: 1.2760292\ttotal: 1m 12s\tremaining: 3m 26s\n",
      "259:\tlearn: 1.2756342\ttotal: 1m 12s\tremaining: 3m 26s\n",
      "260:\tlearn: 1.2750137\ttotal: 1m 12s\tremaining: 3m 25s\n",
      "261:\tlearn: 1.2743009\ttotal: 1m 12s\tremaining: 3m 25s\n",
      "262:\tlearn: 1.2737054\ttotal: 1m 13s\tremaining: 3m 25s\n",
      "263:\tlearn: 1.2733507\ttotal: 1m 13s\tremaining: 3m 24s\n",
      "264:\tlearn: 1.2729846\ttotal: 1m 13s\tremaining: 3m 24s\n",
      "265:\tlearn: 1.2723488\ttotal: 1m 13s\tremaining: 3m 23s\n",
      "266:\tlearn: 1.2719399\ttotal: 1m 14s\tremaining: 3m 23s\n",
      "267:\tlearn: 1.2713911\ttotal: 1m 14s\tremaining: 3m 23s\n",
      "268:\tlearn: 1.2705074\ttotal: 1m 14s\tremaining: 3m 22s\n",
      "269:\tlearn: 1.2699579\ttotal: 1m 14s\tremaining: 3m 22s\n",
      "270:\tlearn: 1.2693835\ttotal: 1m 15s\tremaining: 3m 21s\n",
      "271:\tlearn: 1.2685432\ttotal: 1m 15s\tremaining: 3m 21s\n",
      "272:\tlearn: 1.2679505\ttotal: 1m 15s\tremaining: 3m 21s\n",
      "273:\tlearn: 1.2674523\ttotal: 1m 15s\tremaining: 3m 21s\n",
      "274:\tlearn: 1.2667991\ttotal: 1m 16s\tremaining: 3m 20s\n",
      "275:\tlearn: 1.2660226\ttotal: 1m 16s\tremaining: 3m 20s\n",
      "276:\tlearn: 1.2656371\ttotal: 1m 16s\tremaining: 3m 20s\n",
      "277:\tlearn: 1.2652570\ttotal: 1m 17s\tremaining: 3m 20s\n",
      "278:\tlearn: 1.2644620\ttotal: 1m 17s\tremaining: 3m 20s\n",
      "279:\tlearn: 1.2641271\ttotal: 1m 17s\tremaining: 3m 19s\n",
      "280:\tlearn: 1.2636203\ttotal: 1m 18s\tremaining: 3m 19s\n",
      "281:\tlearn: 1.2630736\ttotal: 1m 18s\tremaining: 3m 19s\n",
      "282:\tlearn: 1.2627294\ttotal: 1m 18s\tremaining: 3m 18s\n",
      "283:\tlearn: 1.2620356\ttotal: 1m 18s\tremaining: 3m 18s\n",
      "284:\tlearn: 1.2614692\ttotal: 1m 19s\tremaining: 3m 18s\n",
      "285:\tlearn: 1.2609930\ttotal: 1m 19s\tremaining: 3m 18s\n",
      "286:\tlearn: 1.2605650\ttotal: 1m 19s\tremaining: 3m 17s\n",
      "287:\tlearn: 1.2602155\ttotal: 1m 19s\tremaining: 3m 17s\n",
      "288:\tlearn: 1.2592952\ttotal: 1m 20s\tremaining: 3m 17s\n",
      "289:\tlearn: 1.2587217\ttotal: 1m 20s\tremaining: 3m 16s\n",
      "290:\tlearn: 1.2584565\ttotal: 1m 20s\tremaining: 3m 16s\n",
      "291:\tlearn: 1.2578469\ttotal: 1m 20s\tremaining: 3m 16s\n",
      "292:\tlearn: 1.2575049\ttotal: 1m 21s\tremaining: 3m 15s\n",
      "293:\tlearn: 1.2571681\ttotal: 1m 21s\tremaining: 3m 15s\n",
      "294:\tlearn: 1.2565537\ttotal: 1m 21s\tremaining: 3m 15s\n",
      "295:\tlearn: 1.2560909\ttotal: 1m 21s\tremaining: 3m 14s\n",
      "296:\tlearn: 1.2555243\ttotal: 1m 22s\tremaining: 3m 14s\n",
      "297:\tlearn: 1.2549251\ttotal: 1m 22s\tremaining: 3m 14s\n",
      "298:\tlearn: 1.2543413\ttotal: 1m 22s\tremaining: 3m 13s\n",
      "299:\tlearn: 1.2540732\ttotal: 1m 22s\tremaining: 3m 13s\n",
      "300:\tlearn: 1.2537619\ttotal: 1m 23s\tremaining: 3m 13s\n",
      "301:\tlearn: 1.2532815\ttotal: 1m 23s\tremaining: 3m 12s\n",
      "302:\tlearn: 1.2527342\ttotal: 1m 23s\tremaining: 3m 12s\n",
      "303:\tlearn: 1.2522409\ttotal: 1m 23s\tremaining: 3m 12s\n",
      "304:\tlearn: 1.2519503\ttotal: 1m 24s\tremaining: 3m 11s\n",
      "305:\tlearn: 1.2514690\ttotal: 1m 24s\tremaining: 3m 11s\n",
      "306:\tlearn: 1.2510254\ttotal: 1m 24s\tremaining: 3m 11s\n",
      "307:\tlearn: 1.2502584\ttotal: 1m 24s\tremaining: 3m 10s\n",
      "308:\tlearn: 1.2498186\ttotal: 1m 25s\tremaining: 3m 10s\n",
      "309:\tlearn: 1.2491653\ttotal: 1m 25s\tremaining: 3m 10s\n",
      "310:\tlearn: 1.2484986\ttotal: 1m 25s\tremaining: 3m 9s\n",
      "311:\tlearn: 1.2476791\ttotal: 1m 25s\tremaining: 3m 9s\n",
      "312:\tlearn: 1.2473847\ttotal: 1m 26s\tremaining: 3m 9s\n",
      "313:\tlearn: 1.2465231\ttotal: 1m 26s\tremaining: 3m 8s\n",
      "314:\tlearn: 1.2462825\ttotal: 1m 26s\tremaining: 3m 8s\n",
      "315:\tlearn: 1.2457710\ttotal: 1m 26s\tremaining: 3m 8s\n",
      "316:\tlearn: 1.2453126\ttotal: 1m 27s\tremaining: 3m 7s\n",
      "317:\tlearn: 1.2447151\ttotal: 1m 27s\tremaining: 3m 7s\n",
      "318:\tlearn: 1.2442716\ttotal: 1m 27s\tremaining: 3m 6s\n",
      "319:\tlearn: 1.2441307\ttotal: 1m 27s\tremaining: 3m 6s\n",
      "320:\tlearn: 1.2437672\ttotal: 1m 27s\tremaining: 3m 6s\n",
      "321:\tlearn: 1.2434721\ttotal: 1m 28s\tremaining: 3m 5s\n",
      "322:\tlearn: 1.2430486\ttotal: 1m 28s\tremaining: 3m 5s\n",
      "323:\tlearn: 1.2424505\ttotal: 1m 28s\tremaining: 3m 5s\n",
      "324:\tlearn: 1.2419576\ttotal: 1m 28s\tremaining: 3m 4s\n",
      "325:\tlearn: 1.2417056\ttotal: 1m 29s\tremaining: 3m 4s\n",
      "326:\tlearn: 1.2411934\ttotal: 1m 29s\tremaining: 3m 4s\n",
      "327:\tlearn: 1.2409533\ttotal: 1m 29s\tremaining: 3m 3s\n",
      "328:\tlearn: 1.2404338\ttotal: 1m 29s\tremaining: 3m 3s\n",
      "329:\tlearn: 1.2402010\ttotal: 1m 30s\tremaining: 3m 2s\n",
      "330:\tlearn: 1.2395982\ttotal: 1m 30s\tremaining: 3m 2s\n",
      "331:\tlearn: 1.2391213\ttotal: 1m 30s\tremaining: 3m 2s\n",
      "332:\tlearn: 1.2388503\ttotal: 1m 30s\tremaining: 3m 1s\n",
      "333:\tlearn: 1.2385702\ttotal: 1m 31s\tremaining: 3m 1s\n",
      "334:\tlearn: 1.2381879\ttotal: 1m 31s\tremaining: 3m 1s\n",
      "335:\tlearn: 1.2379208\ttotal: 1m 31s\tremaining: 3m\n",
      "336:\tlearn: 1.2376572\ttotal: 1m 31s\tremaining: 3m\n",
      "337:\tlearn: 1.2371945\ttotal: 1m 31s\tremaining: 3m\n",
      "338:\tlearn: 1.2367624\ttotal: 1m 32s\tremaining: 2m 59s\n",
      "339:\tlearn: 1.2363297\ttotal: 1m 32s\tremaining: 2m 59s\n",
      "340:\tlearn: 1.2360816\ttotal: 1m 32s\tremaining: 2m 58s\n",
      "341:\tlearn: 1.2356343\ttotal: 1m 32s\tremaining: 2m 58s\n",
      "342:\tlearn: 1.2351859\ttotal: 1m 33s\tremaining: 2m 58s\n",
      "343:\tlearn: 1.2348126\ttotal: 1m 33s\tremaining: 2m 58s\n",
      "344:\tlearn: 1.2342886\ttotal: 1m 33s\tremaining: 2m 57s\n",
      "345:\tlearn: 1.2339376\ttotal: 1m 33s\tremaining: 2m 57s\n",
      "346:\tlearn: 1.2335362\ttotal: 1m 34s\tremaining: 2m 57s\n",
      "347:\tlearn: 1.2331281\ttotal: 1m 34s\tremaining: 2m 56s\n",
      "348:\tlearn: 1.2329009\ttotal: 1m 34s\tremaining: 2m 56s\n",
      "349:\tlearn: 1.2322730\ttotal: 1m 34s\tremaining: 2m 56s\n",
      "350:\tlearn: 1.2318879\ttotal: 1m 35s\tremaining: 2m 55s\n",
      "351:\tlearn: 1.2315920\ttotal: 1m 35s\tremaining: 2m 55s\n",
      "352:\tlearn: 1.2313830\ttotal: 1m 35s\tremaining: 2m 55s\n",
      "353:\tlearn: 1.2311003\ttotal: 1m 35s\tremaining: 2m 55s\n",
      "354:\tlearn: 1.2307065\ttotal: 1m 36s\tremaining: 2m 54s\n",
      "355:\tlearn: 1.2301726\ttotal: 1m 36s\tremaining: 2m 54s\n",
      "356:\tlearn: 1.2296559\ttotal: 1m 36s\tremaining: 2m 54s\n",
      "357:\tlearn: 1.2289748\ttotal: 1m 37s\tremaining: 2m 54s\n",
      "358:\tlearn: 1.2286138\ttotal: 1m 37s\tremaining: 2m 53s\n",
      "359:\tlearn: 1.2282084\ttotal: 1m 37s\tremaining: 2m 53s\n",
      "360:\tlearn: 1.2276261\ttotal: 1m 37s\tremaining: 2m 53s\n",
      "361:\tlearn: 1.2270929\ttotal: 1m 38s\tremaining: 2m 52s\n",
      "362:\tlearn: 1.2266095\ttotal: 1m 38s\tremaining: 2m 52s\n",
      "363:\tlearn: 1.2261369\ttotal: 1m 38s\tremaining: 2m 52s\n",
      "364:\tlearn: 1.2258132\ttotal: 1m 38s\tremaining: 2m 51s\n",
      "365:\tlearn: 1.2253654\ttotal: 1m 39s\tremaining: 2m 51s\n",
      "366:\tlearn: 1.2247313\ttotal: 1m 39s\tremaining: 2m 51s\n",
      "367:\tlearn: 1.2243522\ttotal: 1m 39s\tremaining: 2m 50s\n",
      "368:\tlearn: 1.2240133\ttotal: 1m 39s\tremaining: 2m 50s\n",
      "369:\tlearn: 1.2236212\ttotal: 1m 39s\tremaining: 2m 50s\n",
      "370:\tlearn: 1.2230880\ttotal: 1m 40s\tremaining: 2m 49s\n",
      "371:\tlearn: 1.2227601\ttotal: 1m 40s\tremaining: 2m 49s\n",
      "372:\tlearn: 1.2224649\ttotal: 1m 40s\tremaining: 2m 49s\n",
      "373:\tlearn: 1.2220878\ttotal: 1m 40s\tremaining: 2m 48s\n",
      "374:\tlearn: 1.2216329\ttotal: 1m 41s\tremaining: 2m 48s\n",
      "375:\tlearn: 1.2213607\ttotal: 1m 41s\tremaining: 2m 48s\n",
      "376:\tlearn: 1.2208579\ttotal: 1m 41s\tremaining: 2m 47s\n",
      "377:\tlearn: 1.2204205\ttotal: 1m 41s\tremaining: 2m 47s\n",
      "378:\tlearn: 1.2200394\ttotal: 1m 42s\tremaining: 2m 47s\n",
      "379:\tlearn: 1.2194830\ttotal: 1m 42s\tremaining: 2m 46s\n",
      "380:\tlearn: 1.2190158\ttotal: 1m 42s\tremaining: 2m 46s\n",
      "381:\tlearn: 1.2185614\ttotal: 1m 42s\tremaining: 2m 46s\n",
      "382:\tlearn: 1.2179652\ttotal: 1m 43s\tremaining: 2m 46s\n",
      "383:\tlearn: 1.2173504\ttotal: 1m 43s\tremaining: 2m 45s\n",
      "384:\tlearn: 1.2170222\ttotal: 1m 43s\tremaining: 2m 45s\n",
      "385:\tlearn: 1.2166912\ttotal: 1m 43s\tremaining: 2m 45s\n",
      "386:\tlearn: 1.2160532\ttotal: 1m 44s\tremaining: 2m 44s\n",
      "387:\tlearn: 1.2156865\ttotal: 1m 44s\tremaining: 2m 44s\n",
      "388:\tlearn: 1.2151773\ttotal: 1m 44s\tremaining: 2m 44s\n",
      "389:\tlearn: 1.2146185\ttotal: 1m 44s\tremaining: 2m 43s\n",
      "390:\tlearn: 1.2143229\ttotal: 1m 44s\tremaining: 2m 43s\n",
      "391:\tlearn: 1.2140671\ttotal: 1m 45s\tremaining: 2m 43s\n",
      "392:\tlearn: 1.2135667\ttotal: 1m 45s\tremaining: 2m 42s\n",
      "393:\tlearn: 1.2133638\ttotal: 1m 45s\tremaining: 2m 42s\n",
      "394:\tlearn: 1.2128937\ttotal: 1m 45s\tremaining: 2m 42s\n",
      "395:\tlearn: 1.2123277\ttotal: 1m 46s\tremaining: 2m 41s\n",
      "396:\tlearn: 1.2119499\ttotal: 1m 46s\tremaining: 2m 41s\n",
      "397:\tlearn: 1.2114152\ttotal: 1m 46s\tremaining: 2m 41s\n",
      "398:\tlearn: 1.2110785\ttotal: 1m 46s\tremaining: 2m 40s\n",
      "399:\tlearn: 1.2108013\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "400:\tlearn: 1.2105504\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "401:\tlearn: 1.2101501\ttotal: 1m 47s\tremaining: 2m 39s\n",
      "402:\tlearn: 1.2096800\ttotal: 1m 47s\tremaining: 2m 39s\n",
      "403:\tlearn: 1.2094129\ttotal: 1m 47s\tremaining: 2m 39s\n",
      "404:\tlearn: 1.2090948\ttotal: 1m 48s\tremaining: 2m 38s\n",
      "405:\tlearn: 1.2087304\ttotal: 1m 48s\tremaining: 2m 38s\n",
      "406:\tlearn: 1.2082310\ttotal: 1m 48s\tremaining: 2m 38s\n",
      "407:\tlearn: 1.2078319\ttotal: 1m 49s\tremaining: 2m 38s\n",
      "408:\tlearn: 1.2074161\ttotal: 1m 49s\tremaining: 2m 37s\n",
      "409:\tlearn: 1.2070934\ttotal: 1m 49s\tremaining: 2m 37s\n",
      "410:\tlearn: 1.2066681\ttotal: 1m 49s\tremaining: 2m 37s\n",
      "411:\tlearn: 1.2061231\ttotal: 1m 50s\tremaining: 2m 37s\n",
      "412:\tlearn: 1.2058995\ttotal: 1m 50s\tremaining: 2m 36s\n",
      "413:\tlearn: 1.2056691\ttotal: 1m 50s\tremaining: 2m 36s\n",
      "414:\tlearn: 1.2053821\ttotal: 1m 50s\tremaining: 2m 36s\n",
      "415:\tlearn: 1.2048134\ttotal: 1m 50s\tremaining: 2m 35s\n",
      "416:\tlearn: 1.2043492\ttotal: 1m 51s\tremaining: 2m 35s\n",
      "417:\tlearn: 1.2039323\ttotal: 1m 51s\tremaining: 2m 35s\n",
      "418:\tlearn: 1.2037273\ttotal: 1m 51s\tremaining: 2m 34s\n",
      "419:\tlearn: 1.2033701\ttotal: 1m 51s\tremaining: 2m 34s\n",
      "420:\tlearn: 1.2030183\ttotal: 1m 52s\tremaining: 2m 34s\n",
      "421:\tlearn: 1.2027307\ttotal: 1m 52s\tremaining: 2m 34s\n",
      "422:\tlearn: 1.2022709\ttotal: 1m 52s\tremaining: 2m 33s\n",
      "423:\tlearn: 1.2019274\ttotal: 1m 53s\tremaining: 2m 33s\n",
      "424:\tlearn: 1.2016515\ttotal: 1m 53s\tremaining: 2m 33s\n",
      "425:\tlearn: 1.2012141\ttotal: 1m 53s\tremaining: 2m 32s\n",
      "426:\tlearn: 1.2008951\ttotal: 1m 53s\tremaining: 2m 32s\n",
      "427:\tlearn: 1.2004431\ttotal: 1m 53s\tremaining: 2m 32s\n",
      "428:\tlearn: 1.1999975\ttotal: 1m 54s\tremaining: 2m 32s\n",
      "429:\tlearn: 1.1994326\ttotal: 1m 54s\tremaining: 2m 31s\n",
      "430:\tlearn: 1.1990952\ttotal: 1m 54s\tremaining: 2m 31s\n",
      "431:\tlearn: 1.1984109\ttotal: 1m 55s\tremaining: 2m 31s\n",
      "432:\tlearn: 1.1979879\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "433:\tlearn: 1.1976720\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "434:\tlearn: 1.1974234\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "435:\tlearn: 1.1970388\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "436:\tlearn: 1.1966530\ttotal: 1m 56s\tremaining: 2m 29s\n",
      "437:\tlearn: 1.1965278\ttotal: 1m 56s\tremaining: 2m 29s\n",
      "438:\tlearn: 1.1961122\ttotal: 1m 56s\tremaining: 2m 29s\n",
      "439:\tlearn: 1.1957958\ttotal: 1m 57s\tremaining: 2m 28s\n",
      "440:\tlearn: 1.1955726\ttotal: 1m 57s\tremaining: 2m 28s\n",
      "441:\tlearn: 1.1953571\ttotal: 1m 57s\tremaining: 2m 28s\n",
      "442:\tlearn: 1.1950980\ttotal: 1m 57s\tremaining: 2m 28s\n",
      "443:\tlearn: 1.1947667\ttotal: 1m 58s\tremaining: 2m 27s\n",
      "444:\tlearn: 1.1943778\ttotal: 1m 58s\tremaining: 2m 27s\n",
      "445:\tlearn: 1.1941766\ttotal: 1m 58s\tremaining: 2m 27s\n",
      "446:\tlearn: 1.1938115\ttotal: 1m 58s\tremaining: 2m 26s\n",
      "447:\tlearn: 1.1935342\ttotal: 1m 58s\tremaining: 2m 26s\n",
      "448:\tlearn: 1.1930320\ttotal: 1m 59s\tremaining: 2m 26s\n",
      "449:\tlearn: 1.1926826\ttotal: 1m 59s\tremaining: 2m 26s\n",
      "450:\tlearn: 1.1921456\ttotal: 1m 59s\tremaining: 2m 25s\n",
      "451:\tlearn: 1.1919734\ttotal: 2m\tremaining: 2m 25s\n",
      "452:\tlearn: 1.1915144\ttotal: 2m\tremaining: 2m 25s\n",
      "453:\tlearn: 1.1911532\ttotal: 2m\tremaining: 2m 24s\n",
      "454:\tlearn: 1.1904824\ttotal: 2m\tremaining: 2m 24s\n",
      "455:\tlearn: 1.1900980\ttotal: 2m 1s\tremaining: 2m 24s\n",
      "456:\tlearn: 1.1896676\ttotal: 2m 1s\tremaining: 2m 24s\n",
      "457:\tlearn: 1.1893367\ttotal: 2m 1s\tremaining: 2m 23s\n",
      "458:\tlearn: 1.1890433\ttotal: 2m 1s\tremaining: 2m 23s\n",
      "459:\tlearn: 1.1885715\ttotal: 2m 1s\tremaining: 2m 23s\n",
      "460:\tlearn: 1.1881346\ttotal: 2m 2s\tremaining: 2m 22s\n",
      "461:\tlearn: 1.1876650\ttotal: 2m 2s\tremaining: 2m 22s\n",
      "462:\tlearn: 1.1874051\ttotal: 2m 2s\tremaining: 2m 22s\n",
      "463:\tlearn: 1.1867585\ttotal: 2m 2s\tremaining: 2m 22s\n",
      "464:\tlearn: 1.1864747\ttotal: 2m 3s\tremaining: 2m 21s\n",
      "465:\tlearn: 1.1861983\ttotal: 2m 3s\tremaining: 2m 21s\n",
      "466:\tlearn: 1.1858944\ttotal: 2m 3s\tremaining: 2m 21s\n",
      "467:\tlearn: 1.1853849\ttotal: 2m 3s\tremaining: 2m 20s\n",
      "468:\tlearn: 1.1852392\ttotal: 2m 4s\tremaining: 2m 20s\n",
      "469:\tlearn: 1.1848890\ttotal: 2m 4s\tremaining: 2m 20s\n",
      "470:\tlearn: 1.1846813\ttotal: 2m 4s\tremaining: 2m 19s\n",
      "471:\tlearn: 1.1845101\ttotal: 2m 4s\tremaining: 2m 19s\n",
      "472:\tlearn: 1.1841607\ttotal: 2m 4s\tremaining: 2m 19s\n",
      "473:\tlearn: 1.1839027\ttotal: 2m 5s\tremaining: 2m 18s\n",
      "474:\tlearn: 1.1835154\ttotal: 2m 5s\tremaining: 2m 18s\n",
      "475:\tlearn: 1.1832078\ttotal: 2m 5s\tremaining: 2m 18s\n",
      "476:\tlearn: 1.1828302\ttotal: 2m 5s\tremaining: 2m 18s\n",
      "477:\tlearn: 1.1826141\ttotal: 2m 6s\tremaining: 2m 17s\n",
      "478:\tlearn: 1.1823641\ttotal: 2m 6s\tremaining: 2m 17s\n",
      "479:\tlearn: 1.1819163\ttotal: 2m 6s\tremaining: 2m 17s\n",
      "480:\tlearn: 1.1816461\ttotal: 2m 6s\tremaining: 2m 16s\n",
      "481:\tlearn: 1.1813168\ttotal: 2m 7s\tremaining: 2m 16s\n",
      "482:\tlearn: 1.1809688\ttotal: 2m 7s\tremaining: 2m 16s\n",
      "483:\tlearn: 1.1807276\ttotal: 2m 7s\tremaining: 2m 16s\n",
      "484:\tlearn: 1.1803203\ttotal: 2m 7s\tremaining: 2m 15s\n",
      "485:\tlearn: 1.1800192\ttotal: 2m 8s\tremaining: 2m 15s\n",
      "486:\tlearn: 1.1797282\ttotal: 2m 8s\tremaining: 2m 15s\n",
      "487:\tlearn: 1.1795472\ttotal: 2m 8s\tremaining: 2m 15s\n",
      "488:\tlearn: 1.1791369\ttotal: 2m 8s\tremaining: 2m 14s\n",
      "489:\tlearn: 1.1788096\ttotal: 2m 9s\tremaining: 2m 14s\n",
      "490:\tlearn: 1.1784872\ttotal: 2m 9s\tremaining: 2m 14s\n",
      "491:\tlearn: 1.1779537\ttotal: 2m 9s\tremaining: 2m 13s\n",
      "492:\tlearn: 1.1775496\ttotal: 2m 9s\tremaining: 2m 13s\n",
      "493:\tlearn: 1.1771430\ttotal: 2m 10s\tremaining: 2m 13s\n",
      "494:\tlearn: 1.1768014\ttotal: 2m 10s\tremaining: 2m 13s\n",
      "495:\tlearn: 1.1763602\ttotal: 2m 10s\tremaining: 2m 12s\n",
      "496:\tlearn: 1.1759688\ttotal: 2m 11s\tremaining: 2m 12s\n",
      "497:\tlearn: 1.1757042\ttotal: 2m 11s\tremaining: 2m 12s\n",
      "498:\tlearn: 1.1754363\ttotal: 2m 11s\tremaining: 2m 12s\n",
      "499:\tlearn: 1.1749014\ttotal: 2m 11s\tremaining: 2m 11s\n",
      "500:\tlearn: 1.1745064\ttotal: 2m 11s\tremaining: 2m 11s\n",
      "501:\tlearn: 1.1743401\ttotal: 2m 12s\tremaining: 2m 11s\n",
      "502:\tlearn: 1.1740148\ttotal: 2m 12s\tremaining: 2m 10s\n",
      "503:\tlearn: 1.1737296\ttotal: 2m 12s\tremaining: 2m 10s\n",
      "504:\tlearn: 1.1735407\ttotal: 2m 12s\tremaining: 2m 10s\n",
      "505:\tlearn: 1.1732596\ttotal: 2m 13s\tremaining: 2m 9s\n",
      "506:\tlearn: 1.1728650\ttotal: 2m 13s\tremaining: 2m 9s\n",
      "507:\tlearn: 1.1727504\ttotal: 2m 13s\tremaining: 2m 9s\n",
      "508:\tlearn: 1.1724295\ttotal: 2m 13s\tremaining: 2m 9s\n",
      "509:\tlearn: 1.1721319\ttotal: 2m 14s\tremaining: 2m 8s\n",
      "510:\tlearn: 1.1717694\ttotal: 2m 14s\tremaining: 2m 8s\n",
      "511:\tlearn: 1.1715393\ttotal: 2m 14s\tremaining: 2m 8s\n",
      "512:\tlearn: 1.1711681\ttotal: 2m 14s\tremaining: 2m 7s\n",
      "513:\tlearn: 1.1709915\ttotal: 2m 14s\tremaining: 2m 7s\n",
      "514:\tlearn: 1.1707334\ttotal: 2m 15s\tremaining: 2m 7s\n",
      "515:\tlearn: 1.1705554\ttotal: 2m 15s\tremaining: 2m 7s\n",
      "516:\tlearn: 1.1703008\ttotal: 2m 15s\tremaining: 2m 6s\n",
      "517:\tlearn: 1.1699937\ttotal: 2m 15s\tremaining: 2m 6s\n",
      "518:\tlearn: 1.1695748\ttotal: 2m 16s\tremaining: 2m 6s\n",
      "519:\tlearn: 1.1690861\ttotal: 2m 16s\tremaining: 2m 5s\n",
      "520:\tlearn: 1.1687659\ttotal: 2m 16s\tremaining: 2m 5s\n",
      "521:\tlearn: 1.1684785\ttotal: 2m 16s\tremaining: 2m 5s\n",
      "522:\tlearn: 1.1680073\ttotal: 2m 17s\tremaining: 2m 5s\n",
      "523:\tlearn: 1.1676773\ttotal: 2m 17s\tremaining: 2m 4s\n",
      "524:\tlearn: 1.1672667\ttotal: 2m 17s\tremaining: 2m 4s\n",
      "525:\tlearn: 1.1670101\ttotal: 2m 17s\tremaining: 2m 4s\n",
      "526:\tlearn: 1.1667429\ttotal: 2m 18s\tremaining: 2m 3s\n",
      "527:\tlearn: 1.1664307\ttotal: 2m 18s\tremaining: 2m 3s\n",
      "528:\tlearn: 1.1661782\ttotal: 2m 18s\tremaining: 2m 3s\n",
      "529:\tlearn: 1.1659877\ttotal: 2m 18s\tremaining: 2m 3s\n",
      "530:\tlearn: 1.1656377\ttotal: 2m 18s\tremaining: 2m 2s\n",
      "531:\tlearn: 1.1653657\ttotal: 2m 19s\tremaining: 2m 2s\n",
      "532:\tlearn: 1.1649447\ttotal: 2m 19s\tremaining: 2m 2s\n",
      "533:\tlearn: 1.1646908\ttotal: 2m 19s\tremaining: 2m 1s\n",
      "534:\tlearn: 1.1643980\ttotal: 2m 19s\tremaining: 2m 1s\n",
      "535:\tlearn: 1.1641549\ttotal: 2m 20s\tremaining: 2m 1s\n",
      "536:\tlearn: 1.1638032\ttotal: 2m 20s\tremaining: 2m 1s\n",
      "537:\tlearn: 1.1635479\ttotal: 2m 20s\tremaining: 2m\n",
      "538:\tlearn: 1.1631090\ttotal: 2m 20s\tremaining: 2m\n",
      "539:\tlearn: 1.1628617\ttotal: 2m 21s\tremaining: 2m\n",
      "540:\tlearn: 1.1624207\ttotal: 2m 21s\tremaining: 1m 59s\n",
      "541:\tlearn: 1.1622711\ttotal: 2m 21s\tremaining: 1m 59s\n",
      "542:\tlearn: 1.1620529\ttotal: 2m 21s\tremaining: 1m 59s\n",
      "543:\tlearn: 1.1616456\ttotal: 2m 22s\tremaining: 1m 59s\n",
      "544:\tlearn: 1.1614377\ttotal: 2m 22s\tremaining: 1m 58s\n",
      "545:\tlearn: 1.1609262\ttotal: 2m 22s\tremaining: 1m 58s\n",
      "546:\tlearn: 1.1606063\ttotal: 2m 22s\tremaining: 1m 58s\n",
      "547:\tlearn: 1.1603772\ttotal: 2m 23s\tremaining: 1m 57s\n",
      "548:\tlearn: 1.1600481\ttotal: 2m 23s\tremaining: 1m 57s\n",
      "549:\tlearn: 1.1596576\ttotal: 2m 23s\tremaining: 1m 57s\n",
      "550:\tlearn: 1.1593179\ttotal: 2m 23s\tremaining: 1m 57s\n",
      "551:\tlearn: 1.1590372\ttotal: 2m 24s\tremaining: 1m 56s\n",
      "552:\tlearn: 1.1586748\ttotal: 2m 24s\tremaining: 1m 56s\n",
      "553:\tlearn: 1.1584342\ttotal: 2m 24s\tremaining: 1m 56s\n",
      "554:\tlearn: 1.1581359\ttotal: 2m 24s\tremaining: 1m 56s\n",
      "555:\tlearn: 1.1580019\ttotal: 2m 25s\tremaining: 1m 55s\n",
      "556:\tlearn: 1.1578448\ttotal: 2m 25s\tremaining: 1m 55s\n",
      "557:\tlearn: 1.1575811\ttotal: 2m 25s\tremaining: 1m 55s\n",
      "558:\tlearn: 1.1572721\ttotal: 2m 25s\tremaining: 1m 55s\n",
      "559:\tlearn: 1.1570768\ttotal: 2m 26s\tremaining: 1m 54s\n",
      "560:\tlearn: 1.1566044\ttotal: 2m 26s\tremaining: 1m 54s\n",
      "561:\tlearn: 1.1563976\ttotal: 2m 26s\tremaining: 1m 54s\n",
      "562:\tlearn: 1.1560729\ttotal: 2m 26s\tremaining: 1m 53s\n",
      "563:\tlearn: 1.1557883\ttotal: 2m 27s\tremaining: 1m 53s\n",
      "564:\tlearn: 1.1554275\ttotal: 2m 27s\tremaining: 1m 53s\n",
      "565:\tlearn: 1.1551855\ttotal: 2m 27s\tremaining: 1m 53s\n",
      "566:\tlearn: 1.1550419\ttotal: 2m 27s\tremaining: 1m 52s\n",
      "567:\tlearn: 1.1546706\ttotal: 2m 27s\tremaining: 1m 52s\n",
      "568:\tlearn: 1.1544440\ttotal: 2m 28s\tremaining: 1m 52s\n",
      "569:\tlearn: 1.1541121\ttotal: 2m 28s\tremaining: 1m 51s\n",
      "570:\tlearn: 1.1537112\ttotal: 2m 28s\tremaining: 1m 51s\n",
      "571:\tlearn: 1.1534543\ttotal: 2m 29s\tremaining: 1m 51s\n",
      "572:\tlearn: 1.1530635\ttotal: 2m 29s\tremaining: 1m 51s\n",
      "573:\tlearn: 1.1528208\ttotal: 2m 30s\tremaining: 1m 51s\n",
      "574:\tlearn: 1.1523616\ttotal: 2m 30s\tremaining: 1m 51s\n",
      "575:\tlearn: 1.1521204\ttotal: 2m 30s\tremaining: 1m 50s\n",
      "576:\tlearn: 1.1519278\ttotal: 2m 30s\tremaining: 1m 50s\n",
      "577:\tlearn: 1.1517563\ttotal: 2m 31s\tremaining: 1m 50s\n",
      "578:\tlearn: 1.1514259\ttotal: 2m 31s\tremaining: 1m 50s\n",
      "579:\tlearn: 1.1512101\ttotal: 2m 31s\tremaining: 1m 49s\n",
      "580:\tlearn: 1.1509427\ttotal: 2m 31s\tremaining: 1m 49s\n",
      "581:\tlearn: 1.1505278\ttotal: 2m 32s\tremaining: 1m 49s\n",
      "582:\tlearn: 1.1501375\ttotal: 2m 32s\tremaining: 1m 49s\n",
      "583:\tlearn: 1.1498806\ttotal: 2m 32s\tremaining: 1m 48s\n",
      "584:\tlearn: 1.1496311\ttotal: 2m 33s\tremaining: 1m 48s\n",
      "585:\tlearn: 1.1491541\ttotal: 2m 33s\tremaining: 1m 48s\n",
      "586:\tlearn: 1.1489247\ttotal: 2m 33s\tremaining: 1m 48s\n",
      "587:\tlearn: 1.1487959\ttotal: 2m 33s\tremaining: 1m 47s\n",
      "588:\tlearn: 1.1485831\ttotal: 2m 34s\tremaining: 1m 47s\n",
      "589:\tlearn: 1.1483395\ttotal: 2m 34s\tremaining: 1m 47s\n",
      "590:\tlearn: 1.1481758\ttotal: 2m 34s\tremaining: 1m 47s\n",
      "591:\tlearn: 1.1478573\ttotal: 2m 35s\tremaining: 1m 46s\n",
      "592:\tlearn: 1.1476497\ttotal: 2m 35s\tremaining: 1m 46s\n",
      "593:\tlearn: 1.1473293\ttotal: 2m 35s\tremaining: 1m 46s\n",
      "594:\tlearn: 1.1471023\ttotal: 2m 35s\tremaining: 1m 46s\n",
      "595:\tlearn: 1.1468025\ttotal: 2m 36s\tremaining: 1m 45s\n",
      "596:\tlearn: 1.1465673\ttotal: 2m 36s\tremaining: 1m 45s\n",
      "597:\tlearn: 1.1463844\ttotal: 2m 36s\tremaining: 1m 45s\n",
      "598:\tlearn: 1.1460319\ttotal: 2m 36s\tremaining: 1m 44s\n",
      "599:\tlearn: 1.1457992\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "600:\tlearn: 1.1455844\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "601:\tlearn: 1.1452728\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "602:\tlearn: 1.1450684\ttotal: 2m 37s\tremaining: 1m 43s\n",
      "603:\tlearn: 1.1449078\ttotal: 2m 38s\tremaining: 1m 43s\n",
      "604:\tlearn: 1.1446733\ttotal: 2m 38s\tremaining: 1m 43s\n",
      "605:\tlearn: 1.1445523\ttotal: 2m 38s\tremaining: 1m 43s\n",
      "606:\tlearn: 1.1442901\ttotal: 2m 38s\tremaining: 1m 42s\n",
      "607:\tlearn: 1.1438384\ttotal: 2m 39s\tremaining: 1m 42s\n",
      "608:\tlearn: 1.1434306\ttotal: 2m 39s\tremaining: 1m 42s\n",
      "609:\tlearn: 1.1431956\ttotal: 2m 39s\tremaining: 1m 42s\n",
      "610:\tlearn: 1.1429055\ttotal: 2m 40s\tremaining: 1m 41s\n",
      "611:\tlearn: 1.1426218\ttotal: 2m 40s\tremaining: 1m 41s\n",
      "612:\tlearn: 1.1423644\ttotal: 2m 40s\tremaining: 1m 41s\n",
      "613:\tlearn: 1.1420070\ttotal: 2m 41s\tremaining: 1m 41s\n",
      "614:\tlearn: 1.1417780\ttotal: 2m 41s\tremaining: 1m 40s\n",
      "615:\tlearn: 1.1415242\ttotal: 2m 41s\tremaining: 1m 40s\n",
      "616:\tlearn: 1.1412516\ttotal: 2m 41s\tremaining: 1m 40s\n",
      "617:\tlearn: 1.1409663\ttotal: 2m 42s\tremaining: 1m 40s\n",
      "618:\tlearn: 1.1408004\ttotal: 2m 42s\tremaining: 1m 39s\n",
      "619:\tlearn: 1.1406449\ttotal: 2m 42s\tremaining: 1m 39s\n",
      "620:\tlearn: 1.1404079\ttotal: 2m 42s\tremaining: 1m 39s\n",
      "621:\tlearn: 1.1401821\ttotal: 2m 43s\tremaining: 1m 39s\n",
      "622:\tlearn: 1.1399497\ttotal: 2m 43s\tremaining: 1m 38s\n",
      "623:\tlearn: 1.1396864\ttotal: 2m 43s\tremaining: 1m 38s\n",
      "624:\tlearn: 1.1395538\ttotal: 2m 43s\tremaining: 1m 38s\n",
      "625:\tlearn: 1.1392364\ttotal: 2m 44s\tremaining: 1m 38s\n",
      "626:\tlearn: 1.1390670\ttotal: 2m 44s\tremaining: 1m 37s\n",
      "627:\tlearn: 1.1388992\ttotal: 2m 44s\tremaining: 1m 37s\n",
      "628:\tlearn: 1.1386197\ttotal: 2m 44s\tremaining: 1m 37s\n",
      "629:\tlearn: 1.1384358\ttotal: 2m 45s\tremaining: 1m 36s\n",
      "630:\tlearn: 1.1382435\ttotal: 2m 45s\tremaining: 1m 36s\n",
      "631:\tlearn: 1.1379234\ttotal: 2m 45s\tremaining: 1m 36s\n",
      "632:\tlearn: 1.1376905\ttotal: 2m 45s\tremaining: 1m 36s\n",
      "633:\tlearn: 1.1371569\ttotal: 2m 46s\tremaining: 1m 35s\n",
      "634:\tlearn: 1.1369101\ttotal: 2m 46s\tremaining: 1m 35s\n",
      "635:\tlearn: 1.1365482\ttotal: 2m 46s\tremaining: 1m 35s\n",
      "636:\tlearn: 1.1364339\ttotal: 2m 47s\tremaining: 1m 35s\n",
      "637:\tlearn: 1.1362110\ttotal: 2m 47s\tremaining: 1m 35s\n",
      "638:\tlearn: 1.1359498\ttotal: 2m 47s\tremaining: 1m 34s\n",
      "639:\tlearn: 1.1356299\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "640:\tlearn: 1.1353039\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "641:\tlearn: 1.1348363\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "642:\tlearn: 1.1345102\ttotal: 2m 48s\tremaining: 1m 33s\n",
      "643:\tlearn: 1.1342992\ttotal: 2m 49s\tremaining: 1m 33s\n",
      "644:\tlearn: 1.1337991\ttotal: 2m 49s\tremaining: 1m 33s\n",
      "645:\tlearn: 1.1335951\ttotal: 2m 49s\tremaining: 1m 32s\n",
      "646:\tlearn: 1.1332796\ttotal: 2m 49s\tremaining: 1m 32s\n",
      "647:\tlearn: 1.1328540\ttotal: 2m 50s\tremaining: 1m 32s\n",
      "648:\tlearn: 1.1326406\ttotal: 2m 50s\tremaining: 1m 32s\n",
      "649:\tlearn: 1.1324381\ttotal: 2m 50s\tremaining: 1m 31s\n",
      "650:\tlearn: 1.1321929\ttotal: 2m 50s\tremaining: 1m 31s\n",
      "651:\tlearn: 1.1318138\ttotal: 2m 51s\tremaining: 1m 31s\n",
      "652:\tlearn: 1.1316225\ttotal: 2m 51s\tremaining: 1m 31s\n",
      "653:\tlearn: 1.1313010\ttotal: 2m 51s\tremaining: 1m 30s\n",
      "654:\tlearn: 1.1310085\ttotal: 2m 51s\tremaining: 1m 30s\n",
      "655:\tlearn: 1.1307983\ttotal: 2m 52s\tremaining: 1m 30s\n",
      "656:\tlearn: 1.1304963\ttotal: 2m 52s\tremaining: 1m 30s\n",
      "657:\tlearn: 1.1302196\ttotal: 2m 52s\tremaining: 1m 29s\n",
      "658:\tlearn: 1.1300258\ttotal: 2m 52s\tremaining: 1m 29s\n",
      "659:\tlearn: 1.1298517\ttotal: 2m 53s\tremaining: 1m 29s\n",
      "660:\tlearn: 1.1296279\ttotal: 2m 53s\tremaining: 1m 28s\n",
      "661:\tlearn: 1.1294538\ttotal: 2m 53s\tremaining: 1m 28s\n",
      "662:\tlearn: 1.1292432\ttotal: 2m 54s\tremaining: 1m 28s\n",
      "663:\tlearn: 1.1291188\ttotal: 2m 54s\tremaining: 1m 28s\n",
      "664:\tlearn: 1.1288910\ttotal: 2m 54s\tremaining: 1m 27s\n",
      "665:\tlearn: 1.1286769\ttotal: 2m 54s\tremaining: 1m 27s\n",
      "666:\tlearn: 1.1284456\ttotal: 2m 55s\tremaining: 1m 27s\n",
      "667:\tlearn: 1.1282326\ttotal: 2m 55s\tremaining: 1m 27s\n",
      "668:\tlearn: 1.1279529\ttotal: 2m 56s\tremaining: 1m 27s\n",
      "669:\tlearn: 1.1275844\ttotal: 2m 56s\tremaining: 1m 26s\n",
      "670:\tlearn: 1.1273198\ttotal: 2m 56s\tremaining: 1m 26s\n",
      "671:\tlearn: 1.1271356\ttotal: 2m 57s\tremaining: 1m 26s\n",
      "672:\tlearn: 1.1268064\ttotal: 2m 57s\tremaining: 1m 26s\n",
      "673:\tlearn: 1.1265899\ttotal: 2m 57s\tremaining: 1m 25s\n",
      "674:\tlearn: 1.1264058\ttotal: 2m 58s\tremaining: 1m 25s\n",
      "675:\tlearn: 1.1261887\ttotal: 2m 58s\tremaining: 1m 25s\n",
      "676:\tlearn: 1.1258887\ttotal: 2m 58s\tremaining: 1m 25s\n",
      "677:\tlearn: 1.1255378\ttotal: 2m 58s\tremaining: 1m 24s\n",
      "678:\tlearn: 1.1252755\ttotal: 2m 59s\tremaining: 1m 24s\n",
      "679:\tlearn: 1.1251479\ttotal: 2m 59s\tremaining: 1m 24s\n",
      "680:\tlearn: 1.1250223\ttotal: 2m 59s\tremaining: 1m 24s\n",
      "681:\tlearn: 1.1247866\ttotal: 2m 59s\tremaining: 1m 23s\n",
      "682:\tlearn: 1.1245585\ttotal: 3m\tremaining: 1m 23s\n",
      "683:\tlearn: 1.1242147\ttotal: 3m\tremaining: 1m 23s\n",
      "684:\tlearn: 1.1240127\ttotal: 3m\tremaining: 1m 23s\n",
      "685:\tlearn: 1.1238409\ttotal: 3m 1s\tremaining: 1m 22s\n",
      "686:\tlearn: 1.1234876\ttotal: 3m 1s\tremaining: 1m 22s\n",
      "687:\tlearn: 1.1232363\ttotal: 3m 1s\tremaining: 1m 22s\n",
      "688:\tlearn: 1.1228584\ttotal: 3m 1s\tremaining: 1m 22s\n",
      "689:\tlearn: 1.1225523\ttotal: 3m 2s\tremaining: 1m 21s\n",
      "690:\tlearn: 1.1222651\ttotal: 3m 2s\tremaining: 1m 21s\n",
      "691:\tlearn: 1.1219536\ttotal: 3m 2s\tremaining: 1m 21s\n",
      "692:\tlearn: 1.1217936\ttotal: 3m 2s\tremaining: 1m 20s\n",
      "693:\tlearn: 1.1215928\ttotal: 3m 3s\tremaining: 1m 20s\n",
      "694:\tlearn: 1.1212442\ttotal: 3m 3s\tremaining: 1m 20s\n",
      "695:\tlearn: 1.1210828\ttotal: 3m 3s\tremaining: 1m 20s\n",
      "696:\tlearn: 1.1206817\ttotal: 3m 3s\tremaining: 1m 19s\n",
      "697:\tlearn: 1.1202162\ttotal: 3m 4s\tremaining: 1m 19s\n",
      "698:\tlearn: 1.1200948\ttotal: 3m 4s\tremaining: 1m 19s\n",
      "699:\tlearn: 1.1198322\ttotal: 3m 4s\tremaining: 1m 19s\n",
      "700:\tlearn: 1.1196407\ttotal: 3m 4s\tremaining: 1m 18s\n",
      "701:\tlearn: 1.1194177\ttotal: 3m 5s\tremaining: 1m 18s\n",
      "702:\tlearn: 1.1192037\ttotal: 3m 5s\tremaining: 1m 18s\n",
      "703:\tlearn: 1.1189508\ttotal: 3m 5s\tremaining: 1m 18s\n",
      "704:\tlearn: 1.1187847\ttotal: 3m 5s\tremaining: 1m 17s\n",
      "705:\tlearn: 1.1185915\ttotal: 3m 6s\tremaining: 1m 17s\n",
      "706:\tlearn: 1.1184896\ttotal: 3m 6s\tremaining: 1m 17s\n",
      "707:\tlearn: 1.1182210\ttotal: 3m 6s\tremaining: 1m 16s\n",
      "708:\tlearn: 1.1180020\ttotal: 3m 6s\tremaining: 1m 16s\n",
      "709:\tlearn: 1.1177079\ttotal: 3m 7s\tremaining: 1m 16s\n",
      "710:\tlearn: 1.1172439\ttotal: 3m 7s\tremaining: 1m 16s\n",
      "711:\tlearn: 1.1171198\ttotal: 3m 7s\tremaining: 1m 15s\n",
      "712:\tlearn: 1.1167616\ttotal: 3m 7s\tremaining: 1m 15s\n",
      "713:\tlearn: 1.1165460\ttotal: 3m 8s\tremaining: 1m 15s\n",
      "714:\tlearn: 1.1160969\ttotal: 3m 8s\tremaining: 1m 15s\n",
      "715:\tlearn: 1.1158715\ttotal: 3m 8s\tremaining: 1m 14s\n",
      "716:\tlearn: 1.1155539\ttotal: 3m 8s\tremaining: 1m 14s\n",
      "717:\tlearn: 1.1153065\ttotal: 3m 9s\tremaining: 1m 14s\n",
      "718:\tlearn: 1.1152071\ttotal: 3m 9s\tremaining: 1m 13s\n",
      "719:\tlearn: 1.1150379\ttotal: 3m 9s\tremaining: 1m 13s\n",
      "720:\tlearn: 1.1147640\ttotal: 3m 9s\tremaining: 1m 13s\n",
      "721:\tlearn: 1.1146205\ttotal: 3m 10s\tremaining: 1m 13s\n",
      "722:\tlearn: 1.1143616\ttotal: 3m 10s\tremaining: 1m 12s\n",
      "723:\tlearn: 1.1140388\ttotal: 3m 10s\tremaining: 1m 12s\n",
      "724:\tlearn: 1.1138150\ttotal: 3m 10s\tremaining: 1m 12s\n",
      "725:\tlearn: 1.1136536\ttotal: 3m 10s\tremaining: 1m 12s\n",
      "726:\tlearn: 1.1134149\ttotal: 3m 11s\tremaining: 1m 11s\n",
      "727:\tlearn: 1.1131113\ttotal: 3m 11s\tremaining: 1m 11s\n",
      "728:\tlearn: 1.1128540\ttotal: 3m 11s\tremaining: 1m 11s\n",
      "729:\tlearn: 1.1126707\ttotal: 3m 12s\tremaining: 1m 11s\n",
      "730:\tlearn: 1.1124441\ttotal: 3m 12s\tremaining: 1m 10s\n",
      "731:\tlearn: 1.1123188\ttotal: 3m 12s\tremaining: 1m 10s\n",
      "732:\tlearn: 1.1121108\ttotal: 3m 13s\tremaining: 1m 10s\n",
      "733:\tlearn: 1.1120401\ttotal: 3m 13s\tremaining: 1m 10s\n",
      "734:\tlearn: 1.1118099\ttotal: 3m 13s\tremaining: 1m 9s\n",
      "735:\tlearn: 1.1116405\ttotal: 3m 13s\tremaining: 1m 9s\n",
      "736:\tlearn: 1.1114675\ttotal: 3m 14s\tremaining: 1m 9s\n",
      "737:\tlearn: 1.1111635\ttotal: 3m 14s\tremaining: 1m 8s\n",
      "738:\tlearn: 1.1109738\ttotal: 3m 14s\tremaining: 1m 8s\n",
      "739:\tlearn: 1.1106726\ttotal: 3m 14s\tremaining: 1m 8s\n",
      "740:\tlearn: 1.1102713\ttotal: 3m 15s\tremaining: 1m 8s\n",
      "741:\tlearn: 1.1100033\ttotal: 3m 15s\tremaining: 1m 7s\n",
      "742:\tlearn: 1.1098870\ttotal: 3m 15s\tremaining: 1m 7s\n",
      "743:\tlearn: 1.1097633\ttotal: 3m 15s\tremaining: 1m 7s\n",
      "744:\tlearn: 1.1095438\ttotal: 3m 15s\tremaining: 1m 7s\n",
      "745:\tlearn: 1.1094293\ttotal: 3m 16s\tremaining: 1m 6s\n",
      "746:\tlearn: 1.1091385\ttotal: 3m 16s\tremaining: 1m 6s\n",
      "747:\tlearn: 1.1088909\ttotal: 3m 16s\tremaining: 1m 6s\n",
      "748:\tlearn: 1.1086095\ttotal: 3m 16s\tremaining: 1m 5s\n",
      "749:\tlearn: 1.1084769\ttotal: 3m 17s\tremaining: 1m 5s\n",
      "750:\tlearn: 1.1083435\ttotal: 3m 17s\tremaining: 1m 5s\n",
      "751:\tlearn: 1.1081542\ttotal: 3m 17s\tremaining: 1m 5s\n",
      "752:\tlearn: 1.1079364\ttotal: 3m 17s\tremaining: 1m 4s\n",
      "753:\tlearn: 1.1076796\ttotal: 3m 18s\tremaining: 1m 4s\n",
      "754:\tlearn: 1.1073724\ttotal: 3m 18s\tremaining: 1m 4s\n",
      "755:\tlearn: 1.1071708\ttotal: 3m 18s\tremaining: 1m 4s\n",
      "756:\tlearn: 1.1069725\ttotal: 3m 18s\tremaining: 1m 3s\n",
      "757:\tlearn: 1.1067619\ttotal: 3m 18s\tremaining: 1m 3s\n",
      "758:\tlearn: 1.1065577\ttotal: 3m 19s\tremaining: 1m 3s\n",
      "759:\tlearn: 1.1063827\ttotal: 3m 19s\tremaining: 1m 2s\n",
      "760:\tlearn: 1.1061674\ttotal: 3m 19s\tremaining: 1m 2s\n",
      "761:\tlearn: 1.1058375\ttotal: 3m 19s\tremaining: 1m 2s\n",
      "762:\tlearn: 1.1055827\ttotal: 3m 20s\tremaining: 1m 2s\n",
      "763:\tlearn: 1.1053594\ttotal: 3m 20s\tremaining: 1m 1s\n",
      "764:\tlearn: 1.1051280\ttotal: 3m 20s\tremaining: 1m 1s\n",
      "765:\tlearn: 1.1049465\ttotal: 3m 20s\tremaining: 1m 1s\n",
      "766:\tlearn: 1.1047003\ttotal: 3m 21s\tremaining: 1m 1s\n",
      "767:\tlearn: 1.1046046\ttotal: 3m 21s\tremaining: 1m\n",
      "768:\tlearn: 1.1043957\ttotal: 3m 21s\tremaining: 1m\n",
      "769:\tlearn: 1.1041497\ttotal: 3m 21s\tremaining: 1m\n",
      "770:\tlearn: 1.1040655\ttotal: 3m 22s\tremaining: 1m\n",
      "771:\tlearn: 1.1038123\ttotal: 3m 22s\tremaining: 59.8s\n",
      "772:\tlearn: 1.1036484\ttotal: 3m 22s\tremaining: 59.5s\n",
      "773:\tlearn: 1.1034646\ttotal: 3m 22s\tremaining: 59.3s\n",
      "774:\tlearn: 1.1031151\ttotal: 3m 23s\tremaining: 59s\n",
      "775:\tlearn: 1.1029909\ttotal: 3m 23s\tremaining: 58.7s\n",
      "776:\tlearn: 1.1027991\ttotal: 3m 23s\tremaining: 58.5s\n",
      "777:\tlearn: 1.1026341\ttotal: 3m 23s\tremaining: 58.2s\n",
      "778:\tlearn: 1.1024372\ttotal: 3m 24s\tremaining: 57.9s\n",
      "779:\tlearn: 1.1021004\ttotal: 3m 24s\tremaining: 57.6s\n",
      "780:\tlearn: 1.1019003\ttotal: 3m 24s\tremaining: 57.4s\n",
      "781:\tlearn: 1.1017520\ttotal: 3m 24s\tremaining: 57.1s\n",
      "782:\tlearn: 1.1014720\ttotal: 3m 25s\tremaining: 56.9s\n",
      "783:\tlearn: 1.1013743\ttotal: 3m 25s\tremaining: 56.6s\n",
      "784:\tlearn: 1.1011723\ttotal: 3m 25s\tremaining: 56.3s\n",
      "785:\tlearn: 1.1009723\ttotal: 3m 25s\tremaining: 56.1s\n",
      "786:\tlearn: 1.1008267\ttotal: 3m 26s\tremaining: 55.8s\n",
      "787:\tlearn: 1.1006456\ttotal: 3m 26s\tremaining: 55.5s\n",
      "788:\tlearn: 1.1004809\ttotal: 3m 26s\tremaining: 55.2s\n",
      "789:\tlearn: 1.1003459\ttotal: 3m 26s\tremaining: 55s\n",
      "790:\tlearn: 1.1000599\ttotal: 3m 27s\tremaining: 54.7s\n",
      "791:\tlearn: 1.0998425\ttotal: 3m 27s\tremaining: 54.4s\n",
      "792:\tlearn: 1.0996224\ttotal: 3m 27s\tremaining: 54.2s\n",
      "793:\tlearn: 1.0994257\ttotal: 3m 27s\tremaining: 53.9s\n",
      "794:\tlearn: 1.0990938\ttotal: 3m 28s\tremaining: 53.7s\n",
      "795:\tlearn: 1.0987189\ttotal: 3m 28s\tremaining: 53.4s\n",
      "796:\tlearn: 1.0985187\ttotal: 3m 28s\tremaining: 53.2s\n",
      "797:\tlearn: 1.0982755\ttotal: 3m 28s\tremaining: 52.9s\n",
      "798:\tlearn: 1.0980955\ttotal: 3m 29s\tremaining: 52.6s\n",
      "799:\tlearn: 1.0978343\ttotal: 3m 29s\tremaining: 52.4s\n",
      "800:\tlearn: 1.0976064\ttotal: 3m 29s\tremaining: 52.1s\n",
      "801:\tlearn: 1.0974675\ttotal: 3m 29s\tremaining: 51.8s\n",
      "802:\tlearn: 1.0972847\ttotal: 3m 30s\tremaining: 51.5s\n",
      "803:\tlearn: 1.0970055\ttotal: 3m 30s\tremaining: 51.3s\n",
      "804:\tlearn: 1.0968781\ttotal: 3m 30s\tremaining: 51s\n",
      "805:\tlearn: 1.0965228\ttotal: 3m 30s\tremaining: 50.7s\n",
      "806:\tlearn: 1.0962534\ttotal: 3m 31s\tremaining: 50.5s\n",
      "807:\tlearn: 1.0961020\ttotal: 3m 31s\tremaining: 50.2s\n",
      "808:\tlearn: 1.0959637\ttotal: 3m 31s\tremaining: 49.9s\n",
      "809:\tlearn: 1.0956324\ttotal: 3m 31s\tremaining: 49.7s\n",
      "810:\tlearn: 1.0953870\ttotal: 3m 32s\tremaining: 49.4s\n",
      "811:\tlearn: 1.0951562\ttotal: 3m 32s\tremaining: 49.2s\n",
      "812:\tlearn: 1.0949270\ttotal: 3m 32s\tremaining: 48.9s\n",
      "813:\tlearn: 1.0947319\ttotal: 3m 32s\tremaining: 48.6s\n",
      "814:\tlearn: 1.0946065\ttotal: 3m 33s\tremaining: 48.4s\n",
      "815:\tlearn: 1.0944618\ttotal: 3m 33s\tremaining: 48.1s\n",
      "816:\tlearn: 1.0941632\ttotal: 3m 33s\tremaining: 47.8s\n",
      "817:\tlearn: 1.0939429\ttotal: 3m 33s\tremaining: 47.5s\n",
      "818:\tlearn: 1.0937900\ttotal: 3m 33s\tremaining: 47.3s\n",
      "819:\tlearn: 1.0936447\ttotal: 3m 34s\tremaining: 47s\n",
      "820:\tlearn: 1.0935030\ttotal: 3m 34s\tremaining: 46.7s\n",
      "821:\tlearn: 1.0933921\ttotal: 3m 34s\tremaining: 46.5s\n",
      "822:\tlearn: 1.0931789\ttotal: 3m 34s\tremaining: 46.2s\n",
      "823:\tlearn: 1.0928616\ttotal: 3m 35s\tremaining: 45.9s\n",
      "824:\tlearn: 1.0925872\ttotal: 3m 35s\tremaining: 45.7s\n",
      "825:\tlearn: 1.0923775\ttotal: 3m 35s\tremaining: 45.4s\n",
      "826:\tlearn: 1.0921583\ttotal: 3m 35s\tremaining: 45.2s\n",
      "827:\tlearn: 1.0918555\ttotal: 3m 36s\tremaining: 44.9s\n",
      "828:\tlearn: 1.0915605\ttotal: 3m 36s\tremaining: 44.6s\n",
      "829:\tlearn: 1.0913948\ttotal: 3m 36s\tremaining: 44.4s\n",
      "830:\tlearn: 1.0912955\ttotal: 3m 36s\tremaining: 44.1s\n",
      "831:\tlearn: 1.0909429\ttotal: 3m 37s\tremaining: 43.9s\n",
      "832:\tlearn: 1.0906664\ttotal: 3m 37s\tremaining: 43.6s\n",
      "833:\tlearn: 1.0904598\ttotal: 3m 37s\tremaining: 43.3s\n",
      "834:\tlearn: 1.0903099\ttotal: 3m 37s\tremaining: 43.1s\n",
      "835:\tlearn: 1.0900578\ttotal: 3m 38s\tremaining: 42.8s\n",
      "836:\tlearn: 1.0899101\ttotal: 3m 38s\tremaining: 42.5s\n",
      "837:\tlearn: 1.0897452\ttotal: 3m 38s\tremaining: 42.3s\n",
      "838:\tlearn: 1.0894972\ttotal: 3m 38s\tremaining: 42s\n",
      "839:\tlearn: 1.0893016\ttotal: 3m 39s\tremaining: 41.7s\n",
      "840:\tlearn: 1.0890725\ttotal: 3m 39s\tremaining: 41.5s\n",
      "841:\tlearn: 1.0887948\ttotal: 3m 39s\tremaining: 41.2s\n",
      "842:\tlearn: 1.0886324\ttotal: 3m 39s\tremaining: 40.9s\n",
      "843:\tlearn: 1.0885114\ttotal: 3m 39s\tremaining: 40.7s\n",
      "844:\tlearn: 1.0883432\ttotal: 3m 40s\tremaining: 40.4s\n",
      "845:\tlearn: 1.0881618\ttotal: 3m 40s\tremaining: 40.1s\n",
      "846:\tlearn: 1.0879710\ttotal: 3m 40s\tremaining: 39.9s\n",
      "847:\tlearn: 1.0878189\ttotal: 3m 41s\tremaining: 39.6s\n",
      "848:\tlearn: 1.0876024\ttotal: 3m 41s\tremaining: 39.4s\n",
      "849:\tlearn: 1.0874052\ttotal: 3m 41s\tremaining: 39.1s\n",
      "850:\tlearn: 1.0872384\ttotal: 3m 41s\tremaining: 38.8s\n",
      "851:\tlearn: 1.0869200\ttotal: 3m 41s\tremaining: 38.6s\n",
      "852:\tlearn: 1.0867696\ttotal: 3m 42s\tremaining: 38.3s\n",
      "853:\tlearn: 1.0866224\ttotal: 3m 42s\tremaining: 38s\n",
      "854:\tlearn: 1.0864252\ttotal: 3m 42s\tremaining: 37.8s\n",
      "855:\tlearn: 1.0861506\ttotal: 3m 42s\tremaining: 37.5s\n",
      "856:\tlearn: 1.0857174\ttotal: 3m 43s\tremaining: 37.2s\n",
      "857:\tlearn: 1.0855389\ttotal: 3m 43s\tremaining: 37s\n",
      "858:\tlearn: 1.0853541\ttotal: 3m 43s\tremaining: 36.7s\n",
      "859:\tlearn: 1.0851763\ttotal: 3m 44s\tremaining: 36.5s\n",
      "860:\tlearn: 1.0850446\ttotal: 3m 44s\tremaining: 36.2s\n",
      "861:\tlearn: 1.0849110\ttotal: 3m 44s\tremaining: 35.9s\n",
      "862:\tlearn: 1.0846595\ttotal: 3m 44s\tremaining: 35.7s\n",
      "863:\tlearn: 1.0844238\ttotal: 3m 45s\tremaining: 35.4s\n",
      "864:\tlearn: 1.0842331\ttotal: 3m 45s\tremaining: 35.2s\n",
      "865:\tlearn: 1.0841128\ttotal: 3m 45s\tremaining: 34.9s\n",
      "866:\tlearn: 1.0839237\ttotal: 3m 45s\tremaining: 34.6s\n",
      "867:\tlearn: 1.0837167\ttotal: 3m 46s\tremaining: 34.4s\n",
      "868:\tlearn: 1.0836123\ttotal: 3m 46s\tremaining: 34.1s\n",
      "869:\tlearn: 1.0834350\ttotal: 3m 46s\tremaining: 33.8s\n",
      "870:\tlearn: 1.0832930\ttotal: 3m 46s\tremaining: 33.6s\n",
      "871:\tlearn: 1.0831472\ttotal: 3m 47s\tremaining: 33.3s\n",
      "872:\tlearn: 1.0830190\ttotal: 3m 47s\tremaining: 33.1s\n",
      "873:\tlearn: 1.0827208\ttotal: 3m 47s\tremaining: 32.8s\n",
      "874:\tlearn: 1.0825620\ttotal: 3m 48s\tremaining: 32.6s\n",
      "875:\tlearn: 1.0824705\ttotal: 3m 48s\tremaining: 32.3s\n",
      "876:\tlearn: 1.0822147\ttotal: 3m 48s\tremaining: 32.1s\n",
      "877:\tlearn: 1.0820536\ttotal: 3m 48s\tremaining: 31.8s\n",
      "878:\tlearn: 1.0816909\ttotal: 3m 49s\tremaining: 31.6s\n",
      "879:\tlearn: 1.0814334\ttotal: 3m 49s\tremaining: 31.3s\n",
      "880:\tlearn: 1.0812528\ttotal: 3m 49s\tremaining: 31s\n",
      "881:\tlearn: 1.0811376\ttotal: 3m 50s\tremaining: 30.8s\n",
      "882:\tlearn: 1.0810197\ttotal: 3m 50s\tremaining: 30.5s\n",
      "883:\tlearn: 1.0807779\ttotal: 3m 50s\tremaining: 30.3s\n",
      "884:\tlearn: 1.0806258\ttotal: 3m 51s\tremaining: 30s\n",
      "885:\tlearn: 1.0804813\ttotal: 3m 51s\tremaining: 29.8s\n",
      "886:\tlearn: 1.0802373\ttotal: 3m 51s\tremaining: 29.5s\n",
      "887:\tlearn: 1.0801532\ttotal: 3m 51s\tremaining: 29.2s\n",
      "888:\tlearn: 1.0799131\ttotal: 3m 52s\tremaining: 29s\n",
      "889:\tlearn: 1.0797966\ttotal: 3m 52s\tremaining: 28.7s\n",
      "890:\tlearn: 1.0796321\ttotal: 3m 52s\tremaining: 28.5s\n",
      "891:\tlearn: 1.0794666\ttotal: 3m 52s\tremaining: 28.2s\n",
      "892:\tlearn: 1.0793220\ttotal: 3m 53s\tremaining: 27.9s\n",
      "893:\tlearn: 1.0791687\ttotal: 3m 53s\tremaining: 27.7s\n",
      "894:\tlearn: 1.0788898\ttotal: 3m 53s\tremaining: 27.4s\n",
      "895:\tlearn: 1.0787915\ttotal: 3m 53s\tremaining: 27.2s\n",
      "896:\tlearn: 1.0786897\ttotal: 3m 54s\tremaining: 26.9s\n",
      "897:\tlearn: 1.0784093\ttotal: 3m 54s\tremaining: 26.6s\n",
      "898:\tlearn: 1.0783243\ttotal: 3m 54s\tremaining: 26.4s\n",
      "899:\tlearn: 1.0780141\ttotal: 3m 55s\tremaining: 26.1s\n",
      "900:\tlearn: 1.0777508\ttotal: 3m 55s\tremaining: 25.9s\n",
      "901:\tlearn: 1.0775073\ttotal: 3m 55s\tremaining: 25.6s\n",
      "902:\tlearn: 1.0771004\ttotal: 3m 56s\tremaining: 25.4s\n",
      "903:\tlearn: 1.0768548\ttotal: 3m 56s\tremaining: 25.1s\n",
      "904:\tlearn: 1.0766832\ttotal: 3m 56s\tremaining: 24.9s\n",
      "905:\tlearn: 1.0764402\ttotal: 3m 57s\tremaining: 24.6s\n",
      "906:\tlearn: 1.0762447\ttotal: 3m 57s\tremaining: 24.3s\n",
      "907:\tlearn: 1.0760978\ttotal: 3m 57s\tremaining: 24.1s\n",
      "908:\tlearn: 1.0758887\ttotal: 3m 57s\tremaining: 23.8s\n",
      "909:\tlearn: 1.0757709\ttotal: 3m 58s\tremaining: 23.5s\n",
      "910:\tlearn: 1.0756112\ttotal: 3m 58s\tremaining: 23.3s\n",
      "911:\tlearn: 1.0754775\ttotal: 3m 58s\tremaining: 23s\n",
      "912:\tlearn: 1.0752556\ttotal: 3m 58s\tremaining: 22.7s\n",
      "913:\tlearn: 1.0750677\ttotal: 3m 58s\tremaining: 22.5s\n",
      "914:\tlearn: 1.0749176\ttotal: 3m 59s\tremaining: 22.2s\n",
      "915:\tlearn: 1.0747677\ttotal: 3m 59s\tremaining: 22s\n",
      "916:\tlearn: 1.0746082\ttotal: 3m 59s\tremaining: 21.7s\n",
      "917:\tlearn: 1.0744604\ttotal: 3m 59s\tremaining: 21.4s\n",
      "918:\tlearn: 1.0743509\ttotal: 4m\tremaining: 21.2s\n",
      "919:\tlearn: 1.0742468\ttotal: 4m\tremaining: 20.9s\n",
      "920:\tlearn: 1.0740322\ttotal: 4m\tremaining: 20.6s\n",
      "921:\tlearn: 1.0738717\ttotal: 4m\tremaining: 20.4s\n",
      "922:\tlearn: 1.0736950\ttotal: 4m 1s\tremaining: 20.1s\n",
      "923:\tlearn: 1.0734035\ttotal: 4m 1s\tremaining: 19.9s\n",
      "924:\tlearn: 1.0732220\ttotal: 4m 1s\tremaining: 19.6s\n",
      "925:\tlearn: 1.0730447\ttotal: 4m 1s\tremaining: 19.3s\n",
      "926:\tlearn: 1.0726862\ttotal: 4m 2s\tremaining: 19.1s\n",
      "927:\tlearn: 1.0726295\ttotal: 4m 2s\tremaining: 18.8s\n",
      "928:\tlearn: 1.0722940\ttotal: 4m 2s\tremaining: 18.5s\n",
      "929:\tlearn: 1.0721432\ttotal: 4m 2s\tremaining: 18.3s\n",
      "930:\tlearn: 1.0720017\ttotal: 4m 3s\tremaining: 18s\n",
      "931:\tlearn: 1.0718277\ttotal: 4m 3s\tremaining: 17.8s\n",
      "932:\tlearn: 1.0716536\ttotal: 4m 3s\tremaining: 17.5s\n",
      "933:\tlearn: 1.0715003\ttotal: 4m 3s\tremaining: 17.2s\n",
      "934:\tlearn: 1.0713322\ttotal: 4m 4s\tremaining: 17s\n",
      "935:\tlearn: 1.0711196\ttotal: 4m 4s\tremaining: 16.7s\n",
      "936:\tlearn: 1.0709523\ttotal: 4m 4s\tremaining: 16.4s\n",
      "937:\tlearn: 1.0707824\ttotal: 4m 4s\tremaining: 16.2s\n",
      "938:\tlearn: 1.0705958\ttotal: 4m 5s\tremaining: 15.9s\n",
      "939:\tlearn: 1.0704516\ttotal: 4m 5s\tremaining: 15.7s\n",
      "940:\tlearn: 1.0703070\ttotal: 4m 5s\tremaining: 15.4s\n",
      "941:\tlearn: 1.0701220\ttotal: 4m 5s\tremaining: 15.1s\n",
      "942:\tlearn: 1.0698687\ttotal: 4m 6s\tremaining: 14.9s\n",
      "943:\tlearn: 1.0696135\ttotal: 4m 6s\tremaining: 14.6s\n",
      "944:\tlearn: 1.0693478\ttotal: 4m 6s\tremaining: 14.4s\n",
      "945:\tlearn: 1.0691331\ttotal: 4m 6s\tremaining: 14.1s\n",
      "946:\tlearn: 1.0689409\ttotal: 4m 7s\tremaining: 13.8s\n",
      "947:\tlearn: 1.0687774\ttotal: 4m 7s\tremaining: 13.6s\n",
      "948:\tlearn: 1.0686394\ttotal: 4m 7s\tremaining: 13.3s\n",
      "949:\tlearn: 1.0684119\ttotal: 4m 7s\tremaining: 13s\n",
      "950:\tlearn: 1.0682398\ttotal: 4m 8s\tremaining: 12.8s\n",
      "951:\tlearn: 1.0680507\ttotal: 4m 8s\tremaining: 12.5s\n",
      "952:\tlearn: 1.0679066\ttotal: 4m 8s\tremaining: 12.3s\n",
      "953:\tlearn: 1.0677538\ttotal: 4m 8s\tremaining: 12s\n",
      "954:\tlearn: 1.0674833\ttotal: 4m 9s\tremaining: 11.7s\n",
      "955:\tlearn: 1.0673143\ttotal: 4m 9s\tremaining: 11.5s\n",
      "956:\tlearn: 1.0671845\ttotal: 4m 9s\tremaining: 11.2s\n",
      "957:\tlearn: 1.0670560\ttotal: 4m 9s\tremaining: 11s\n",
      "958:\tlearn: 1.0669393\ttotal: 4m 10s\tremaining: 10.7s\n",
      "959:\tlearn: 1.0667477\ttotal: 4m 10s\tremaining: 10.4s\n",
      "960:\tlearn: 1.0666173\ttotal: 4m 10s\tremaining: 10.2s\n",
      "961:\tlearn: 1.0663245\ttotal: 4m 10s\tremaining: 9.9s\n",
      "962:\tlearn: 1.0661062\ttotal: 4m 10s\tremaining: 9.64s\n",
      "963:\tlearn: 1.0659019\ttotal: 4m 11s\tremaining: 9.38s\n",
      "964:\tlearn: 1.0657384\ttotal: 4m 11s\tremaining: 9.12s\n",
      "965:\tlearn: 1.0656081\ttotal: 4m 11s\tremaining: 8.86s\n",
      "966:\tlearn: 1.0654466\ttotal: 4m 11s\tremaining: 8.6s\n",
      "967:\tlearn: 1.0652134\ttotal: 4m 12s\tremaining: 8.34s\n",
      "968:\tlearn: 1.0650382\ttotal: 4m 12s\tremaining: 8.08s\n",
      "969:\tlearn: 1.0648860\ttotal: 4m 12s\tremaining: 7.82s\n",
      "970:\tlearn: 1.0648098\ttotal: 4m 12s\tremaining: 7.55s\n",
      "971:\tlearn: 1.0645894\ttotal: 4m 13s\tremaining: 7.29s\n",
      "972:\tlearn: 1.0643638\ttotal: 4m 13s\tremaining: 7.03s\n",
      "973:\tlearn: 1.0642098\ttotal: 4m 13s\tremaining: 6.77s\n",
      "974:\tlearn: 1.0639993\ttotal: 4m 14s\tremaining: 6.51s\n",
      "975:\tlearn: 1.0638167\ttotal: 4m 14s\tremaining: 6.25s\n",
      "976:\tlearn: 1.0636116\ttotal: 4m 14s\tremaining: 5.99s\n",
      "977:\tlearn: 1.0634917\ttotal: 4m 14s\tremaining: 5.73s\n",
      "978:\tlearn: 1.0633403\ttotal: 4m 15s\tremaining: 5.47s\n",
      "979:\tlearn: 1.0632524\ttotal: 4m 15s\tremaining: 5.21s\n",
      "980:\tlearn: 1.0630812\ttotal: 4m 15s\tremaining: 4.95s\n",
      "981:\tlearn: 1.0628871\ttotal: 4m 15s\tremaining: 4.69s\n",
      "982:\tlearn: 1.0627386\ttotal: 4m 16s\tremaining: 4.43s\n",
      "983:\tlearn: 1.0625353\ttotal: 4m 16s\tremaining: 4.17s\n",
      "984:\tlearn: 1.0623871\ttotal: 4m 16s\tremaining: 3.91s\n",
      "985:\tlearn: 1.0622509\ttotal: 4m 16s\tremaining: 3.65s\n",
      "986:\tlearn: 1.0621528\ttotal: 4m 17s\tremaining: 3.39s\n",
      "987:\tlearn: 1.0619534\ttotal: 4m 17s\tremaining: 3.13s\n",
      "988:\tlearn: 1.0618088\ttotal: 4m 17s\tremaining: 2.86s\n",
      "989:\tlearn: 1.0617091\ttotal: 4m 17s\tremaining: 2.6s\n",
      "990:\tlearn: 1.0615776\ttotal: 4m 18s\tremaining: 2.34s\n",
      "991:\tlearn: 1.0612805\ttotal: 4m 18s\tremaining: 2.08s\n",
      "992:\tlearn: 1.0611029\ttotal: 4m 18s\tremaining: 1.82s\n",
      "993:\tlearn: 1.0609060\ttotal: 4m 18s\tremaining: 1.56s\n",
      "994:\tlearn: 1.0606068\ttotal: 4m 19s\tremaining: 1.3s\n",
      "995:\tlearn: 1.0604063\ttotal: 4m 19s\tremaining: 1.04s\n",
      "996:\tlearn: 1.0601967\ttotal: 4m 19s\tremaining: 781ms\n",
      "997:\tlearn: 1.0600134\ttotal: 4m 19s\tremaining: 521ms\n",
      "998:\tlearn: 1.0599366\ttotal: 4m 19s\tremaining: 260ms\n",
      "999:\tlearn: 1.0596694\ttotal: 4m 20s\tremaining: 0us\n",
      "For the multi response, classification report on test set is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.60      0.55     17896\n",
      "         1.0       0.46      0.40      0.43     17641\n",
      "         2.0       0.33      0.21      0.26     17445\n",
      "         3.0       0.40      0.36      0.38     17475\n",
      "         4.0       0.56      0.64      0.59     17440\n",
      "         5.0       0.75      0.94      0.83     17583\n",
      "         6.0       0.99      1.00      0.99     17545\n",
      "\n",
      "    accuracy                           0.59    123025\n",
      "   macro avg       0.57      0.59      0.58    123025\n",
      "weighted avg       0.57      0.59      0.58    123025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure estimator\n",
    "cbc = CatBoostClassifier(classes_count=7)\n",
    "\n",
    "# Train and test for multi response\n",
    "cbc.fit(X_train_multi, y_train_multi)\n",
    "y_predict = cbc.predict(X_test_multi)\n",
    "print('For the multi response, classification report on test set is:')\n",
    "print(classification_report(y_test_multi, y_predict))\n",
    "print(pd.crosstab(y_predict, y_test_multi, rownames=['y_predict'], colnames=['y_test']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis 2 Report\n",
    "\n",
    "At first, I was trying to use a single train set and test set for all those chronic conditions and all models. But when I finished running those models, the performance on each condition is really poor that the model tend to predict most samples into one class. The multiclass case is even worse that actually all test cases are classified as 0 for all models.\n",
    "\n",
    "The reason is that the classes are highly imbalanced for each chronic condition since only a small population has those conditions. Moreover, the population who have each condition is different from each other. So I over sampled for each condition, and over sampled again for the multiclass case. The resulting performance is then improved dramatically.\n",
    "\n",
    "There are 5 features with a large range, `'_DRNKWK1', '_FRUTSU1', '_VEGESU1', 'FRNCHDA_', '_BMI5'`, that may affect the performance. So standardization is applied to those features. All other features have small range with 10, all they are categorical, so the rest are kept unchanged. The resulting performance is then slightly improved.\n",
    "\n",
    "The table bellow shows the performance of each model on both responses. Scores are accuracy score calculated on the test set.\n",
    "\n",
    "| Model               | Binary | Multiclass |\n",
    "|---------------------|--------|------------|\n",
    "| Logistic Regression | 0.61   | 0.29       |\n",
    "| KNN                 | 0.95   | 0.83       |\n",
    "| Random Forest       | 1.00   | 0.94       |\n",
    "| Gradient Boost      | 0.63   | 0.40       |\n",
    "| XGBoost             | 0.70   | 0.53       |\n",
    "| CatBoost            | 0.60   | 0.59        |\n",
    "\n",
    "\n",
    "Among those models random forest would be chosen as the model for classification because of its impressive performance and its speed in training. KNN could also be used for classify the binary category as it has a relatively high score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}